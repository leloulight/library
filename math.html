<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  数学 - 小土刀的笔记
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="小土刀的笔记" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        <li id="menu_item_index"><a href="index.html">HOME</a></li>
        <li id="menu_item_archives"><a href="archives.html">Archives</a></li>
        <li id="menu_item_about"><a href="about.html">ABOUT</a></li>
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" action="http://google.com/search" method="get">
    <input type="hidden" name="q" value="site:" />
    <input tabindex="1" type="search" name="q"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 小土刀的笔记</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="math.html">数学</a></li>
        
            <li><a href="personal.html">个人</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="14520204009043.html">
                
                  <h1>统计陷阱</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>有 3 种谎言：谎言，糟糕透顶的谎言和统计资料</li>
<li>对于追求效率的公民而言，统计思维总有一天会和读写能力一样重要</li>
<li>使我们陷入麻烦的通常并非我们不知道的事情，而是那些我们知道却不正确的事情</li>
<li>整数总是不完善的</li>
<li>我需要完成一个很大的课题——统计学，但却感到我的写作功底十分有限，如果不牺牲准确性和完整性，就很难使人理解</li>
</ul>

<h2 id="toc_0">第一章 内在有偏的数据</h2>

<ul>
<li>单凭某一数据很难反应实情</li>
<li>一条河永远不可能高于它的源头，同理，对样本研究后得到的结论不会好于样本本身</li>
<li>一个以抽样为基础的报告如果要有价值，就必须使用具有代表性的样本，这种样本排除了各种误差</li>
<li>无形的误差与有形的误差一样容易破坏样本的可信度</li>
</ul>

<h2 id="toc_1">第二章 精心挑选的平均数</h2>

<p>普查工作者一般都具有足够的统计知识、技术以及调查费用以确保抽样的精确度。他们并非居心叵测之徒。但并不是所有能见到的数据都产生于这样良好的环境，也并不是所有的数据都会有附有类似的精确度说明</p>

<h2 id="toc_2">第三章 没有披露的数据</h2>

<ul>
<li>如果某条信息提供了显著性程度，你将对它有更深的了解。显著成都通常用概率表示。</li>
<li>将『正常的』与『期望的』混为一谈导致事情变得更糟</li>
<li>这些没有透露的数据其欺骗性在于人们经常忽略了它们的不存在，这当然也是使用这些数据的人获取成功的奥秘</li>
<li>当一个平均数、一张图表或者某种趋势遗漏了这些重要的数据，请对它们保留一些怀疑。</li>
</ul>

<h2 id="toc_3">第四章 毫无意义的工作</h2>

<ul>
<li>你的样本以多大的精度代表总体是可以用数据来衡量的，那就是：可能误差和标准误差</li>
<li>只有当差别有意义时才能称之为差别</li>
</ul>

<h2 id="toc_4">第五章 惊人的统计图形</h2>

<p>注意比例尺和起始标尺，这可能会产生极大的误导性</p>

<h2 id="toc_5">第六章 平面图形</h2>

<p>利用一维图形的信息不对称，可以营造出非常夸张的视觉效果</p>

<h2 id="toc_6">第七章 不相匹配的资料</h2>

<p>如果你想证明某事，却发现没有能力办到，那么试着解释其他事情并假装它们是同一回事。</p>

<h2 id="toc_7">第八章 相关关系与因果关系</h2>

<p>相关并不等于因果，一定要注意这里的区别</p>

<h2 id="toc_8">第九章 如何进行统计操纵</h2>

<ul>
<li>扭曲统计数据的最巧妙方法是利用地图</li>
<li>百分数也给误解提供了肥沃的土壤。和小数一样，它也能为不确切的食物蒙上精确的面纱</li>
<li>将一些看似能直接相加却不能这样操作的事情加在一起会产生大量的欺骗和隐瞒</li>
</ul>

<h2 id="toc_9">第十章 对统计资料提出的五个问题</h2>

<ol>
<li>谁说的？有意识的偏差和无意识的偏差</li>
<li>他是如何知道的？注意样本的有偏，数值是否足够大</li>
<li>遗漏了什么？</li>
<li>是否有人偷换了概念？</li>
<li>这个资料有意义吗？</li>
</ol>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204008891.html">
                
                  <h1>信号与噪声</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Nate Silver</p>

<p>『预测』一词源于日耳曼语，而『预言』一词源自拉丁语。『预测』反映的是新教世俗思想，而不是神圣罗马帝国的理想世界。『预测』是指再不确定的条件下进行计划，这一行为需要谨慎、智慧和勤奋，更像我们今天所说的『预见』一词。</p>

<h2 id="toc_0">生产力悖论</h2>

<p>一旦信息增长的速度过快，而我们处理信息的能力尚且不足，情况就很危险。过去 40 年的人类历史表明，把信息转变为有用的知识可能还需要很长时间，一不小心，我们就有可能倒退回去。</p>

<p>20 世纪七八十年代的计算机热非但未能推动经济和科学的发展，反而造成了两个领域生产力水平的短暂下降。</p>

<h2 id="toc_1">为何未来使我们震惊</h2>

<p>波及奥认为，进化来的本能有时会让我们去寻找原本不存在的模式，人们一直都在努力从随机噪声中发现模式。阿尔文·托夫勒认为，尽管世界本身正走向分化，变得更加复杂，但人类仍会以坚持自身看法的方式使这个世界变得简单，这便是我们的防御机制。</p>

<p>像万维网这类复杂的系统有这样一个特点，它们不像那些相对简单的系统那么容易出错，但一旦出错，必定是要命的大错。在信息宣传方面，资本主义和互联网都非常高效，这就使得好坏两种消息的广泛传播成为可能，而且坏消息也许会造成更大的影响。</p>

<h2 id="toc_2">预测与贝叶斯定理</h2>

<p>要做出准确的预测，首要的前提就是坚信客观真理的存在，并且执着地追寻它。而预测者的另一个承诺，就是要认识到他无法穷尽对客观真理的认知。</p>

<p>假设并不科学，可证伪的假设才是科学的。这就意味着在真实的世界里，假设可以通过预测得到检验。</p>

<h2 id="toc_3">第一章 预测失败的灾难性后果</h2>

<p>最失败的预测通常由很多共同点，即我们只关注那些符合我们对这个世界的期许的信息，而不在乎其真实性。对于那些最难测定的风险，即使它们严重威胁到我们的幸福生活，我们也会对其视而不见。</p>

<p>我们以为自己可以控制很多风险，但结果并非如此，也许这才是更大的威胁。</p>

<p>从更广泛得意义上讲，评级公司的问题在于，它们无法区分风险和不确定性的不同，或者它们对两者间的差别根本就不关心。</p>

<p>贪婪和恐惧是两个非常不稳定的因素，只有两者保持平衡，经济才能顺利发展。若贪婪在经济体系中占上风，就会产生经济泡沫；若恐惧因素压过贪婪，经济又会陷入恐慌。</p>

<h3 id="toc_4">失败预测的公式——非样本，无思考</h3>

<p>举个例子就很容易明白，假设你有30年的驾龄，在20000次的出行中，只有两次轻微的擦碰事故。有一天，你喝醉了，这个时候是应该自己开车回家，还是叫出租车呢？当然是应该叫出租车。</p>

<p>但是如果突发奇想想要自己开车回去，可能会这样给自己找理由，在20000的驾驶中由19998次都安全抵达，既然如此，何必找出租车呢？</p>

<p>问题是，20000次出行记录没有一次是像这次这样喝醉的，所以醉驾的样本数量是0，而不是20000。因此用之前的经验来预测是毫无意义的。这就是所谓的『非样本』问题。</p>

<h3 id="toc_5">前事不忘 后事之师</h3>

<p>很多预测者通常都不愿意考虑『非样本』中存在的问题。当我们将样本扩大到涵盖了那些在时空上都离我们很远的事件时，这通常意味着我们会遇到一些自己并不熟悉或与所进行研究关系并不紧密的案例。</p>

<p>我们忘了——也可能是故意忽略——我们的预测模式就是简化了的世界，我们以为即使犯了错，也无大碍。然而，在复杂系统中，错误都不是用程度来衡量的，而使用级别衡量的</p>

<h2 id="toc_6">第二章 政治选举预测：狐狸和刺猬，谁更聪明？</h2>

<p>泰特罗克发现，那些政治专家很难预测到苏联解体，因为既要预测到政权的衰亡，又要找到其衰亡的原因，就需要进行预测的人将不同立场的观点论据穿插到一起。这些观点本身没什么内在矛盾，但通常是由身处两个不同阵营的人发出的，而坚定地站债某一个思想阵营的学者则不可能同时接受两种思想。</p>

<h3 id="toc_7">狐狸型专家</h3>

<p>狐狸千伎百俩而有尽，刺猬凭一技之长而无穷。刺猬认为自己掌控者世间真理，认为自己就是万物的法则，切实保障着社会的运行。比如马克思和阶级斗争、弗洛伊德和潜意识、或是马尔科姆·格拉德威尔和引爆点等。而狐狸认为解决问题由许多种办法。他们对于琐碎、不确定、复杂或是有分歧的意见更加有耐心。如果说刺猬是猎手，总在不停地寻找大型猎物，那么狐狸更像是一个采集者.做预测时，狐狸型专家比刺猬型专家考虑得更周全。</p>

<table>
<thead>
<tr>
<th style="text-align: center">狐狸型专家的想法</th>
<th style="text-align: center">刺猬型专家的想法</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">千伎百俩：汇聚不同学科的思想，忽略最初的政治派别</td>
<td style="text-align: center">一技之长：把大部分精力投入到一两个重大问题上，以怀疑的眼光看待『局外人』的观点</td>
</tr>
<tr>
<td style="text-align: center">适应力强：最初的方法失效后，试图找到新的方法，或同时寻求多种方法</td>
<td style="text-align: center">坚持力强：坚持『总揽一切』的方法，新数据只能用来改善原始模式</td>
</tr>
<tr>
<td style="text-align: center">严于律己：有时会愿意（或是欣于）承认预测中的错误并接受谴责</td>
<td style="text-align: center">固执己见：错误归咎到坏运气或特殊情况上——好模式没有赶上好时机</td>
</tr>
<tr>
<td style="text-align: center">承认复杂性：承认宇宙的复杂性，认为许多基本问题不可解决或本身就是不可预测的</td>
<td style="text-align: center">寻找秩序：一旦从噪声中找到信号，便期望世界遵循某种相对简单的支配关系</td>
</tr>
<tr>
<td style="text-align: center">谨慎：用概率术语表达预测结论，并且证明自己的观点是正确的</td>
<td style="text-align: center">自信：很少对自己的预测进行正面回复，并且不愿改变自己的预测</td>
</tr>
<tr>
<td style="text-align: center">经验主义：更多地依赖观察而非理论</td>
<td style="text-align: center">意识形态：期待日常的问题正是宏伟理论或斗争的体现</td>
</tr>
<tr>
<td style="text-align: center">较好的预测家</td>
<td style="text-align: center">较差的预测家</td>
</tr>
</tbody>
</table>

<h3 id="toc_8">刺猬型专家更适合做电视嘉宾节目</h3>

<p>与刺猬型专家相比，狐狸型专家更清楚自己还有很多无知之处。</p>

<h3 id="toc_9">政治预测为什么常常失败</h3>

<p>一个陷阱就是党派意识形态。刺猬型专家总会将自己固有的偏好与分析的问题混为一谈，将证据带有偏见，仅凭个人喜好。</p>

<h3 id="toc_10">狐狸型预测方法</h3>

<h4 id="toc_11">原则一：用概率的方法思考问题</h4>

<p>结果的广泛分布就是现实世界不确定性的真实体现</p>

<h4 id="toc_12">原则二：今天的预测是你以后人生的第一个预测</h4>

<p>更新、更好的信息会不断出现，所以，只有时刻更新预测才能最大程度地利用有限的信息。因为害怕出丑而不对预测进行更改，这其实才是懦弱的表现。</p>

<h4 id="toc_13">原则三：寻求共识</h4>

<p>许多证据表明，群体预测要比个人预测准确，其准确率随预测领域的不同通常会高出 15%~20%。这并不是说群体预测就一定是准确的，但从多个角度考虑问题总会大有裨益。</p>

<h4 id="toc_14">定性信息与定量信息同等重要</h4>

<p>刺猬型专家会接受各种类型的信息，并借助这些信息强化他们的偏见，而狐狸型专家则会对不同类型的信息进行总体权衡，将定性分析和定量分析结合起来，所以能经常做出正确的预测。</p>

<h4 id="toc_15">做出客观的预测并非易事</h4>

<p>狐狸型专家认识到了人类在预测世界进程是所作判断的局限性，认识到这些局限，才能做出更准确的预测</p>

<h2 id="toc_16">第三章 棒球比赛预测：球探和数据怪才，谁更胜一筹</h2>

<p>一个好的棒球预测系统必须可以完成三项基本任务：</p>

<ol>
<li>考虑影响球员表现的外在因素</li>
<li>区别看待技术和运气因素</li>
<li>熟知老化曲线，了解球员的表现是如何随着年龄增长而发生变化的。</li>
</ol>

<p>设计完善的预测系统能够辨识出那些容易受运气影响的数据，比如，平均击球数就比本垒打数善变。</p>

<p>数据怪才们也有自己的偏见，其中最致命的一个偏见：若某项因素很难量化，那它就被视为无关紧要。</p>

<h3 id="toc_17">信息是决定预测成败的关键</h3>

<p>预测成功的关键是，不应该局限于定量信息，而应该用心权衡信息的适用性。</p>

<h3 id="toc_18">并不是信息越多，预测就越成功</h3>

<p>招募新球员时，球探都是带着主观想法进行选吧的，他们心中早就有了典型标准。</p>

<h2 id="toc_19">第四章 天气预测：蝴蝶扇动翅膀，有可能引起龙卷风</h2>

<p>适用于混沌理论的系统，常有以下两个特征：</p>

<ol>
<li>系统是动态的，这就意味着当前某一个时间点发生的动作会影响未来的动作</li>
<li>该系统是非线性的，这就意味着其会呈指数型增长而非加法积累</li>
</ol>

<h3 id="toc_20">什么样的预测才算是好预测</h3>

<ol>
<li>是否准确。预测与实际天气是否相符</li>
<li>诚实性。这个预测是不是反映了预测者的最佳判断呢？公之于众之前，这个预测是否作了某种程度的修饰呢？</li>
<li>经济价值。预测是否有助于公众或政治决策者做出更好的决定</li>
</ol>

<p>卡特琳娜飓风带给人们的教训是，准确性才是预测者的第一要务；而认为政治、个人荣誉或者经济利益高于预测的真实性，其实是预测的原罪。</p>

<h2 id="toc_21">第五章 地震预测：一个困惑了人类 1000 年的难题</h2>

<p>在统计学中，将噪声误认为信号的行为被称为过拟合。过度拟合代表了双重霉运：过度拟合的模型表面上来看比较好，但其实际性能却很糟糕。过拟合说明是好奇心左右了我们。</p>

<p>复杂理论认为，当一个简单的事物和其他事物互相作用时，就会表现得神秘怪异。一旦这种复杂性超越了某种水平，我们就不可能对这些过程做出预测。</p>

<h3 id="toc_22">被审判的预测科学</h3>

<p>预测者的首要职责就是忠于真理。</p>

<h2 id="toc_23">第六章 经济预测：经济学家为什么没有预测到 2008 年经济危机</h2>

<h3 id="toc_24">相关的两个经济变量未必互为因果</h3>

<p>在哈祖斯看来，经济预测者面临着三大基本挑战：</p>

<ol>
<li>单纯依靠经济统计数据，很难判断起因和结果。</li>
<li>经济始终都在变化，某一经济周期的经济运行状况无法被用来解释未来经济的发展。</li>
<li>经济学家以往的预测如此糟糕，那么他们作预测时所参照的数据也好不到哪里去</li>
</ol>

<p>真正具有预测性的变量几乎不存在，想要弄明白哪些是因果关系，哪些属于相关性，是很困难的。</p>

<p>相关性并不是指因果关系。</p>

<h3 id="toc_25">经济是一个动态系统，不是一个方程式</h3>

<p>经济学家与气象预报员面对的挑战或许有些可比性，两个基本问题：</p>

<ol>
<li>经济与大气一样，是动态系统。不同事物之间互相作用，这些系统都处于永久的运动当中。</li>
<li>气象预报受某些不确定的初始条件的约束。</li>
</ol>

<h3 id="toc_26">克服预测偏见的两种选择</h3>

<p>经济预测中不可避免地会存在偏见，如果想减少这种偏见，有两个基本选择：</p>

<ol>
<li>供应性选择，即为准确的经济预测创造市场。</li>
<li>需求性选择，即减少对不准确且过度自信的预测的需求</li>
</ol>

<p>从更广义的角度来看，在预测中表现出的自信并不能代表预测的准确程度，相反，这两者经常成反比。在经济领域或其他领域中，当我们阻止预测者对我们周围世界的内在风险给予百分百重视时，就会埋下巨大的风险。</p>

<h2 id="toc_27">第七章 传染性疾病预测：禽流感为何会突然爆发，又突然消失？</h2>

<p>外推法是一种非常初级的预测方法。这一方法仅仅包含一个假说，即未来是现在趋势持续发展的结果。众所周知的预测失败案例中，有些就是由于太过随意地应用了这一假设。</p>

<h3 id="toc_28">自我实现预测与自我否定预测</h3>

<p>设计和娱乐等领域由更多更加微妙得例子。这些领域间的竞争主要是猜测消费者的喜好——但是，商家也可以通过巧妙的营销计划影响消费者的喜好。同样的，疾病和其他身体状况也有这种自我实现的特性。</p>

<h3 id="toc_29">预测是为了让损失最小化</h3>

<p>预测时，形成更好的自我认识，正确解读所收到的信号非常重要。</p>

<h2 id="toc_30">第八章 贝叶斯定理：只有正确的预测才能让我们更接近真相</h2>

<p>成功的『赌客』以及任何领域中成功的预测者，从来不会以稳赚不赔的心态、无懈可击的理论和极其准确的尺度去看待未来，这些都是失败者的幻想，是过度自信的弊病。成功的『赌客』会把未来看成零星的可能性，这些可能性，这些可能性会像股票行情一样随着新信息的出现而上下浮动。当赌客们能够确保自己的预测不会出差错时，他们才会下注。</p>

<p>贝叶斯定理涉及条件概率，也就是说，一旦发生了某个事件，这一定理就可以告诉我们一种理论或假设是否正确。</p>

<p>拥有的信息量呈指数增长，需要验证的假设也正在以同样的速度增长。</p>

<h2 id="toc_31">第九章 国际象棋大战：计算机与人类的智能博弈</h2>

<p>开局阶段，独立思考能力更重要。</p>

<p>中局阶段：宽度与深度的两难选择。</p>

<p>残局阶段：计算机能力方面的较量。</p>

<p>用试错法提高计算机的预测能力</p>

<h2 id="toc_32">第十章 扑克牌游戏：如何从 1326 种组合中猜出对手的底牌</h2>

<p>德万说：我知道我做过的许多事情并不是最佳选择，但长期来看，恰恰是这些事情为我赢得了大笔赌金。但直到最近几年，人们才终于开始意识到这一点，情况才有所改善。</p>

<p>运气和技能通常被视为两个极端，但两者之间的关系其实更复杂一些。</p>

<h3 id="toc_33">以过程而不是结果为导向</h3>

<p>在这个不确定的世界上，我们仍是不完美的生物。即使作了糟糕的预测，我们也永远不会知道这是自己的错误还是预测模型的缺陷，或者只是因为我们不够走运。最接近的近似解，就是达到一种噪声与信号的和谐状态，两者缺一不可，我们要学会欣赏它们。</p>

<h2 id="toc_34">第十一章 股票市场：非理性交易者的存在让价格泡沫不可避免</h2>

<p>本书的核心前提就是，若想做出更准确的预测，就必须承认我们的判断是不可靠的。市场交易是集体判断的反应，从这个层面来看，这些反应也会出错。事实上，能做出完美预测的市场从理论上讲是不存在的。</p>

<p>噪声交易者让金融市场交易的存在变成可能，这样我们才能观察金融资产的价格。但是，噪声交易者们也导致市场无效运转。总体来看，噪声会使那些金融或经济市场运转方式的使用理论或学术理论难以检测。大多数时候，我们都在摸着石头过河。</p>

<h2 id="toc_35">第十二章 温室效应：未来 10 年，全球气温会上升还是下降</h2>

<p>在科学领域，很少看到所有数据都集中到一个明确的结论上的情况。真正的数据非常嘈杂，即使理论是无懈可击的，信号有时也会有所偏离，更何况根据贝叶斯定理，无懈可击的理论是不存在的。科学渐进的过程，需要进一步提炼与检验，这是科学怀疑论的全部。</p>

<h2 id="toc_36">第十三章 恐怖主义：比 911 更严重的恐怖袭击事件会发生吗</h2>

<p>事后更容易从一堆无关的信号中滤出用的信号。当然事发后的信号总是相当清晰，因为灾难已经发生。但是在事发之前，信号总是模糊不清，让人难以捉摸。</p>

<h2 id="toc_37">以概率的方式思考问题</h2>

<p>大脑在处理信息时使用的是近似法。与其说这是一种既成事实，不如说它是一种生物必要性：我们观察到的信息远多于我们有意识进行思考的信息，我们处理信息的方式是按照规律和模式对它们进行分类</p>

<ul>
<li>知道自己的观点源于何处</li>
<li>在不断的试错中进步</li>
<li>对可预测性的认知能力</li>
</ul>

<hr/>

<p>本书作者纳特西尔弗（Nate Silver）曾经在棒球预测和选举预测两大领域都取得了成功。在棒球预测中，他建立的PECOTA系统（PECOTA：“投手经验比对与优化测试算法”的首字母缩写）在2003年~2008年领先于其他预测系统；在选举预测中，他建立的538网站（取自选举人票的总票数538张）在2008年的美国总统竞选中，命中了总共50个州中的49个州。</p>

<p>在《信号与噪声》中，西尔弗对“预测”进行了全面的审视，书中对房市、选举、棒球、天气、地震、经济、传染病、NBA、国际象棋、扑克牌、股票、气候，甚至恐怖袭击等诸多方面的预测进行了分析，并提出了一套完整的预测框架。</p>

<p>虽然涉猎众广，且“预测”在一般意义上被认为是一个技术性的词汇，本书却并不是本“手把手”的操作书，而是一部方法论。</p>

<p>在绝大部分篇幅里，我们找不到任何的“鱼”：具体的预测技巧。相反，作者在一遍又一遍（上述13个领域构成了本书的13章）地教授“渔”：预测的目标怎么定，预测的质量有多高，影响的因素在哪里，改进的方法有什么。</p>

<h2 id="toc_38">一、前提假设</h2>

<p>既然是方法论，当然会有一个前提假设。本书假设的前提有三点：</p>

<ol>
<li>世界上存在着客观真理；</li>
<li>人类无法直接认识客观真理；</li>
<li>人类可以通过对自己观念的修正来不断地接近客观真理。</li>
</ol>

<h2 id="toc_39">二、前七章概述</h2>

<p>当然作者不是一开门就抛出这套理论，不然马上就会遭到异议。因为作者所提出的和我们——至少最近二三十年的几代——所接受的系统性的科学教育中隐含的本质是相悖的。我们接受的科学主义的核心是：通过科学可以认识世界——换个说法，即客观真理。</p>

<p>为了让读者能循序渐接受，全书的前七章实际上都在铺垫。简要罗列前七章主要领域的预测分析：</p>

<p>（注：理论指理论根基，模型指数据模型，数据指数据质量，预测指预测效果；另外差、中、好是我总结的，不代表作者观点）</p>

<ol>
<li>房市：理论差、模型差、数据差、人为影响大，预测差；</li>
<li>选举：理论中、模型中、数据中、人为影响大，预测差；</li>
<li>棒球：理论好、模型中、数据好、人为影响小，预测好；</li>
<li>天气：理论好、模型中、数据好、人为影响小，预测好；</li>
<li>地震：理论差、模型差、数据差、人为影响大、预测差；</li>
<li>经济：理论差、模型差、数据差、人为影响大、预测差；</li>
<li>传染病：理论差、模型差、数据中、人为影响大、预测差。</li>
</ol>

<p>实际上，“房市”和“经济”是同一类。</p>

<p>我们看到，预测基本是由“人”、“理论”、“数据”三者相互作用而产生的（下文我将它们称为“预测三要素”，当然此处也不代表作者观点）。好的预测需要“天时地利人和”：好的理论、好的模型、好的数据和减少人为影响同时作用。若一个元素不好，甚至每个元素都不好，预测的结果也不会好。</p>

<h2 id="toc_40">三、预测三要素：人</h2>

<p>之前不是说过作者的538网站在选举预测中大获成功吗？为什么选举预测总体上还是很差呢？</p>

<p>因为那只是个例。选举期间，真正面对广大受众的，在新闻、访谈、社论中出镜、执笔的专家们所做的预测，准确率是极低的。作者以广受欢迎的政治节目“麦克劳夫伦讨论小组”为例：小组成员的平均预测准确率是49%~52%，和掷硬币猜人头的概率相当。</p>

<p>“麦克劳夫伦讨论小组”中的成员可谓名副其实的“圈内人士”：他们来自《芝加哥论坛报》、《福克斯新闻》、《新闻周刊》，民调的数据也很容易获取，为什么他们的预测效果仍然不好呢？作者给出的答案是：立场。</p>

<p>保守派不会预测自由派当选，自由派也一样。更重要的是，有时预测者并不在意预测的结果，他们更在意过程——是否吸引了足够多的受众。于是他们的选择是：坚持观点，和加大嗓门坚持观点。</p>

<p>也就是说，预测者们专注于观点本身——无论对错——带来的影响力，而不关心结果如何。在现实中能被我们轻易识别出的，也正是那些站定派别后就不再换边的人。</p>

<p>但选举总会有结果，与此相比那些需要更长时间才能检验结果的领域，比如地震和经济预测上，在谋求影响力的推动下，不断产生“青蛙预测地震”或“橄榄球超级碗大赛冠军预测经济走势”这样的论调就不足为奇了。</p>

<p>回头再看，作者的538网站之所以能取得成功，仅仅因为西尔弗盯住民调作为主要指标——竞选级别越高，越接近最终大选，民调的结果就越稳定——而摒弃了人在其中的影响。</p>

<p>与此类似，棒球和天气之所以能取得成功，很大一部分原因也在于预测者们摒弃了个人的好恶，专注于从数据中挖掘证据。</p>

<h2 id="toc_41">四、预测三要素：理论</h2>

<p>但是，如果过于强调数据的作用，就会掉入“数据决定论”的陷阱。事实上，作者认为，在人、理论、数据这三者中，数据的重要性反而是最低的，一个正确的理论远胜于千万数据。</p>

<p>例如棒球。棒球运动中，几乎所有运动员的表现都能被量化，但正因为数据庞杂，如何选择合适的数据成了预测的关键。最好的理论需要的并不仅仅是棒球场上量化的数据：本垒打数、保送数——反映了球员现在的能力；也需要结合棒球场外无法量化的数据：态度、自信心——反映了球员未来的潜力。</p>

<p>再如天气。最开始的天气预测实际上是纯数据的：统计“历史上的今天”降水的平均概率。很显然我们都知道不能仅靠过去去预测未来：现在天气预测先将大气层划分为一块块的“网格”，并建立模型预测它们之间相互作用时对天气的变化和影响，精度取决于“网格”的密度。随着科学发展，和对气流、温度变化的持续研究——还有越来越强大的超级计算机的帮助，我们已经能够把大气的“网格”划分得越来越小。</p>

<p>而对于地震、传染病，正因为目前我们对它们的成因或传播方式的研究还有诸多盲点，所以目前的模型都有各自的局限，预测效果也不好。</p>

<h2 id="toc_42">五、预测三要素：数据</h2>

<p>虽然数据的顺位不如理论和人，但也是很重要的——经由理论建立的模型需要投入大量的数据才能运算。</p>

<p>但是数据也有自身的问题：太多了。在如今的信息社会，每天都会产出大量的数据，其中真实数据的产出速度远不如虚假、重复数据的产出速度——比如作为一个直观的案例，可以打开微博和朋友圈看看大多数信息的质量——也就是说，有用的信号太少，噪声太多。</p>

<p>这也是影响经济预测重要因素：美国政府每年公布的数据有4.5万个，而私人数据提供者甚至能追踪400万个不同的统计，其中真正能起到指标意义的数据，只有绝少的一部分。</p>

<h2 id="toc_43">六、预测的偏见</h2>

<p>预测需要一个好的理论，但好理论或坏理论都只有人才能建立。</p>

<p>模型结合了理论和数据，但对模型效果的检验需要更多的数据和——人的参与。</p>

<p>此外一些数据本身就是“偏见”的产物：比如棒球运动员的“自信心”，需要人——球探——依靠主观经验去量化。</p>

<p>我们能看到，在预测中“人”的影响无处不在，而人又是带有偏见的，所以大部分的预测难免会被偏见所影响。</p>

<h2 id="toc_44">七、预测的框架——贝叶斯定理</h2>

<p>前七章毕，我们眼前有两个问题：</p>

<ol>
<li>人、理论和数据都有各自的局限，如何组织它们？</li>
<li>预测难免带有人的偏见，有没有带着人的偏见也能作出好预测的方法？</li>
</ol>

<p>对此，作者提出了一套预测的框架——贝叶斯定理。在这里只简要介绍下如何应用贝叶斯定理：</p>

<ol>
<li>承认人在预测前就带有某种偏见。（举个例子，比如我发现前方蹲着一只生物，我想预测下它到底是什么，此时我有一个初始偏见：遇见一只未知生物时会先下意识地以为它是狗。）</li>
<li>将这种偏见表示为概率的形式。（称作“先验概率”，此时我对我的偏见进行主观量化，我认为该生物是狗的概率为60%）。</li>
<li>当更多事件发生时，分别计算出先验条件存在和不存在时相关事件发生的概率。（我听到了一声“汪”。假如它是狗，那么它发出“汪”的概率是99%——考虑到有些狗可能喜欢说外语，比如“喵”；若非狗，它“汪”的概率是0.5%——考虑到可能有某些大概会说外语的猫，和真能说外语的八哥）。</li>
<li>将先验概率用相关事件下的不同概率调整后，计算得到后验概率，这就是你对事件的预测（最终得到的“后验概率”中，我预测蹲着的生物是狗的可能性变成了99.69%）。</li>
<li>此时的“后验概率”就变成了你的“先验概率”。（也可以被看作是这件事对你的影响程度，比如我再往前走，遇到了另一只蹲着的生物，此时我的初始偏见就变成了：它是狗的可能性是99.69%）</li>
</ol>

<p>可以看到，应用贝叶斯定理时，即便带有初始偏见，只要经过足够多的事件，不断地检验和修正后，我们的偏见是可以被纠正到很低的水平的——也就是，无限地接近客观真理。</p>

<p>再看看贝叶斯定理下的预测三要素：人既是提供偏见——先验概率的，又是做出客观预测——后验概率的；一个好的理论能保证这一过程的顺利进行；数据——大量持续的数据——是使贝叶斯定理不断应用，后验概率逐渐接近客观真理的保障。</p>

<h2 id="toc_45">八、九至十三章</h2>

<p>最后几章主要是应用贝叶斯定理时需要注意的问题，归根结底还是人、理论和数据。</p>

<p>对于人的偏见问题、立场问题，作者几乎在每一章都苦口婆心地唠叨了一遍。例如股票市场中，为什么股票经纪人有没有预测到熊市都会坚持买入？因为他们的考核周期只有90天，而股市在90天内崩盘的可能性只有4%，无论熊市还是牛市，坚持买入对他们最有利。</p>

<p>对于理论，假如现有的模型失败了该怎么办？作者建议启用备用模型——一个合理的基准预测，比如选举预测中，备用的模型是选还在台上的那个。</p>

<p>对于数据，重要的是筛选出信号——有用的那个。我们都知道GDP在公布之后还会被不断被修正，可是你知道修正的范围有多大吗？1965~2009年美国政府修正过的季度GDP中，误差幅度为±4.3%——最初估计为超常增长的，实际上也有可能在衰退。原因在于GDP估值并没有一个公认准确的概率市场——类似于股市对股票的估值，虽然这也是不确切的——实际上大部分数据都如此，因此对于数据需要在应用中注意不断修正。</p>

<p>书中于此相关的论述颇多，就不加赘述了。</p>

<h2 id="toc_46">九、竞争的水位——预测得准还不够</h2>

<p>需要特别指出的是，在现实世界里，并不是掌握了贝叶斯定理，做几个准确的预测就能挣钱。例如在扑克牌领域，即便你的预测能达到95%的准确度，依然有可能输，因为顶尖玩家预测的准确度是99%。</p>

<p>在竞争性强的领域，特别是零和博弈的条件下，预测能力最差的玩家最终都会被淘汰。当那些准确度达到85%的玩家都因为亏损而离场后，准确度为86%的玩家就开始亏钱了，顺此而上，最终只有最顶尖的玩家才能生存。</p>

<p>如西尔弗所说：“竞争为人们设定了‘水位’，而个人的利润只是‘冰山一角’，漂浮在水面的仅仅是一小部分竞争优势，而隐蔽在水面下支持它的，是一个由汗水铸成的巨大堡垒。”</p>

<h2 id="toc_47">十、作者的终极理想</h2>

<p>作者的终极理想是，如果人人都用贝叶斯定理，那么世界大同将不是梦。</p>

<p>从表面上看这是合理的，因为不管大家一开始的想法有多大的差距，在严格遵循贝叶斯定理的框架时，经过对各自观念的长期、持续的修正后，最终都将收敛于一点。</p>

<p>但这里其实有一个问题，“不断修正”时需要大家都取相同或接近的概率，而在现实中并没有提供这一概率的公认市场。而让人们从各自的主观出发去估计这一概率——显然大家的估计都是不同的——难免会导致后验概率的不断震荡，最终自由派和保守派是很难收敛到一个点上去的。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204008705.html">
                
                  <h1>推荐系统实践</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<!-- MarkdownTOC -->

<ul>
<li>推荐系统评测

<ul>
<li>离线实验</li>
<li>评测指标</li>
<li>评测维度</li>
</ul></li>
<li>利用用户行为数据

<ul>
<li>基于用户的协同过滤算法</li>
<li>基于物品的协同过滤算法</li>
<li>UserCF 和 ItemCF 优缺点对比</li>
</ul></li>
<li>隐语义模型</li>
<li>基于图的模型</li>
<li>冷启动问题</li>
<li>利用用户标签数据

<ul>
<li>一个最简单的算法</li>
<li>改进：TF-IDF</li>
<li>改进：数据稀疏性</li>
<li>改进：标签清理</li>
<li>基于图的推荐算法</li>
<li>推荐标签</li>
</ul></li>
<li>利用上下文信息

<ul>
<li>物品的生存周期和系统的时效性</li>
<li>推荐系统的实时性</li>
<li>时间上下文推荐算法</li>
<li>地点上下文信息</li>
</ul></li>
<li>利用社交网络数据</li>
<li>推荐系统实例

<ul>
<li>外围架构</li>
<li>推荐系统架构</li>
<li>推荐引擎的架构

<ul>
<li>生成用户特征向量</li>
<li>特征-物品相关推荐</li>
<li>过滤模块</li>
<li>排名模块</li>
</ul></li>
</ul></li>
<li>评分预测</li>
<li>十条经验和教训</li>
</ul>

<!-- /MarkdownTOC -->

<hr/>

<p>推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式。</p>

<p>几乎所有的推荐系统应用都是由前台的展示页面、后台的日志系统以及推荐算法系统 3 部分构成的。</p>

<p>亚马逊推荐列表的组成部分：</p>

<ul>
<li>推荐结果的标题、缩略图以及其他内容属性</li>
<li>推荐结果的平均分</li>
<li>推荐理由</li>
</ul>

<p>基于物品的推荐系统还是比较流行的(Amazon, Netflix)</p>

<p>Pandora 背后的音乐推荐算法主要来自于一个叫做<strong>音乐基因工程</strong>的项目。</p>

<p>音乐推荐的特点：</p>

<ul>
<li>物品空间大(相对于书和电影而言)</li>
<li>消费每首歌代价很小</li>
<li>物品种类丰富</li>
<li>听一首歌耗时很少</li>
<li>物品重用率很高</li>
<li>用户充满激情</li>
<li>上下文相关(和心情，场景有关)</li>
<li>次序很重要</li>
<li>很多播放列表资源</li>
<li>不需要用户全神贯注</li>
<li>高度社会化</li>
</ul>

<h2 id="toc_0">推荐系统评测</h2>

<p>三个参与方：用户、物品提供者和提供推荐系统的网站，一个好的推荐系统是能够令三方共赢的系统。</p>

<h3 id="toc_1">离线实验</h3>

<ol>
<li>通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集</li>
<li>将数据集按照一定的规则分成训练集和测试集</li>
<li>在训练集上训练用户兴趣模型，在测试集上进行预测</li>
<li>通过事先定义的离线指标评测算法在测试集上的预测结果</li>
</ol>

<h3 id="toc_2">评测指标</h3>

<p><strong>用户满意度</strong></p>

<p>调查问卷，推荐结果的直接反馈按钮(豆瓣电台)</p>

<p><strong>预测准确度</strong></p>

<p>可以通过离线实验计算，分为不同的研究方向</p>

<ol>
<li><strong>评分预测</strong>。一般通过<code>均方根误差(RMSE)</code>和<code>平均绝对误差(MAE)</code>计算。Netflix 认为 RMSE 加大了对预测不准的用户物品评分的惩罚(平方)，因而对系统的评测更加苛刻。研究表明，如果评分系统是基于整数建立的(即用户给的评分都是整数)，那么对预测结果取整会降低 MAE 的误差</li>
<li><strong>TopN 预测</strong>。一般通过<code>准确率(precision)/召回率(recall)</code>度量。主要目的应该是找到用户最有可能感兴趣的电影，而不是预测用户看了电影会给多少分，所以 TopN 更符合实际的应用需求。</li>
<li><strong>覆盖率(coverage)</strong>。对物品长尾的发掘能力。有两个著名的指标可以用来定义覆盖率：<code>信息熵</code>和<code>基尼系数(Gini Index)</code>。推荐系统的初衷是消除马太效应，但是现在的主流推荐算法是具有马太效应的。</li>
<li><strong>多样性</strong>。描述了推荐列表中物品两两之间的不相似性。</li>
<li><strong>新颖性</strong>。给用户推荐那些他们以前没有听说过的物品。最简单的方法是利用推荐结果的平均流行度。困难的是如何在不牺牲精度的情况下提高多样性和新颖性。</li>
<li><strong>惊喜度(serendipity)</strong>。Guy Shani <q>Evaluatin Recommendation Systems</q> 如果推荐结果和用户的兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听过这个推荐结果。Yuan Cao Zhang <q>Auralist:introducing serendipity into music recommendation</q>, Tomoko Murakami <q>Metrics for evaluating the serendipity of recommendation lists</q></li>
<li><strong>信任度</strong>。只能通过问卷调查的方式。提高信任度主要有两种方法。首先增加透明度(transparency), Henriette Cramer <q>The effects of transparency on trust in and aceeptance of a content-based art recommender</q>，也就是提供推荐解释，了解推荐系统运行的机制。关于推荐系统信任度的研究主要集中在评论网站 Epinion 的推荐系统(Paolo Massa <q>Trust-aware recommender systems</q>)</li>
<li><strong>实时性</strong>。第一是满足用户新的行为变化，第二是将新加入系统的物品推荐给用户</li>
<li><strong>健壮性</strong>。抗击作弊的能力(Neil Hurley <q>Tutorial on Robustness of Recommender System</q>)。</li>
<li><strong>商业目标</strong>。</li>
</ol>

<h3 id="toc_3">评测维度</h3>

<ul>
<li>用户维度：主要包括用户的人口统计学信息、活跃度以及是不是新用户</li>
<li>物品维度：包括物品的属性信息、流行度、平均分以及是不是新加入的物品等</li>
<li>时间维度：包括季节，是工作日还是周末，是白天还是晚上</li>
</ul>

<h2 id="toc_4">利用用户行为数据</h2>

<p>用户行为：显性反馈行为(explicit feedback)和隐性反馈行为(implicit feedback)</p>

<p>很多数据分布都满足一种称为 Power Law 的分布(长尾分布)，Zipf 定律</p>

<h3 id="toc_5">基于用户的协同过滤算法</h3>

<p>主要包括两个步骤：</p>

<ol>
<li>找到和目标用户兴趣相似的用户集合</li>
<li>找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户</li>
</ol>

<p><img src="./_resources/rs1.jpg" alt="rs1"/></p>

<p>实践过程中用倒排表是比较快捷的方法。</p>

<p>一些注意事项：</p>

<ol>
<li>对于超级热门的书籍，并不能认为两个用户都买过就是兴趣相似。</li>
<li>两个用户对冷门物品采取过同样的行为更能说明他们兴趣的相似度。(John S. Breese <q>Empirical Analysis of Predictive Algorithms for Collaborative Filtering</q>)</li>
</ol>

<p>对于热度较高的物品需要一定的惩罚，一般是用 log</p>

<p><img src="./_resources/rs2.jpg" alt="rs2"/></p>

<h3 id="toc_6">基于物品的协同过滤算法</h3>

<p>业界基本使用这个(Linden Greg <q>Amazon.com Recommendations: Item-to-Item Collaborative Filtering</q>)</p>

<p>并不利用物品的内容属性计算物品之间的相似度，主要通过分析用户的行为记录物品之间的相似度。该算法认为，物品 A 和物品 B 具有很大的相似度是因为喜欢物品 A 的用户大都也喜欢物品 B。</p>

<p><img src="./_resources/rs3.jpg" alt="rs3"/></p>

<p>主要包括两个步骤：</p>

<ol>
<li>计算物品之间的相似度</li>
<li>根据物品的相似度和用户的历史行为给用户生成推荐列表</li>
</ol>

<p>但是如果其中一个物品很热门，那么得到的相似系数就会很大，所以分母需要开根号惩罚一下。</p>

<p><img src="./_resources/rs4.jpg" alt="rs4"/></p>

<p>用户活跃度问题，John S. Breese <q>Empirical Analysis of Predicitve Algorithms for Collaborative Filtering</q> 提出了一个称为 IUF(Inverse User Frequence)的参数，活跃用户对物品相似度的贡献应该小于不活跃的用户</p>

<p><img src="./_resources/rs5.jpg" alt="rs5"/></p>

<p>物品相似度的归一化，Karypis 在研究中发现如果将相似度矩阵按最大值归一化(George Karypis <q>Evaluation of Item-based Top-N Recommendation Algorithms</q>)</p>

<p><img src="./_resources/rs6.jpg" alt="rs6"/></p>

<h3 id="toc_7">UserCF 和 ItemCF 优缺点对比</h3>

<table>
<thead>
<tr>
<th>x</th>
<th>UserCF</th>
<th>ItemCF</th>
</tr>
</thead>

<tbody>
<tr>
<td>性能</td>
<td>适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大</td>
<td>适用于物品数明显小于用户数的场合，如果物品很多，计算物品相似度矩阵代价很大</td>
</tr>
<tr>
<td>领域</td>
<td>时效性较强，用户个性化兴趣不太明显的领域</td>
<td>长尾物品丰富，用户个性化需求强烈的领域</td>
</tr>
<tr>
<td>实时性</td>
<td>用户有新行为，不一定造成推荐结果立即变化</td>
<td>用户有新行为，一定会导致推荐结果的实时变化</td>
</tr>
<tr>
<td>冷启动</td>
<td>在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的</td>
<td>新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品</td>
</tr>
<tr>
<td>x</td>
<td>新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户</td>
<td>但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户</td>
</tr>
<tr>
<td>推荐理由</td>
<td>很难提供令用户信服的推荐解释</td>
<td>利用用户的历史行为给用户做推荐解释，可以令用户比较信服</td>
</tr>
</tbody>
</table>

<p><strong>哈利波特问题</strong></p>

<p><img src="./_resources/rs4.jpg" alt="rs4"/></p>

<p>对于太热门的物品分子仍然会非常接近热门书籍的热度，可以采用下面的方法</p>

<p><img src="./_resources/rs7.jpg" alt="rs7"/></p>

<h2 id="toc_8">隐语义模型</h2>

<p>相关名词：LFM(latnet factor model), LSI, pLSA, LDA, Topic Model。这些技术和方法本质上是相通的，其中很多方法都可以用于个性化推荐系统。</p>

<p>核心思想是通过隐含特征(latent factor)联系用户兴趣和物品，采取基于用户行为统计的自动聚类。</p>

<p><img src="./_resources/rs8.jpg" alt="rs8"/></p>

<p>找寻负样本时需要遵循以下原则：</p>

<ul>
<li>对每个用户，要保证正负样本的平衡(数目相似)</li>
<li>对每个用户采样负样本时，要选取那些很热门，用户却没有行为的物品</li>
</ul>

<p>一般认为，很热门而用户却没有行为更加代表用户对这个物品不感兴趣。因为对于冷门的物品，用户可能是压根没在网站中发现这个物品，所以谈不上是否感兴趣。</p>

<p><img src="./_resources/rs9.jpg" alt="rs9"/></p>

<p>LFM 模型在实际使用中有一个困难，就是很难实现实时的推荐。经典的 LFM 模型每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户隐类向量( p~u )和物品隐类向量( q~i )</p>

<p>LFM 是一种基于机器学习的方法，具有比较好的理论基础。这个方法和基于邻域的方法(比如 UserCF, ItemCF)相比，各有优缺点。</p>

<ul>
<li><strong>理论基础</strong> LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标建立最优的模型。基于邻域的方法更多的是一种基于统计的方法，并没有学习过程。</li>
<li><strong>离线计算的空间复杂度</strong> 基于邻域的方法需要维护一张离线的相关表。在离线计算相关表的过程中，如果用户/物品数很多，将会占据很大的内存。假设有 M 个用户和 N 个物品，在计算相关表的过程中，我们可能会获得一张比较稠密的临时相关表（尽管最终我们对每个物品只保留 K 个最相关的物品，但在中间计算过程中稠密的相关表是不可避免的），那么假设是用户相关表，则需要<code>O(M*M)</code>的空间，而对于物品相关表，则需要<code>O(N*N)</code>的空间。而LFM在建模过程中，如果是F个隐类，那么它需要的存储空间是<code>O(F*(M+N))</code>，这在M和N很大时可以很好地节省离线计算的内存。在Netflix Prize中，因为用户数很庞大（40多万），很少有人使用UserCF算法（据说需要30 GB左右的内存），而LFM由于大量节省了训练过程中的内存（只需要4 GB），从而成为Netflix Prize中最流行的算法。</li>
<li><strong>离线计算的时间复杂度</strong>　假设有 M 个用户、N 个物品、K条用户对物品的行为记录。那么，UserCF 计算用户相关表的时间复杂度是<code>O(N*(K/N)^2)</code>，而ItemCF计算物品相关表的时间复杂度是<code>O(M*(K/M)^2)</code>。而对于LFM，如果用F个隐类，迭代S次，那么它的计算复杂度是<code>O(K*F*S)</code>。那么，如果<code>K/N &gt; F*S</code>，则代表UserCF的时间复杂度低于LFM，如果 <code>K/M&gt;F*S</code>，则说明 ItemCF 的时间复杂度低于 LFM。在一般情况下，LFM 的时间复杂度要稍微高于 UserCF 和 ItemCF，这主要是因为该算法需要多次迭代。但总体上，这两种算法在时间复杂度上没有质的差别。</li>
<li><strong>在线实时推荐</strong>　UserCF 和 ItemCF 在线服务算法需要将相关表缓存在内存中，然后可以在线进行实时的预测。以 ItemCF 算法为例，一旦用户喜欢了新的物品，就可以通过查询内存中的相关表将和该物品相似的其他物品推荐给用户。因此，一旦用户有了新的行为，而且该行为被实时地记录到后台的数据库系统中，他的推荐列表就会发生变化。而从 LFM 的预测公式可以看到，LFM 在给用户生成推荐列表时，需要计算用户对所有物品的兴趣权重，然后排名，返回权重最大的 N 个物品。那么，在物品数很多时，这一过程的时间复杂度非常高，可达<code>O(M*N*F)</code>。因此，LFM 不太适合用于物品数非常庞大的系统，如果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用 LFM 重新排名。另一方面，LFM 在生成一个用户推荐列表时速度太慢，因此不能在线实时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中。因此，LFM不能进行在线实时推荐，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。</li>
<li><strong>推荐解释</strong>　ItemCF 算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。但 LFM 无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，却很难用自然语言描述并生成解释展现给用户。</li>
</ul>

<h2 id="toc_9">基于图的模型</h2>

<p>用户行为很容易用二分图表示，因此很多图的算法都可以用到推荐系统中。</p>

<p>基于图的模型（graph-based model）是推荐系统中的重要内容。其实，很多研究人员把基于邻域的模型也称为基于图的模型，因为可以把基于邻域的模型看做基于图的模型的简单形式。</p>

<p>令G(V,E)表示用户物品二分图，其中V=V~U ∪ V~I 由用户顶点集合 V~U 和物品顶点集合 V~I 组成。对于数据集中每一个二元组(u, i)，图中都有一套对应的边e(v~u ,v~i )，其中 v~u ∈ V~U 是用户 u 对应的顶点，v~i ∈ V~I 是物品 i 对应的顶点。下图是一个简单的用户物品二分图模型，其中圆形节点代表用户，方形节点代表物品，圆形节点和方形节点之间的边代表用户对物品的行为。比如图中用户节点A和物品节点a、b、d相连，说明用户A对物品a、b、d产生过行为。</p>

<p><img src="./_resources/rs10.jpg" alt="rs10"/></p>

<p>度量图中两个顶点之间相关性的方法很多，但一般来说图中顶点的相关性主要取决于下面3个因素：</p>

<ul>
<li>两个顶点之间的路径数；</li>
<li>两个顶点之间路径的长度；</li>
<li>两个顶点之间的路径经过的顶点。</li>
</ul>

<p>而相关性高的一对顶点一般具有如下特征：</p>

<ul>
<li>两个顶点之间有很多路径相连；</li>
<li>连接两个顶点之间的路径长度都比较短；</li>
<li>连接两个顶点之间的路径不会经过出度比较大的顶点。</li>
</ul>

<p>Fouss Francois <q>Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation</q></p>

<p>介绍一种基于随机游走的PersonalRank算法(Taher <q>Topic-Sensitive PageRank</q>)</p>

<p>假设要给用户 u 进行个性化推荐，可以从用户 u 对应的节点 v~u 开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率 α 决定是继续游走，还是停止这次游走并从 v 节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。</p>

<p><img src="./_resources/rs11.jpg" alt="rs11"/></p>

<p>但是计算量较大，有两种解决办法：减少迭代次数或者是从矩阵论出发重新设计算法，暂略</p>

<h2 id="toc_10">冷启动问题</h2>

<p>冷启动问题（cold start）主要分3类。</p>

<ul>
<li><strong>用户冷启动</strong>　用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣，从而无法借此给他做个性化推荐。</li>
<li><strong>物品冷启动</strong>　物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。</li>
<li><strong>系统冷启动</strong>　系统冷启动主要解决如何在一个新开发的网站上（还没有用户，也没有用户行为，只有一些物品的信息）设计个性化推荐系统，从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。</li>
</ul>

<p>对于这3种不同的冷启动问题，有不同的解决方案。一般来说，可以参考如下解决方案。</p>

<ul>
<li><strong>提供非个性化的推荐</strong>　非个性化推荐的最简单例子就是热门排行榜，我们可以给用户推荐热门排行榜，然后等到用户数据收集到一定的时候，再切换为个性化推荐。</li>
<li>利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。</li>
<li>利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。</li>
<li>要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。</li>
<li>对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。</li>
<li>在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。</li>
</ul>

<p>能够用来启动用户兴趣的物品需要具有以下特点：</p>

<ul>
<li><strong>比较热门</strong>　如果要让用户对一个物品进行反馈，前提是用户知道这个物品是什么东西。以电影为例，如果一开始让用户进行反馈的电影都很冷门，而用户不知道这些电影的情节和内容，也就无法对它们做出准确的反馈。</li>
<li><strong>具有代表性和区分性</strong>　启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性。还以电影为例，用一部票房很高且广受欢迎的电影做启动物品，可以想象的到的是几乎所有用户都会喜欢这部电影，因而无法区分用户个性化的兴趣。</li>
<li><strong>启动物品集合需要有多样性</strong>　在冷启动时，我们不知道用户的兴趣，而用户兴趣的可能性非常多，为了匹配多样的兴趣，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣。</li>
</ul>

<p>Nadav Golbandi在论文中探讨了选择启动物品的问题，提出可以用一个决策树解决这个问题(“Adaptive Bootstrapping of Recommender Systems Using Decision Trees”)</p>

<p>Nadav Golbandi 的算法首先会从所有用户中找到具有最高区分度的物品 i，然后将用户分成 3 类。然后在每类用户中再找到最具区分度的物品，然后将每一类用户又各自分为 3 类，也就是将总用户分成9类，然后这样继续下去，最终可以通过对一系列物品的看法将用户进行分类。而在冷启动时，我们从根节点开始询问用户对该节点物品的看法，然后根据用户的选择将用户放到不同的分枝，直到进入最后的叶子节点，此时我们就已经对用户的兴趣有了比较清楚的了解，从而可以开始对用户进行比较准确地个性化推荐。</p>

<p><img src="./_resources/rs12.jpg" alt="rs12"/></p>

<p>通过一个简单的例子解释Nadav Golbandi的算法。如图所示，假设通过分析用户数据，我们发现《变形金刚》最有区分度。而在喜欢《变形金刚》的用户中《钢铁侠》最有区分度，不知道《变形金刚》的用户中《阿甘正传》最有区分度，不喜欢《变形金刚》的用户中《泰坦尼克号》最有区分度。进一步分析，我们发现不喜欢《变形金刚》但喜欢《泰坦尼克号》的用户中，《人鬼情未了》最有区分度。那么，假设来了一个新用户，系统会首先询问他对《变形金刚》的看法，如果他说不喜欢，我们就会问他对《泰坦尼克》号的看法，如果他说喜欢，我们就会问他对《人鬼情未了》的看法，如果这个时候用户停止了反馈，我们也大概能知道该用户可能对爱情片比较感兴趣，对科幻片兴趣不大。</p>

<p>一般来说，物品的内容可以通过向量空间模型(Vector Space Model)表示，该模型会将物品表示成一个关键词向量。如果物品的内容是一些诸如导演、演员等实体的话，可以直接将这些实体作为关键词。但如果内容是文本的形式，则需要引入一些理解自然语言的技术抽取关键词。</p>

<p>向量空间模型在内容数据丰富时可以获得比较好的效果。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。</p>

<p>如何建立文章、话题和关键词的关系是话题模型（topic model）研究的重点。代表性的话题模型有LDA。</p>

<p>任何模型都有一个假设，LDA 作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。LDA 中有 3 种元素，即<strong>文档</strong>、<strong>话题</strong>和<strong>词语</strong>。每一篇文档都会表现为词的集合，这称为<strong>词袋模型(bag of words)</strong>。每个词在一篇文章中属于一个话题。令D为文档集合，<code>D[i]</code>是第 i 篇文档。<code>w[i][j]</code>是第 i 篇文档中的第 j 个词。<code>z[i][j]</code>是第 i 篇文档中第 j 个词属于的话题。</p>

<p>LDA 的计算过程包括初始化和迭代两部分。首先要对 z 进行初始化，而初始化的方法很简单，假设一共有 K 个话题，那么对第 i 篇文章中的第 j 个词，可以随机给它赋予一个话题。同时，用 NWZ(w,z)记录词 w 被赋予话题 z 的次数，NZD(z,d)记录文档 d 中被赋予话题 z 的词的个数。LDA可以很好地将词组合成不同的话题。</p>

<p>在使用 LDA 计算物品的内容相似度时，我们可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。计算分布的相似度可以利用 KL 散度</p>

<p><img src="./_resources/rs13.jpg" alt="rs13"/></p>

<h2 id="toc_11">利用用户标签数据</h2>

<p>标签系统的最大优势在于可以发挥群体的智能，获得对物品内容信息比较准确的关键词描述，而准确的内容信息是提升个性化推荐系统性能的重要资源。</p>

<p>打标签作为一种重要的用户行为，蕴含了很多用户兴趣信息，因此深入研究和利用用户打标签的行为可以很好地指导我们改进个性化推荐系统的推荐质量。同时，标签的表示形式非常简单，便于很多算法处理。标签系统中的推荐问题主要有以下两个。</p>

<ul>
<li>如何利用用户打标签的行为为其推荐物品（基于标签的推荐）？</li>
<li>如何在用户给物品打标签时为其推荐适合该物品的标签（标签推荐）？</li>
</ul>

<p>一个用户标签行为的数据集一般由一个三元组的集合表示，其中记录(u, i, b)表示用户 u 给物品 i 打上了标签 b。当然，用户的真实标签行为数据远远比三元组表示的要复杂，比如用户打标签的时间、用户的属性数据、物品的属性数据等。但是本章为了集中讨论标签数据，只考虑上面定义的三元组形式的数据，即用户的每一次打标签行为都用一个三元组（用户、物品、标签）表示。</p>

<h3 id="toc_12">一个最简单的算法</h3>

<p>拿到了用户标签行为数据，相信大家都可以想到一个最简单的个性化推荐算法。这个算法的描述如下所示。</p>

<ul>
<li>统计每个用户最常用的标签。</li>
<li>对于每个标签，统计被打过这个标签次数最多的物品。</li>
<li>对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。</li>
</ul>

<p>对于上面的算法，用户u对物品i的兴趣公式如下：</p>

<p><img src="./_resources/rs14.jpg" alt="rs14"/></p>

<p>这里，B(u)是用户 u 打过的标签集合，B(i)是物品i被打过的标签集合，n~u，b 是用户 u 打过标签 b 的次数，n~b，i 是物品 i 被打过标签 b 的次数。</p>

<h3 id="toc_13">改进：TF-IDF</h3>

<p>前面这个公式倾向于给热门标签对应的热门物品很大的权重，因此会造成推荐热门的物品给用户，从而降低推荐结果的新颖性。另外，这个公式利用用户的标签向量对用户兴趣建模，其中每个标签都是用户使用过的标签，而标签的权重是用户使用该标签的次数。这种建模方法的缺点是给热门标签过大的权重，从而不能反应用户个性化的兴趣。这里我们可以借鉴TF-IDF的思想，对这一公式进行改进：</p>

<p><img src="./_resources/rs15.jpg" alt="rs15"/></p>

<p>同理，我们也可以借鉴TF-IDF的思想对热门物品进行惩罚，从而得到如下公式：</p>

<p><img src="./_resources/rs16.jpg" alt="rs16"/></p>

<p>和TagBasedTFIDF算法相比，除了多样性有所下降，其他指标都有明显提高。这一结果表明，适当惩罚热门标签和热门物品，在增进推荐结果个性化的同时并不会降低推荐结果的离线精度。</p>

<h3 id="toc_14">改进：数据稀疏性</h3>

<p>在前面的算法中，用户兴趣和物品的联系是通过B(u)∩B(i)中的标签建立的。但是，对于新用户或者新物品，这个集合（B(u)∩B(i)）中的标签数量会很少。为了提高推荐的准确率，我们可能要对标签集合做扩展，比如若用户曾经用过“推荐系统”这个标签，我们可以将这个标签的相似标签也加入到用户标签集合中，比如“个性化”、“协同过滤”等标签。</p>

<p>进行标签扩展有很多方法，其中常用的有话题模型(topic model)，不过这里遵循简单的原则介绍一种基于邻域的方法。</p>

<p>标签扩展的本质是对每个标签找到和它相似的标签，也就是计算标签之间的相似度。最简单的相似度可以是同义词。如果有一个同义词词典，就可以根据这个词典进行标签扩展。如果没有这个词典，我们可以从数据中统计出标签的相似度。</p>

<p>如果认为同一个物品上的不同标签具有某种相似度，那么当两个标签同时出现在很多物品的标签集合中时，我们就可以认为这两个标签具有较大的相似度。对于标签b，令N(b)为有标签b的物品的集合，n~b，i 为给物品 i 打上标签 b 的用户数，我们可以通过如下余弦相似度公式计算标签 b 和标签 b&#39; 的相似度：</p>

<p><img src="./_resources/rs17.jpg" alt="rs17"/></p>

<p>进行标签扩展确实能够提高基于标签的物品推荐的准确率和召回率，但可能会稍微降低推荐结果的覆盖率和新颖度。</p>

<h3 id="toc_15">改进：标签清理</h3>

<p>不是所有标签都能反应用户的兴趣。同时，标签系统里经常出现词形不同、词义相同的标签。</p>

<p>标签清理的另一个重要意义在于将标签作为推荐解释。如果我们要把标签呈现给用户，将其作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意义的停止词或者表示情绪的词，其次这些推荐解释里不能包含很多意义相同的词语。</p>

<p>一般来说有如下标签清理方法：</p>

<ul>
<li>去除词频很高的停止词；</li>
<li>去除因词根不同造成的同义词，比如recommender system和recommendation system；</li>
<li>去除因分隔符造成的同义词，比如collaborative_filtering和collaborative-filtering。</li>
</ul>

<p>为了控制标签的质量，很多网站也采用了让用户进行反馈的思想，即让用户告诉系统某个标签是否合适。关于这方面的研究可以参考Grou-pLens的Shilad Wieland Sen同学的博士论文(Nurturing Tagging Communities)</p>

<h3 id="toc_16">基于图的推荐算法</h3>

<p>首先，我们需要将用户打标签的行为表示到一张图上。我们知道，图是由顶点、边和边上的权重组成的。而在用户标签数据集上，有 3 种不同的元素，即用户、物品和标签。因此，我们需要定义 3 种不同的顶点，即用户顶点、物品顶点和标签顶点。然后，如果我们得到一个表示用户 u 给物品 i 打了标签 b 的用户标签行为(u,i,b)，那么最自然的想法就是在图中增加 3 条边，首先需要在用户 u 对应的顶点v(u)和物品 i 对应的顶点v(i)之间增加一条边(如果这两个顶点已经有边相连，那么就应该将边的权重加1)，同理，在v(u)和v(b)之间需要增加一条边，v(i)和v(b)之间也需要边相连接。</p>

<p>在定义出用户—物品—标签图后，我们可以用 PersonalRank 算法计算所有物品节点相对于当前用户节点在图上的相关性，然后按照相关性从大到小的排序，给用户推荐排名最高的 N 个物品。</p>

<p>基于标签的推荐其最大好处是可以利用标签做推荐解释，这方面的代表性应用是豆瓣的个性化推荐系统。</p>

<p>豆瓣使用标签云组织推荐结果页面有很多好处，首先是提高了推荐结果的多样性。我们知道，一个用户的兴趣在长时间内是很广泛的，但在某一天却比较具体。因此，我们如果想在某一天击中用户当天的兴趣，是非常困难的。而豆瓣通过标签云，展示了用户的所有兴趣，然后让用户自己根据他今天的兴趣选择相关的标签，得到推荐结果，从而极大地提高了推荐结果的多样性，使得推荐结果更容易满足用户多样的兴趣。同时，标签云也提供了推荐解释功能。用户通过这个界面可以知道豆瓣给自己推荐的每一本书都是基于它认为自己对某个标签感兴趣。而对于每个标签，用户总能通过回忆自己之前的行为知道自己是否真的对这个标签感兴趣。我们知道，要让用户直观上感觉推荐结果有道理是很困难的，而豆瓣将推荐结果的可解释性拆分成了两部分，首先让用户觉得标签云是有道理的，然后让用户觉得从某个标签推荐出某本书也是有道理的。因为生成让用户觉得有道理的标签云比生成让用户觉得有道理的推荐图书更加简单，标签和书的关系就更容易让用户觉得有道理，从而让用户最终觉得推荐出来的书也是很有道理的。</p>

<p>同时，标签云也提供了推荐解释功能。用户通过这个界面可以知道豆瓣给自己推荐的每一本书都是基于它认为自己对某个标签感兴趣。而对于每个标签，用户总能通过回忆自己之前的行为知道自己是否真的对这个标签感兴趣。</p>

<p>我们知道，要让用户直观上感觉推荐结果有道理是很困难的，而豆瓣将推荐结果的可解释性拆分成了两部分，首先让用户觉得标签云是有道理的，然后让用户觉得从某个标签推荐出某本书也是有道理的。因为生成让用户觉得有道理的标签云比生成让用户觉得有道理的推荐图书更加简单，标签和书的关系就更容易让用户觉得有道理，从而让用户最终觉得推荐出来的书也是很有道理的。</p>

<p>Jesse Vig对基于标签的解释进行了深入研究(Tagsplanations: Explaining Recommendations Using Tags)。</p>

<p>Jesse Vig 将用户和物品之间的关系变成了用户对标签的兴趣(tag preference)和标签与物品的相关度(tag relevance)，然后作者用同一种推荐算法给用户推荐物品，但设计了4种标签解释的展示界面。</p>

<ul>
<li><strong>RelSort</strong>　对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣和标签与物品的相关度，但标签按照和物品的相关度排序。</li>
<li><strong>PrefSort</strong>　对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣和标签与物品的相关度，但标签按照用户的兴趣程度排序。</li>
<li><strong>RelOnly</strong>　对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了标签与物品的相关度，且标签按照和物品的相关度排序。</li>
<li><strong>PrefOnly</strong>　对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣程度，且标签按照用户的兴趣程度排序。</li>
</ul>

<p>作者询问了用户对4种不同推荐解释界面的总体满意度，结果显示PrefOnly &gt; RelSort &gt; PrefSort &gt; RelOnly。</p>

<ul>
<li>用户对标签的兴趣对帮助用户理解为什么给他推荐某个物品更有帮助</li>
<li>用户对标签的兴趣和物品标签的相关度对于帮助用户判定自己是否喜欢被推荐物品具有同样的作用</li>
<li>物品标签相关度对于帮助用户判定被推荐物品是否符合他当前的兴趣更有帮助</li>
<li>客观事实类标签相比主观感受类标签对用户更有作用</li>
</ul>

<h3 id="toc_17">推荐标签</h3>

<ul>
<li><strong>方便用户输入标签</strong>　让用户从键盘输入标签无疑会增加用户打标签的难度，这样很多用户不愿意给物品打标签，因此我们需要一个辅助工具来减小用户打标签的难度，从而提高用户打标签的参与度。</li>
<li><strong>提高标签质量</strong>　同一个语义不同的用户可能用不同的词语来表示。这些同义词会使标签的词表变得很庞大，而且会使计算相似度不太准确。而使用推荐标签时，我们可以对词表进行选择，首先保证词表不出现太多的同义词，同时保证出现的词都是一些比较热门的、有代表性的词。</li>
</ul>

<p>用户 u 给物品 i 打标签时，我们有很多方法可以给用户推荐和物品 i 相关的标签。比较简单的方法有 4 种。</p>

<ul>
<li>第 0 种方法就是给用户 u 推荐整个系统里最热门的标签(这里将这个算法称为PopularTags)。</li>
<li>第 1 种方法就是给用户 u 推荐物品 i 上最热门的标签(这里将这个算法称为ItemPopularTags)。</li>
<li>第 2 种方法是给用户 u 推荐他自己经常使用的标签(这里将这个算法称为UserPopularTags)。</li>
<li>第 3 种算法是前面两种的融合(这里记为HybridPopu-larTags)，该方法通过一个系数将上面的推荐结果线性加权，然后生成最终的推荐结果。

<ul>
<li>具体实现时，两个列表线性相加时都将两个列表按最大值做了归一化，这样的好处是便于控制两个列表对最终结果的影响，而不至于因为物品非常热门而淹没用户对推荐结果的影响，或者因为用户非常活跃而淹没物品对推荐结果的影响。</li>
</ul></li>
</ul>

<p>离线测试标准</p>

<p><img src="./_resources/rs18.jpg" alt="rs18"/></p>

<h2 id="toc_18">利用上下文信息</h2>

<p>关于上下文推荐的研究，可以参考 Alexander Tuzhilin 教授的一篇综述 Context Aware RecommenderSystems。</p>

<p>时间信息对用户兴趣的影响表现在以下几个方面：</p>

<ul>
<li><strong>用户兴趣是变化的</strong>　我们这里提到的用户兴趣变化是因为用户自身原因发生的变化。比如随着年龄的增长，用户小时候喜欢看动画片，长大了喜欢看文艺片。如果我们要准确预测用户现在的兴趣，就应该关注用户最近的行为，因为用户最近的行为最能体现他现在的兴趣。当然，考虑用户最近的兴趣只能针对渐变的用户兴趣，而对突变的用户兴趣很难起作用，比如用户突然中奖了。</li>
<li><strong>物品也是有生命周期的</strong>　一部电影刚上映的时候可能被很多人关注，但是经久不衰的电影是很少的，很多电影上映后不久就被人们淡忘了。此外，物品也可能受新闻事件的影响，比如一部已经被淡忘的电影会因为突然被某个新闻事件涉及而重新热门起来。因此，当我们决定在某个时刻给某个用户推荐某个物品时，需要考虑该物品在该时刻是否已经过时了。</li>
<li><strong>季节效应</strong>　季节效应主要反映了时间本身对用户兴趣的影响。比如人们夏天吃冰淇淋，冬天吃火锅，夏天穿T恤，冬天穿棉衣。当然，我们也不排除有特别癖好的人存在，但大部分用户都是遵循这个规律的。除此之外，节日也是一种季节效应：每年的圣诞节，人们都要去购物；每年的奥斯卡颁奖礼，人们都要关注电影。</li>
</ul>

<h3 id="toc_19">物品的生存周期和系统的时效性</h3>

<p>不同类型网站的物品具有不同的生命周期，比如新闻的生命周期很短，而电影的生命周期很长。我们可以用如下指标度量网站中物品的生命周期。</p>

<ul>
<li><strong>物品平均在线天数</strong>　如果一个物品在某天被至少一个用户产生过行为，就定义该物品在这一天在线。因此，我们可以通过物品的平均在线天数度量一类物品的生存周期。考虑到物品的平均在线天数和物品的流行度应该成正比，因此给定一个数据集，我们首先将物品按照流行度分成20份，然后计算每一类物品的平均在线天数。</li>
<li><strong>相隔T天系统物品流行度向量的平均相似度</strong>　取系统中相邻T天的两天，分别计算这两天的物品流行度，从而得到两个流行度向量。然后，计算这两个向量的余弦相似度，如果相似度大，说明系统的物品在相隔T天的时间内没有发生大的变化，从而说明系统的时效性不强，物品的平均在线时间较长。相反，如果相似度很小，说明系统中的物品在相隔T天的时间内发生了很大变化，从而说明系统的时效性很强，物品的平均在线时间很短。</li>
</ul>

<h3 id="toc_20">推荐系统的实时性</h3>

<p>用户兴趣是不断变化的，其变化体现在用户不断增加的新行为中。一个实时的推荐系统需要能够实时响应用户新的行为，让推荐列表不断变化，从而满足用户不断变化的兴趣。</p>

<p>实现推荐系统的实时性除了对用户行为的存取有实时性要求，还要求推荐算法本身具有实时性，而推荐算法本身的实时性意味着:</p>

<ul>
<li>实时推荐系统不能每天都给所有用户离线计算推荐结果，然后在线展示昨天计算出来的结果。所以，要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计算推荐列表。</li>
<li>推荐算法需要平衡考虑用户的近期行为和长期行为，即要让推荐列表反应出用户近期行为所体现的兴趣变化，又不能让推荐列表完全受用户近期行为的影响，要保证推荐列表对用户兴趣预测的延续性。</li>
</ul>

<p>推荐系统每天推荐结果的变化程度被定义为推荐系统的时间多样性。时间多样性高的推荐系统中用户会经常看到不同的推荐结果。</p>

<p>提高推荐结果的时间多样性需要分两步解决：首先，需要保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；其次，需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。</p>

<p>对于第一步，又可以分成两种情况进行分析。第一是从推荐系统的实时性角度分析。有些推荐系统会每天离线生成针对所有用户的推荐结果，然后在线直接将这些结果展示给用户。这种类型的系统显然无法做到在用户有了新行为后及时调整推荐结果。第二，即使是实时推荐系统，由于使用的算法不同，也具有不同的时间多样性。</p>

<p>对于不同算法的时间多样性，Neal Lathia博士在 Evaluating Collaborative Filtering Over Time 中进行了深入探讨</p>

<p>那么，如果用户没有行为，如何保证给用户的推荐结果具有一定的时间多样性呢？一般的思路有以下几种。</p>

<ul>
<li>在生成推荐结果时加入一定的随机性。比如从推荐列表前20个结果中随机挑选10个结果展示给用户，或者按照推荐物品的权重采样10个结果展示给用户。</li>
<li>记录用户每天看到的推荐结果，然后在每天给用户进行推荐时，对他前几天看到过很多次的推荐结果进行适当地降权。</li>
<li>每天给用户使用不同的推荐算法。可以设计很多推荐算法，比如协同过滤算法、内容过滤算法等，然后在每天用户访问推荐系统时随机挑选一种算法给他进行推荐。</li>
</ul>

<p>当然，时间多样性也不是绝对的。推荐系统需要首先保证推荐的精度，在此基础上适当地考虑时间多样性。在实际应用中需要通过多次的实验才能知道什么程度的时间多样性对系统是最好的。</p>

<h3 id="toc_21">时间上下文推荐算法</h3>

<p><strong>最近最热门</strong></p>

<p><img src="./_resources/rs19.jpg" alt="rs19"/></p>

<p><strong>时间上下文相关的 ItemCF 算法</strong></p>

<p>基于物品（item-based）的个性化推荐算法是商用推荐系统中应用最广泛的，从前面几章的讨论可以看到，该算法由两个核心部分构成：</p>

<ul>
<li>利用用户行为离线计算物品之间的相似度；</li>
<li>根据用户的历史行为和物品相似度矩阵，给用户做在线个性化推荐。</li>
</ul>

<p>时间信息在上面两个核心部分中都有重要的应用，这体现在两种时间效应上。</p>

<ul>
<li><strong>物品相似度</strong>　用户在相隔很短的时间内喜欢的物品具有更高相似度。以电影推荐为例，用户今天看的电影和用户昨天看的电影其相似度在统计意义上应该大于用户今天看的电影和用户一年前看的电影的相似度。</li>
<li><strong>在线推荐</strong>　用户近期行为相比用户很久之前的行为，更能体现用户现在的兴趣。因此在预测用户现在的兴趣时，应该加重用户近期行为的权重，优先给用户推荐那些和他近期喜欢的物品相似的物品。</li>
</ul>

<p>基于物品的协同过滤算法，它通过如下公式计算物品的相似度</p>

<p><img src="./_resources/rs20.jpg" alt="rs20"/></p>

<p>而在给用户u做推荐时，用户u对物品i的兴趣p(u,i)通过如下公式计算</p>

<p><img src="./_resources/rs21.jpg" alt="rs21"/></p>

<p>在得到时间信息（用户对物品产生行为的时间）后，我们可以通过如下公式改进相似度计算</p>

<p><img src="./_resources/rs22.jpg" alt="rs22"/></p>

<p>除了考虑时间信息对相关表的影响，我们也应该考虑时间信息对预测公式的影响。一般来说，用户现在的行为应该和用户最近的行为关系更大。因此，我们可以通过如下方式修正预测公式</p>

<p><img src="./_resources/rs23.jpg" alt="rs23"/></p>

<p><strong>时间上下文相关的 UserCF 算法</strong></p>

<p>和 ItemCF 算法一样，UserCF 算法同样可以利用时间信息提高预测的准确率。首先，回顾一下前面关于 UserCF 算法的基本思想：给用户推荐和他兴趣相似的其他用户喜欢的物品。从这个基本思想出发，我们可以在以下两个方面利用时间信息改进 UserCF 算法。</p>

<ul>
<li><strong>用户兴趣相似度</strong>　两个用户兴趣相似是因为他们喜欢相同的物品，或者对相同的物品产生过行为。但是，如果两个用户同时喜欢相同的物品，那么这两个用户应该有更大的兴趣相似度。</li>
<li><strong>相似兴趣用户的最近行为</strong>　在找到和当前用户 u 兴趣相似的一组用户后，这组用户最近的兴趣显然相比这组用户很久之前的兴趣更加接近用户 u 今天的兴趣。也就是说，我们应该给用户推荐和他兴趣相似的用户最近喜欢的物品。</li>
</ul>

<p>UserCF通过如下公式计算用户u和用户v的兴趣相似度：</p>

<p><img src="./_resources/rs24.jpg" alt="rs24"/></p>

<p>上面公式的分子对于用户 u 和用户 v 共同喜欢的物品 i 增加了一个时间衰减因子。用户 u 和用户 v 对物品 i 产生行为的时间越远，那么这两个用户的兴趣相似度就会越小。</p>

<p>在得到用户相似度后，UserCF通过如下公式预测用户对物品的兴趣：</p>

<p><img src="./_resources/rs25.jpg" alt="rs25"/></p>

<p>如果考虑和用户u兴趣相似用户的最近兴趣，我们可以设计如下公式：</p>

<p><img src="./_resources/rs26.jpg" alt="rs26"/></p>

<h3 id="toc_22">地点上下文信息</h3>

<p>除了时间，地点作为一种重要的空间特征，也是一种重要的上下文信息。不同地区的用户兴趣有所不同，用户到了不同的地方，兴趣也会有所不同。</p>

<h2 id="toc_23">利用社交网络数据</h2>

<p><strong>获取社交网络数据的途径</strong></p>

<ul>
<li>电子邮件</li>
<li>用户注册信息</li>
<li>用户的位置数据</li>
<li>论坛和讨论组</li>
<li>即时聊天工具</li>
<li>社交网站(Facebook, Twitter)</li>
</ul>

<p>以Facebook为代表的社交网络称为<strong>社交图谱(social graph)</strong>，而以Twitter为代表的社交网络称为<strong>兴趣图谱(interest graph)</strong>。</p>

<p>社交网络定义了用户之间的联系，因此可以用图定义社交网络。我们用图G(V,E,w)定义一个社交网络，其中V是顶点集合，每个顶点代表一个用户，E是边集合，如果用户va和vb有社交网络关系，那么就有一条边e(va,vb)连接这两个用户，而w(va,vb)定义了边的权重。业界有两种著名的社交网络。一种以Facebook为代表，它的朋友关系是需要双向确认的，因此在这种社交网络上可以用无向边连接有社交网络关系的用户。另一种以Twitter为代表，它的朋友关系是单向的，因此可以用有向边代表这种社交网络上的用户关系。</p>

<p>此外，对图G中的用户顶点u，定义out(u)为顶点u指向的顶点集合(如果套用微博中的术语，out(u)就是用户u关注的用户集合)，定义in(u)为指向顶点u的顶点集合(也就是关注用户u的用户集合)。那么，在Facebook这种无向社交网络中显然有out(u)=in(u)。</p>

<p>一般来说，有 3 种不同的社交网络数据。</p>

<ul>
<li><strong>双向确认的社交网络数据</strong>　在以 Facebook 和人人网为代表的社交网络中，用户 A 和 B 之间形成好友关系需要通过双方的确认。因此，这种社交网络一般可以通过无向图表示。</li>
<li><strong>单向关注的社交网络数据</strong>　在以 Twitter 和新浪微博为代表的社交网络中，用户 A 可以关注用户 B 而不需要得到用户 B 的允许，因此这种社交网络中的用户关系是单向的，可以通过有向图表示。</li>
<li><strong>基于社区的社交网络数据</strong>　还有一种社交网络数据，用户之间并没有明确的关系，但是这种数据包含了用户属于不同社区的数据。比如豆瓣小组，属于同一个小组可能代表了用户兴趣的相似性。或者在论文数据集中，同一篇文章的不同作者也存在着一定的社交关系。或者是在同一家公司工作的人，或是同一个学校毕业的人等。</li>
</ul>

<p>社会化推荐之所以受到很多网站的重视，是缘于如下优点：</p>

<ul>
<li><strong>好友推荐可以增加推荐的信任度</strong>　好友往往是用户最信任的。用户往往不一定信任计算机的智能，但会信任好朋友的推荐。同样是给用户推荐《天龙八部》，前面提到的基于物品的协同过滤算法会说是因为用户之前看过《射雕英雄传》，而好友推荐会说是因为用户有 8 个好友都非常喜欢《天龙八部》。对比这两种解释，第二种解释一般能让用户更加心动，从而购买或者观看《天龙八部》。</li>
<li><strong>社交网络可以解决冷启动问题</strong>　当一个新用户通过微博或者 Facebook 账号登录网站时，我们可以从社交网站中获取用户的好友列表，然后给用户推荐好友在网站上喜欢的物品。从而我们可以在没有用户行为记录时就给用户提供较高质量的推荐结果，部分解决了推荐系统的冷启动问题。</li>
</ul>

<p>如果将Twitter的架构搬到社会化推荐系统中，我们就可以按照如下方式设计系统：</p>

<ul>
<li>首先，为每个用户维护一个消息队列，用于存储他的推荐列表；</li>
<li>当一个用户喜欢一个物品时，就将（物品ID、用户ID和时间）这条记录写入关注该用户的推荐列表消息队列中；</li>
<li>当用户访问推荐系统时，读出他的推荐列表消息队列，对于这个消息队列中的每个物品，重新计算该物品的权重。计算权重时需要考虑物品在队列中出现的次数，物品对应的用户和当前用户的熟悉程度、物品的时间戳。同时，计算出每个物品被哪些好友喜欢过，用这些好友作为物品的推荐解释。</li>
</ul>

<p>关于社会化推荐系统的离线评测可以参考Georg Groh和Christian Ehmig的工作成果(Recommendations in Taste Related Domains: Collaborative Filtering vs. Social Filtering)。不过社会化推荐系统的效果往往很难通过离线实验评测，因为社会化推荐的优势不在于增加预测准确度，而是在于通过用户的好友增加用户对推荐结果的信任度，从而让用户单击那些很冷门的推荐结果。此外，很多社交网站（特别是基于社交图谱的社交网站）中具有好友关系的用户并不一定有相似的兴趣。因此，利用好友关系有时并不能增加离线评测的准确率和召回率。因此，很多研究人员利用用户调查和在线实验的方式评测社会化推荐系统。</p>

<p>社交网络研究中有两个最著名的问题。第一个是如何度量人的重要性，也就是社交网络顶点的中心度(centrality)，第二个问题是如何度量社交网络中人和人之间的关系，也就是链接预测。这两个问题的研究都有着深刻的实际意义，因此得到了业界和学术界的广泛关注。对这两个问题感兴趣的读者可以参考社交网络分析方面的书<Social Network Analysis: Methods and Applications> <Social Network Analysis: A Handbook></p>

<p>对于基于社交网络的推荐算法，因为数据集的限制，最早的研究都是基于Epinion的用户信任网络的。Ma Hao 在 Epinion 数据集上提出了很多基于矩阵分解的社会化推荐算法用来解决评分预测问题(SoRec: Social Recommendation Using Probabilistic Matrix Factorization)，其主要思想是在矩阵分解模型中加入正则化项，让具有社交关系的用户的隐语义向量具有比较高的相似度。</p>

<h2 id="toc_24">推荐系统实例</h2>

<h3 id="toc_25">外围架构</h3>

<p>推荐系统要发挥强大的作用，除了推荐系统本身，主要还依赖于两个条件——界面展示和用户行为数据。不过，如果我们看看目前流行的推荐系统界面，可以看到这些界面都有一些共性。</p>

<ul>
<li>通过一定方式展示物品，主要包括物品的标题、缩略图和介绍等。</li>
<li>很多推荐界面都提供了推荐理由，理由可以增加用户对推荐结果的信任度。</li>
<li>推荐界面还需要提供一些按钮让用户对推荐结果进行反馈，这样才能让推荐算法不断改善用户的个性化推荐体验。</li>
</ul>

<p><strong>数据收集和存储</strong></p>

<p>个性化推荐算法依赖于用户行为数据，而在任何一个网站中都存在着各种各样的用户行为数据。那么如何存取这些数据就是推荐系统需要解决的首要问题。</p>

<p>一般来说，需要实时存取的数据存储在数据库和缓存中，而大规模的非实时地存取数据存储在分布式文件系统（如HDFS）中。</p>

<p>数据能否实时存取在推荐系统中非常重要，因为推荐系统的实时性主要依赖于能否实时拿到用户的新行为。只有快速拿到大量用户的新行为，推荐系统才能够实时地适应用户当前的需求，给用户进行实时推荐。</p>

<h3 id="toc_26">推荐系统架构</h3>

<p><img src="./_resources/rs28.jpg" alt="rs28"/></p>

<p>推荐系统需要由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回</p>

<p><img src="./_resources/rs27.jpg" alt="rs27"/></p>

<p>这样做还有两个好处。</p>

<ul>
<li>可以方便地增加/删除引擎，控制不同引擎对推荐结果的影响。对于绝大多数需求，只需要通过不同的引擎组合实现。</li>
<li>可以实现推荐引擎级别的用户反馈。每一个推荐引擎其实代表了一种推荐策略，而不同的用户可能喜欢不同的推荐策略。有些用户可能喜欢利用他的年龄性别作出的推荐，有些用户可能比较喜欢看到新加入的和他兴趣相关的视频，有些用户喜欢比较新颖的推荐，有些用户喜欢专注于一个邻域的推荐，有些用户喜欢多样的推荐。我们可以将每一种策略都设计成一个推荐引擎，然后通过分析用户对推荐结果的反馈了解用户比较喜欢哪些引擎推荐出来的结果，从而对不同的用户给出不同的引擎组合权重。</li>
</ul>

<h3 id="toc_27">推荐引擎的架构</h3>

<p><img src="./_resources/rs29.jpg" alt="rs29"/></p>

<p>部分 A 负责从数据库或者缓存中拿到用户行为数据，通过分析不同行为，生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。</p>

<p>部分 B 负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。</p>

<p>部分 C 负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。</p>

<h4 id="toc_28">生成用户特征向量</h4>

<p>一般来说，用户的特征包括两种，一种是用户的注册信息中可以提取出来的，主要包括用户的人口统计学特征。对于使用这种特征的推荐引擎，如果内存够，可以将存储这些特征的信息直接缓存在内存中，在推荐时直接拿到用户的特征数据并生成特征向量。除了这种特征，另一种特征主要是从用户的行为中计算出来的，本节着重讨论如何生成特征。</p>

<p>一个特征向量由特征以及特征的权重组成，在利用用户行为计算特征向量时需要考虑以下因素。</p>

<ul>
<li><strong>用户行为的种类</strong>　在一个网站中，用户可以对物品产生很多不同种类的行为。用户可以浏览物品、单击物品的链接、收藏物品、给物品打分、购买物品、评论物品、给物品打上不同的标签、和好友分享物品、搜索不同的关键词等。这些行为都会对物品特征的权重产生影响，但不同行为的影响不同，大多时候很难确定什么行为更加重要，一般的标准就是用户付出代价越大的行为权重越高。</li>
<li><strong>用户行为产生的时间</strong>　一般来说，用户近期的行为比较重要，而用户很久之前的行为相对比较次要。因此，如果用户最近购买过某一个物品，那么这个物品对应的特征将会具有比较高的权重。</li>
<li><strong>用户行为的次数</strong>　有时用户对一个物品会产生很多次行为。比如用户会听一首歌很多次，看一部电视剧的很多集等。因此用户对同一个物品的同一种行为发生的次数也反映了用户对物品的兴趣，行为次数多的物品对应的特征权重越高。</li>
<li><strong>物品的热门程度</strong>　如果用户对一个很热门的物品产生了行为，往往不能代表用户的个性，因为用户可能是在跟风，可能对该物品并没有太大兴趣，特别是在用户对一个热门物品产生了偶尔几次不重要的行为（比如浏览行为）时，就更说明用户对这个物品可能没有什么兴趣，可能只是因为这个物品的链接到处都是，很容易点到而已。反之，如果用户对一个不热门的物品产生了行为，就说明了用户的个性需求。因此，推荐引擎在生成用户特征时会加重不热门物品对应的特征的权重。</li>
</ul>

<h4 id="toc_29">特征-物品相关推荐</h4>

<p>从上面的架构图可以看到，特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。它的应用场合一般是产品需求希望将某些类型的电视剧推荐给用户。比如有些产品要求给用户推荐最近一周加入的新物品，那么候选物品集合就包括最近一周新加的物品。</p>

<p>也许有读者会奇怪，为什么不在过滤模块中将候选集合外的电视剧过滤掉，而要在相关推荐模块中处理候选物品列表？这里举一个简单的例子说明原因。首先，一般来说对于协同过滤算法计算出的相关表，每个物品都会倾向于和比较热门的物品具有较高的相似度。那么假设用户购买过物品A，候选列表中包含了物品B，A和B相关，但A比B热门。那么，一般情况下，B在A的相关物品列表中会排在靠后的位置(假设排在第10名)，而A在B的相关物品列表中会排在靠前的位置(假设排在第1名)。那么，如果推荐算法是给用户推荐和A最相关的5部电视剧，那么B就不会出现在用户的推荐列表中。但是，如果算法在给定候选列表时会用一种不同的方式进行推荐，比如如果用户看过和B最相关的5部电视剧中的某一部，就将B推荐给用户，那么这种情况下B就出现在推荐列表中了。</p>

<p>除此之外，还需要给用户返回物品推荐列表中每个推荐结果的解释列表，表明这个物品是因为哪些特征推荐出来的。</p>

<h4 id="toc_30">过滤模块</h4>

<p>在得到初步的推荐列表后，还不能把这个列表展现给用户，首先需要按照产品需求对结果进行过滤，过滤掉那些不符合要求的物品。一般来说，过滤模块会过滤掉以下物品。</p>

<ul>
<li><strong>用户已经产生过行为物品</strong>　因为推荐系统的目的是帮助用户发现物品，因此没必要给用户推荐他已经知道的物品，这样可以保证推荐结果的新颖性。</li>
<li><strong>候选物品以外的物品</strong>　候选物品集合一般有两个来源，一个是产品需求。比如在首页可能要求将新加入的物品推荐给用户，因此需要在过滤模块中过滤掉不满足这一条件的物品。另一个来源是用户自己的选择，比如用户选择了某一个价格区间，只希望看到这个价格区间内的物品，那么过滤模块需要过滤掉不满足用户需求的物品。</li>
<li><strong>某些质量很差的物品</strong>　为了提高用户的体验，推荐系统需要给用户推荐质量好的物品，那么对于一些绝大多数用户评论都很差的物品，推荐系统需要过滤掉。这种过滤一般以用户的历史评分为依据，比如过滤掉平均分在2分以下的物品。</li>
</ul>

<h4 id="toc_31">排名模块</h4>

<p>经过过滤后的推荐结果直接展示给用户一般也没有问题，但如果对它们进行一些排名，则可以更好地提升用户满意度，一般排名模块需要包括很多不同的子模块，下面将对不同的模块分别加以介绍。</p>

<p><strong>新颖性</strong></p>

<p>新颖性排名模块的目的是给用户尽量推荐他们不知道的、长尾中的物品。虽然前面的过滤模块已经过滤掉了用户曾经有过行为的物品，保证了一定程度的新颖性，但是用户在当前网站对某个物品没有行为并不代表用户不知道这个物品，比如用户可能已经在别的途径知道这个物品了。</p>

<p>要准确了解用户是否已经知道某个物品是非常困难的，因此我们只能通过某种近似的方式知道，比如对推荐结果中热门的物品进行降权，比如使用如下公式：</p>

<p><img src="./_resources/rs30.jpg" alt="rs30"/></p>

<p>不过，要实现推荐结果的新颖性，仅仅在最后对热门物品进行降权是不够的，而应在推荐引擎的各个部分考虑新颖性问题。</p>

<p>本章提到的推荐系统架构主要是基于物品的推荐算法的，因此可以回顾一下基于物品的推荐算法的基本公式</p>

<p><img src="./_resources/rs31.jpg" alt="rs31"/></p>

<p><img src="./_resources/rs32.jpg" alt="rs32"/></p>

<p>如果用户喜欢一个热门的物品，ItemCF算法也很难给他推荐一个冷门的物品。因此可以做如下的设计。首先，考虑到推荐系统是为了给用户介绍他们不熟悉的物品，那么可以假设如果用户知道了物品j，对物品j产生过行为，那么和j相似的且比j热门的物品用户应该也有比较大的概率知道，因此可以降低这种物品的权重，比如：</p>

<p><img src="./_resources/rs33.jpg" alt="rs33"/></p>

<p>此外，也可以引入内容相似度矩阵，因为内容相似度矩阵中和每个物品相似的物品都不是很热门，所以引入内容相似度矩阵也能够提高最终推荐结果的新颖度。利用上面几种考虑新颖性的方法，我们可以通过控制参数α控制最终推荐结果的新颖度。</p>

<p><strong>多样性</strong></p>

<p>多样性也是推荐系统的重要指标之一。增加多样性可以让推荐结果覆盖尽可能多的用户兴趣。当然，这里需要指出的是提高多样性并不是时时刻刻都很好。比如在个性化网络电台中，因为用户某一固定时刻的兴趣是固定的，所以不希望听到不同曲风的歌曲，尽管这些曲风可能都是用户之前表示喜欢的。不过，本节主要讨论如果要提高多样性，应该怎么提高。</p>

<p>第一种提高多样性的方法是将推荐结果按照某种物品的内容属性分成几类，然后在每个类中都选择该类中排名最高的物品组合成最终的推荐列表。比如，如果是电影，可以按照电影的类别（爱情片、动作片、科幻片等）对推荐结果中的电影分类，然后每种类别都选出几部电影组成最终的推荐结果。</p>

<p>这种方法的好处是比较简单直观，但这种方法也有严重的缺点。首先，选择什么样的内容属性进行分类对结果的影响很大。其次，就算选择了某种类别，但物品是否属于某个类别是编辑确定的，并不一定能够得到用户的公认。比如成龙的电影，有人认为是功夫片，有人认为是喜剧片，不同人看法不一。</p>

<p>因此，第二种提高推荐结果多样性的方法是控制不同推荐结果的推荐理由出现的次数。本章提出的推荐系统对于每个推荐出来的物品都有一个推荐理由，这个推荐理由一般是产生推荐结果的重要特征。那么，要提高推荐结果的多样性，就需要让推荐结果尽量来自不同的特征，具有不同的推荐理由，而不是所有的推荐结果都对应一个理由。</p>

<p><strong>时间多样性</strong></p>

<p>时间多样性主要是为了保证用户不要每天来推荐系统都看到同样的推荐结果。首先要保证推荐系统的实时性，在用户有新行为时实时调整推荐结果以满足用户最近的需求。这一点，在本章的推荐系统设计中已经考虑到了。如果用户有实时行为发生，那么行为提取和分析模块就能实时拿到行为数据并转化为新的特征，然后经过特征-物品相关模块转换成和新特征最相关的物品，因而推荐列表中就立即反应了用户最新行为的影响。提高推荐结果多样性的第二个方面是要在用户没有新的行为时，也要保证推荐结果每天都有变化。要实现这一点，只能通过如下方式。</p>

<ul>
<li>记录用户每次登陆推荐系统看到的推荐结果。</li>
<li>将这些结果发回日志系统。这种数据不需要实时存储，只要能保证小于一天的延时就足够了。</li>
<li>在用户登录时拿到用户昨天及之前看过的推荐结果列表，从当前推荐结果中将用户已经看到的推荐结果降权。</li>
</ul>

<p><strong>用户反馈</strong></p>

<p>排名模块最重要的部分就是用户反馈模块。用户反馈模块主要通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。</p>

<p>如果推荐系统的目标是提高用户对推荐结果的点击率，那么可以利用点击模型（click model）预测用户是否会点击推荐结果。点击模型在很多领域得到了广泛应用，比如搜索结果的点击预测、搜索广告的点击预测、上下文广告的点击预测。点击预测的主要问题是预测用户看到某个推荐结果时是否会点击。那么要进行点击率预测，首先需要提取特征。在推荐系统的点击率预测中可以用如下特征预测用户u会不会点击物品i：</p>

<ul>
<li>用户u相关的特征，比如年龄、性别、活跃程度、之前有没有点击行为；</li>
<li>物品i相关的特征，比如流行度，平均分，内容属性；</li>
<li>物品i在推荐列表中的位置。用户的点击和用户界面的设计有很高的相关性，因此物品i在推荐列表中的位置对预测用户是否点击很重要；</li>
<li>用户之前是否点击过和推荐物品i具有同样推荐解释的其他推荐结果；</li>
<li>用户之前是否点击过和推荐物品i来自同样推荐引擎的其他推荐结果。</li>
</ul>

<p>MyMedia是一个比较著名的开源推荐系统架构。它是由欧洲研究人员开发的一个推荐系统开源框架。该框架同时支持评分预测和TopN推荐，全面支持各种数据和各种算法，对该项目感兴趣的用户可以访问该项目的网站<a href="http://www.mymediapro-ject.org/default.aspx%E3%80%82">http://www.mymediapro-ject.org/default.aspx。</a></p>

<p>本章提出的推荐系统架构基本上是从基于物品的推荐算法衍生出来的，因此本章的架构并不适合用来解决社会化推荐问题。如果要了解社会化推荐方面的架构，可以参考Twitter公开的一些文档。</p>

<h2 id="toc_32">评分预测</h2>

<p>这一部分因为涉及不多，暂时略过</p>

<h2 id="toc_33">十条经验和教训</h2>

<ol>
<li>确定你真的需要推荐系统。推荐系统只有在用户遇到信息过载时才必要。如果你的网站物品不太多，或者用户兴趣都比较单一，那么也许并不需要推荐系统。所以不要纠结于推荐系统这个词，不要为了做推荐系统而做推荐系统，而是应该从用户的角度出发，设计出能够真正帮助用户发现内容的系统，无论这个系统算法是否复杂，只要能够真正帮助用户，就是一个好的系统。</li>
<li>确定商业目标和用户满意度之间的关系。对用户好的推荐系统不代表商业上有用的推荐系统，因此要首先确定用户满意的推荐系统和商业上需求的差距。一般来说，有些时候用户满意和商业需求并不吻合。但是一般情况下，用户满意度总是符合企业的长期利益，因此这一条的主要观点是要平衡企业的长期利益和短期利益之间的关系。</li>
<li>选择合适的开发人员。一般来说，如果是一家大公司，应该雇用自己的开发人员来专门进行推荐系统的开发。</li>
<li>忘记冷启动的问题。不断地创新，互联网上有任何你想要的数据。只要用户喜欢你的产品，他们就会不断贡献新的数据。</li>
<li>平衡数据和算法之间的关系。使用正确的用户数据对推荐系统至关重要。对用户行为数据的深刻理解是设计好推荐系统的必要条件，因此分析数据是设计系统中最重要的部分。数据分析决定了如何设计模型，而算法只是决定了最终如何优化模型。</li>
<li>找到相关的物品很容易，但是何时以何种方式将它们展现给用户是很困难的。不要为了推荐而推荐。</li>
<li>不要浪费时间计算相似兴趣的用户，可以直接利用社会网络数据。</li>
<li>需要不断地提升算法的扩展性。</li>
<li>选择合适的用户反馈方式。</li>
<li>设计合理的评测系统，时刻关注推荐系统各方面的性能。</li>
</ol>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204008526.html">
                
                  <h1>集体智慧编程 笔记</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>这本书主要是大概浏览一下相关领域的基本应用，方便以后遇到类似问题至少知道怎么开始</p>

<h3 id="toc_0">列表推导式 list comprehension</h3>

<p>一种方便简洁的语法形式</p>

<pre><code>[表达式 for 变量 in 列表]
or
[表达式 for 变量 in 列表 if 条件]

l=[1,2,3,4,5,6,7,8,9]
print [v*10 for v in l if v&gt;4]
timesten=dict([(v,v*10) for v in l])
</code></pre>

<h2 id="toc_1">导言</h2>

<ul>
<li>利用开放的 API 搜集数据 + 机器学习算法和统计方法 = 借助集体智慧的相关方法</li>
<li>所有机器算法都有过度归纳的可能性</li>
</ul>

<h2 id="toc_2">提供推荐 Making Recommendations</h2>

<ul>
<li>如何根据群体偏好来为人们提供推荐</li>
<li>两条相似度评判体系：欧几里得距离和皮尔逊相关度</li>
<li>皮尔逊方法修正了“夸大分值(grade inflation)”的情况。如果某人总是倾向于给出比另一个人更高的分值，而二者的分值之差又始终保持一致，则他们依然可能会存在很好的相关性。

<ul>
<li>首先找出两位评论者都曾评价过的物品，然后计算两者的评分总和与平方和，并求得评分的乘积之和，最后利用这些计算出皮尔逊相关系数</li>
</ul></li>
<li>如何找到商品之间的近似关系</li>
<li>与前面类似，不过人与物品的关系对调</li>
<li>以上都是基于用户的协作型过滤(user-based collabonative filtering)</li>
</ul>

<p>另一种是基于物品的协作型过滤(item-based collaborative filtering)，总体思路是为每件物品预先计算好最为相近的其他物品。然后，当我们想为某位用户提供推荐时，就可以查看他曾经评过分的物品，并从中选出排位靠前者，再构造出一个加权列表，其中包含了与这些选中物品最为相近的其他物品。尽管第一步要求我们检查所有的数据，但是物品间的比较不会像用户间的比较那么频繁变化。</p>

<p><a href="http://grouplens.org/datasets/movielens/">MovieLens 数据集</a></p>

<h3 id="toc_3">基于用户进行过滤还是基于物品进行过滤</h3>

<p>在针对大数据集生成推荐列表时，基于物品进行过滤的方式明显要比基于用户的过滤更快，不过有维护物品相似度表的额外开销。而对于稀疏数据集，基于物品的过滤方法通常要优于基于用户的过滤方法，而对于密集数据集而言，两者的效率几乎是一样的。</p>

<p>尽管如此，基于用户的过滤方法更加易于实现，而且无需额外步骤，因此更加适用于规模较小的变化非常频繁的内存数据集。</p>

<h2 id="toc_4">发现群组 Discovering Groups</h2>

<p>数据聚类(data clustering) 用以寻找紧密相关的事、人或观点，并将其可视化的方法。</p>

<h3 id="toc_5">监督学习和无监督学习</h3>

<ul>
<li>利用样本输入和期望输入来学习如何预测的技术被称为监督学习法(supervised learning methods)，例如神经网络、决策树、向量支持机和贝叶斯过滤。</li>
<li>聚类是无监督学习(unsupervised learning)的一个例子。还有非负矩阵因式分解(non-negative matrix factorization)和自组织映射(self-organizing maps)</li>
</ul>

<h3 id="toc_6">单词向量 Word Vectors</h3>

<p>为聚类算法准备数据的常见做法是定义一组公共的数值型属性，然后利用这些属性对数据项进行比较。例如可以根据内容对博客用户进行分类</p>

<h3 id="toc_7">分级聚类</h3>

<p>通过连续不断地将最为相似的群组两两合并，来构造出一个群组的层级结构。其中的每个群组都是从单一元素开始的。通常，待分级聚类完成之后，我们可以利用树状图(dendrogram)来展现所得到的结果。</p>

<p>但是这种聚类的计算量惊人，很多时候 Kmeans 是一个更好的方法。</p>

<ul>
<li>先对笔记进行分词，然后聚类找到风格，又或者是自动提取出关键字</li>
<li>Beautiful Soup 用来处理网页</li>
<li>多维缩放技术(multidimensional scaling) 缩放的过程中一些信息可能会丢失掉，但缩放后的结果会更加有助于我们理解算法的原理</li>
</ul>

<h2 id="toc_8">搜索与排名 Searching and Ranking</h2>

<p>全文搜索算法是最重要的集体智慧算法之一。</p>

<h3 id="toc_9">搜索引擎的组成</h3>

<p>首要步骤是找到一种搜集文档的方法，然后建立索引，最后一步是通过查询返回一个经过排序的文档列表。</p>

<h3 id="toc_10">PageRank 算法</h3>

<p>为每个网页都赋予了一个指示网页重要程度的评价值。网页的重要性是依据指向该网页的所有其他网页的重要性，以及这些网页中所包含的链接数求得的。</p>

<p>理论上，PageRank 计算的是某个人在任意次链接点击之后到达某一网页的可能性。如果某个网页拥有来自其他热门网页的外部回指链接越多，人们无意间到达该网页的可能性也就越大。当然，如果用户始终不停地点击，那么他们终将到达每一个网页，但是大多数人在浏览一段时间之后就会停止点击。为了反映这一情况，PageRank 还使用了一个值为 0.85 的阻尼因子，用以指示用户持续点击每个网页中链接的概率为 85%。</p>

<p>计算时为所有的 PageRank 都设置一个任意的初始值，经过反复迭代，会越来越接近真实值。</p>

<h3 id="toc_11">从点击行为中学习</h3>

<p>构造一个人工神经网络，以一组节点(神经元)构成，并且彼此相连，称为多层感知机(multilayer perceptron, MLP) 网络。此类网络由多层神经元构造而成，其中第一层神经元接受输入，最后一层给予输出。神经网络可以有多个中间层，称为隐藏层，其职责是对输入进行组合</p>

<h2 id="toc_12">优化 Optimization</h2>

<p>随机优化(stochastic optimization)的技术来解决协作类问题，擅长处理受多种变量影响，存在许多可能解的问题，以及结果因这些变量的组合而产生很大变化的问题。</p>

<p>成本函数是用优化算法解决问题的关键，它通常是最难确定的。任何优化算法的目标，就是要寻找一组能够使成本函数的返回结果达到最小化的输入。对于好坏程度并没有特定的衡量尺度，唯一的要求就是函数返回的值越大，表示该方案越差。</p>

<p>爬山法以一个随机解开始，然后在其临近的解集中寻找更好的题解(拥有更低的成本)，最后的解是一个局部范围内的最小值，但却不一定是全局最优解。解决这一难题的一种方法是随机重复爬山法(random-restart hill climbing)</p>

<p>退火是指将合金加热后再慢慢冷却的过程。大量的原子因为受到激发而向周围跳跃，然后又逐渐稳定到一个低能阶的状态，所以这些原子能够找到一个低能阶的配置(configuration)。退火算法以一个问题的随机解开始，用一个变量来表示温度，这一温度开始非常高，而后逐渐变低。每一次迭代期间，算法会随机选中题解中的某个数字，然后朝某个方向变化。退火过程开始阶段会接受表现比较差的解。随着退火过程的不断进行，算法越来越不可能接受较差的解，直到最后，它将只会接受更优的解。</p>

<p>介绍模拟退火前，先介绍爬山算法。爬山算法是一种简单的贪心搜索算法，该算法每次从当前解的临近解空间中选择一个最优解作为当前解，直到达到一个局部最优解。爬山算法实现很简单，其主要缺点是会陷入局部最优解，而不一定能搜索到全局最优解。如下图所示：假设C点为当前解，爬山算法搜索到A点这个局部最优解就会停止搜索，因为在A点无论向那个方向小幅度移动都不能得到更优的解。</p>

<p><img src="./_resource/pci1.jpg" alt="pci1"/></p>

<p>爬山法是完完全全的贪心法，每次都鼠目寸光的选择一个当前最优解，因此只能搜索到局部的最优值。模拟退火其实也是一种贪心算法，但是它的搜索过程引入了随机因素。模拟退火算法以一定的概率来接受一个比当前解要差的解，因此有可能会跳出这个局部的最优解，达到全局的最优解。以图1为例，模拟退火算法在搜索到局部最优解A后，会以一定的概率接受到E的移动。也许经过几次这样的不是局部最优的移动后会到达D点，于是就跳出了局部最大值A。</p>

<p>模拟退火算法描述：</p>

<ul>
<li>若J( Y(i+1) )&gt;= J( Y(i) )  (即移动后得到更优解)，则总是接受该移动</li>
<li>若J( Y(i+1) )&lt; J( Y(i) )  (即移动后的解比当前解要差)，则以一定的概率接受移动，而且这个概率随着时间推移逐渐降低（逐渐降低才能趋向稳定）</li>
<li>这里的“一定的概率”的计算参考了金属冶炼的退火过程，这也是模拟退火算法名称的由来。</li>
</ul>

<p>爬山算法：兔子朝着比现在高的地方跳去。它找到了不远处的最高山峰。但是这座山不一定是珠穆朗玛峰。这就是爬山算法，它不能保证局部最优值就是全局最优值。</p>

<p>模拟退火：兔子喝醉了。它随机地跳了很长时间。这期间，它可能走向高处，也可能踏入平地。但是，它渐渐清醒了并朝最高方向跳去。这就是模拟退火。</p>

<p>遗传算法 Genetic Algorithm</p>

<p>先随机生成一组解，称之为种群(population)，在优化过程中的每一步，算法会计算整个种群的成本函数，从而得到一个有关题解的有序列表。在对题解进行排序之后，一个新的种群，也就是下一代，被创建出来了。首先，我们将当前种群中位于最顶端的题解加入其所在的新种群中(精英选拔法elitism)。新种群中的余下部分是由修改最优解后形成的全新解所组成。</p>

<p>有两种修改题解的方法，一种是变异(mutation)，通常的做法是对一个既有解进行微小的简单的随机的改变。另一种方法称之为交叉(crossover)或配对(breeding)。这种方法是选取最优解中的两个解，然后将它们按照某种方式进行结合。</p>

<p>作为遗传算法生物背景的介绍，下面内容了解即可：<br/>
+ 种群(Population)：生物的进化以群体的形式进行，这样的一个群体称为种群。<br/>
+ 个体：组成种群的单个生物。<br/>
+ 基因 ( Gene ) ：一个遗传因子。 <br/>
+ 染色体 ( Chromosome ) ：包含一组的基因。<br/>
+ 生存竞争，适者生存：对环境适应度高的、牛B的个体参与繁殖的机会比较多，后代就会越来越多。适应度低的个体参与繁殖的机会比较少，后代就会越来越少。<br/>
+ 遗传与变异：新个体会遗传父母双方各一部分的基因，同时有一定的概率发生基因变异。</p>

<p>简单说来就是：繁殖过程，会发生基因交叉( Crossover ) ，基因突变 ( Mutation ) ，适应度( Fitness )低的个体会被逐步淘汰，而适应度高的个体会越来越多。那么经过N代的自然选择后，保存下来的个体都是适应度很高的，其中很可能包含史上产生的适应度最高的那个个体。</p>

<h2 id="toc_13">文档过滤 Document Filtering</h2>

<p>根据内容来对文档进行分类。将单词作为特征时，其假设是：某些单词相对而言更有可能会出现于垃圾信息中。</p>

<p>在训练的初期阶段，极少出现的单词会变得异常敏感。为了解决上述问题，在我们手头掌握的有关当前特征的信息极为有限时，我们还需要根据一个假设的概率来作出判断。</p>

<p>朴素贝叶斯分类器：假设要被组合的各个概率是彼此独立的。Pr(A|B) = Pr(A|B) x Pr(A) / Pr(B)。有些时候承认不知道答案，要好过判断答案就是概率值稍大一些的分类，所以为每个分类设定一个最小的阈值。</p>

<p>费舍尔方法：朴素贝叶斯方法的一种替代方案，可以给出非常精确的结果，尤其是和垃圾信息过滤。与朴素贝叶斯过滤器利用特征概率来计算整篇文档的概率不同，费舍尔方法为文档中的每个特征都求得了分类的概率，又将这些概率组合起来，并判断其是否有可能构成一个随机集合。</p>

<p>!! 可以结合下面的决策树来进行文档类型的分类，不能确定的就还放回 Inbox 中</p>

<h2 id="toc_14">决策树建模</h2>

<p>相比于其他方法，决策树是一种更为简单的机器学习方法，它是对被观测数据进行分类的一种相当直观的方法。使用一种叫做 CART(Classification and Regression Trees, 分类回归树)的算法。为了构造决策树，算法首先创建一个根节点。然后通过评估表中的所有观测变量，从中选出最合适的变量对数据进行拆分。</p>

<p>基尼不纯度(Gini Impurity)将来自集合中的某种结果随机应用与集合中的某一数据的预期误差率。</p>

<p>熵(Entropy): 集合的无序程度</p>

<p>上面两个的主要区别在于，熵达到峰值的过程要相对慢一些。因此，熵对于混乱集合的惩罚往往要更重一些</p>

<h2 id="toc_15">构建价格模型</h2>

<h3 id="toc_16">k-最近邻算法</h3>

<p>对于葡萄酒定价问题而言，找到几瓶情况最为相近的酒，并假设其价格大体相同。算法通过寻找与当前关注的商品情况相似的一组商品，对这些商品的价格求平均值，进而作出价格预测。k 的取值过大或者过小都会降低准确性。</p>

<p>需要定义相似度，同样可以用不同的距离公式来决定。实现起来相对简单，但是计算量很大，不过优点在于，每次有新数据加入，都无须重新进行训练。</p>

<p>不同的近邻可以有不同的权重，越接近的应该权重越大。具体的权重分配方法有以下几种供参考：</p>

<ul>
<li>反函数：例如倒数</li>
<li>减法函数：用一个常量相减</li>
<li>高斯函数：执行速度较慢</li>
</ul>

<p>交叉验证：将数据拆分成训练集与测试集的一系列技术的统称。将训练集传入算法，随着正确答案的得出，就得到了一组用以进行预测的数据集。随后，我们要求算法对测试集中的每一项数据都作出预测。其所给出的答案，将与正确答案进行对比，所发会计算出一个整体分值，以评估其所做预测的准确程度。</p>

<p>不足之处：算法需要计算针对每个点的距离，预测过程的计算量很大。</p>

<h2 id="toc_17">高阶分类：核方法与 SVM</h2>

<p>决策边界是这样一条线：位于这条线一侧的每一个点会被赋予某个分类，而位于另一次的每个点会被赋予另一个分类。</p>

<p>线性分类器的问题在只能找到一条直线。为了改进，对于任何用到了点积运算的算法(包括线性分类器)可以采用一种叫做核技法(The Kernel Trick)的技术。</p>

<p>核技法的思路是用一个新的函数来取代原来的点积函数，当借助某个映射函数将数据第一次变换到更高维度的坐标空间时，新函数将会返回高维度坐标空间内的点积结果，但是现实中我们只会采用少数几种变换方法，其中一种叫做径向基函数(radial-basis function)</p>

<p>径向基函数与点积类似，它接受两个向量作为输入参数，并返回一个标量值。与点积不同的是，径向基函数是非线性的，因而它能够将数据映射到更为复杂的空间中。</p>

<h3 id="toc_18">支持向量机 (Support-Vector Machines)</h3>

<p>支持向量机是广为人知的一组方法的统称，其思路是，尝试寻找一条尽可能远离所有分类的线，这条线被称为最大间隔超平面(maximum-margin hyperplane)。我们将位于这条分界线附近的坐标点称作支持向量。寻找支持向量，并利用支持向量来寻找分界线的算法便是支持向量机。在高维数据集上有不错的表现</p>

<p>libSVM package</p>

<h2 id="toc_19">寻找独立特征</h2>

<p>!! 这个可以用在笔记中，自动发现重要特征</p>

<p>在数据集并未明确标识结果的前提下，从中提取出重要的潜在特征来。和聚类一样，这些方法的目的不是为了预测，而是要尝试对数据进行特征识别，并且告诉我们值得关注的重要信息。</p>

<p>非负矩阵因式分解(NMF)，本书涉及的最为复杂的技术之一。权重矩阵与特征矩阵。利用NumPy</p>

<h2 id="toc_20">智能进化 Evolving Intelligence</h2>

<p>遗传编程(genetic programming)的技术，通常的工作方式是：以一大堆程序(种群)开始，随后，这些程序将会在一个由用户定义的任务中展开竞争。接下来，算法可以采取两种不同的方式对表现最好的程序实施复制和修改(变异/配对)。在每一个复制和修改的阶段，算法都会借助于一个适当的函数对程序的质量作出评估。因为种群大小保持不变，所以优胜劣汰。直到终止条件满足才会结束，不同的问题有不同的终止条件。</p>

<h2 id="toc_21">算法总结</h2>

<ul>
<li>贝叶斯分类器：只要我们能将其转换成一组特征列表，所谓特征，就是指一个给定项中存在或缺少的某种东西。

<ul>
<li>优势在于接受大数据量训练和查询时也可以保持高速，并且对分类器实际学习状况的解释还是相对简单的。</li>
<li>最大缺陷是无法处理基于特征组合所产生的变化结果。</li>
</ul></li>
<li>决策树分类器：利用决策树进行分类非常简单，但对决策树进行训练则需要更多技巧。

<ul>
<li>优点在于解释一个受训模型是非常容易的，能够很容易地处理变量之间的相互影响。</li>
<li>缺点是不支持增量式训练，有新的数据就需要重新开始。</li>
</ul></li>
<li>神经网络：层与层之间通过突触(synapse)彼此相连

<ul>
<li>优点是可以处理复杂的非线性函数，并且能发现不同输入间的依赖关系；允许增量式训练</li>
<li>缺点在于是一种黑盒方法，并且在选择训练数据的比率以及与问题相适应的网络规模方面，并没有明确的规则可以遵循，往往是依据大量的实验。训练比率过高可能过拟，过低可能学习程度不足。</li>
</ul></li>
<li>支持向量机(SVM)：针对每个数据集的最佳核变换函数及其相应的参数都是不一样的，需要大量数据进行训练。也是一种黑盒技术，由于存在向高维空间的变换，SVM 的分类过程甚至更加难于理解。也许能得到很好的答案，但是我们永远都不知道为什么。</li>
<li>k-最近邻算法：能够利用复杂函数进行预测，又保持简单易懂，是一种在线技术，可以随时加入数据。主要缺点在于为了完成预测所有的训练数据都缺一不可，空间时间问题，算法效率较低。寻找合理的缩放因子是一项乏味的工作。</li>
<li>聚类：找相似，多维缩放</li>
<li>非负矩阵因式分解：非监督算法</li>
<li>优化：模拟退火，遗传算法，成本函数</li>
</ul>

<h2 id="toc_22">数学公式</h2>

<ul>
<li>欧几里得距离</li>
<li>皮尔逊相关系数</li>
<li>加权平均</li>
<li>Tanimoto 系数</li>
<li>条件概率</li>
<li>基尼不纯度</li>
<li>熵</li>
<li>方差</li>
<li>高斯函数</li>
<li>点积</li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204008388.html">
                
                  <h1>概率统计基础</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">协方差</h2>

<p>\[Cov(X,Y)=E(XY)-E(X)E(Y)\]</p>

<p>若\(Cov(X,Y)=0\)，X 和 Y 不相关。X 和 Y 独立，则一定不相关，但不相关不一定独立。</p>

<p>协方差是两个随机变量具有相同方向变化趋势的度量。若 \(Cov(X,Y)&gt;0\)，则变化趋势相同；若 \(Cov(X,Y)&lt;0\)，则变化趋势相反；</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204008264.html">
                
                  <h1>Freemind 博客机器学习系列文章</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	
                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204008128.html">
                
                  <h1>机器学习实战</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<!-- MarkdownTOC -->

<ul>
<li>第一部分 分类</li>
<li>第 1 章 机器学习基础

<ul>
<li>如何选择合适的算法</li>
<li>开发机器学习应用程序的步骤</li>
</ul></li>
<li>第 2 章 k-近邻算法(kNN)

<ul>
<li>k-近邻算法的一般流程</li>
<li>使用k-近邻算法改进约会网站的配对效果

<ul>
<li>使用 Matplotlib 创建散点图</li>
<li>归一化数值</li>
<li>测试算法</li>
</ul></li>
<li>小结</li>
</ul></li>
<li>第 3 章 决策树

<ul>
<li>决策树的一般流程</li>
<li>小结</li>
</ul></li>
<li>第 4 章 基于概率论的分类方法：朴素贝叶斯

<ul>
<li>朴素贝叶斯的一般过程</li>
<li>文档词袋模型</li>
<li>过滤垃圾电子邮件</li>
<li>小结</li>
</ul></li>
<li>第 5 章 Logistic 回归

<ul>
<li>Logitstic 回归的一般过程</li>
<li>基于最优化方法的最佳回归系数确定

<ul>
<li>梯度上升法</li>
<li>处理数据中的缺失值</li>
</ul></li>
<li>小结</li>
</ul></li>
<li>第 6 章 支持向量机

<ul>
<li>基于最大间隔分隔数据</li>
<li>SVM 的一般流程</li>
<li>SMO 高效优化算法</li>
<li>在复杂数据上应用核函数

<ul>
<li>利用核函数将数据映射到高维空间</li>
<li>径向基核函数</li>
</ul></li>
<li>小结</li>
</ul></li>
<li>第 7 章 利用 AdaBoost 元算法提高分类性能

<ul>
<li>基于数据集多重抽样的分类器

<ul>
<li>bagging：基于数据随机重抽样的分类器构建方法</li>
<li>boosting</li>
</ul></li>
<li>AdaBoost 的一般流程</li>
<li>训练算法：基于错误提升分类器的性能</li>
<li>构建弱分类器</li>
<li>完整的 AdaBoost 算法实现</li>
<li>一个实例</li>
</ul></li>
<li>非均衡分类问题</li>
</ul>

<!-- /MarkdownTOC -->

<h2 id="toc_0">第一部分 分类</h2>

<p>本书前两部分主要谈好监督学习(supervised learning)。在监督学习过程中，我们只需要给定输入样本集，机器就可以 从中推演出指定目标变量的可能结果。监督学习相对比较简单，机器只需从输入数据中预测合适的模型，并从中计算出目标变量的结果。</p>

<p>监督学习一般使用两种类型的目标变量：标称型和数值型。标称型目标变量的结果只在有限目标集中取值，如真与假。数值型目标变量主要用于回归分析。</p>

<h2 id="toc_1">第 1 章 机器学习基础</h2>

<p>机器学习：利用计算机来彰显数据背后的真实含义。</p>

<p>简单地说，机器学习就是把无序的数据转换成有用的信息。</p>

<p>机器学习的主要任务就是<strong>分类</strong>。最终我们决定使用某个机器学习算法进行分类，首先需要做的是算法训练，即学习如何分类。通常我们为算法输入大量已分类数据作为算法的<strong>训练集</strong>。训练集是用于训练机器学习算法的数据样本集合，其中包含若干<strong>训练样本</strong>，每个训练样本会有若干种特征以及一个<strong>目标变量</strong>。目标变量是机器学习算法的预测结果，在分类算法中目标变量的类型通常是标称型的，而在回归算法中通常是连续型的。训练样本集必须确定知道目标变量的值，以便机器学习算法可以发现特征和目标变量之间的关系。</p>

<p>我们通常将分类问题中的目标变量称为<strong>类别</strong>，并假定分类问题只存在有限个数的类别。</p>

<p><img src="./_resources/mla1.2.jpg" alt="mla1.2"/></p>

<blockquote>
<p>特征或者属性通常是训练样本集的列，它们是独立测量得到的结果，多个特征联系在一起共同组成一个训练样本</p>
</blockquote>

<p>为了测试机器学习算法的效果，通常使用两套独立的样本集：训练数据和<strong>测试数据</strong>。当机器学习程序开始运行时，使用训练样本集作为算法的输入，训练完成之后输入测试样本。比较测试样本预测的目标变量值域实际样本类别之间的差别，就可以得出算法的实际精确度。</p>

<p>机器学习的另一项任务是<strong>回归</strong>，它主要用于预测数值型数据。例子：数据拟合曲线，通过给定数据点的最优拟合曲线。分类和回归属于<strong>监督学习</strong>，之所以称之为监督学习，是因为这类算法必须知道预测什么，即目标变量的分类信息。</p>

<p>与监督学习相对于的是<strong>无监督学习</strong>，此时数据没有类别信息，也不会给定目标值。在无监督学习中，将数据集合分成由类似的对象组成的多个类的过程被称为<strong>聚类</strong>；将寻找描述数据统计值的过程称之为<strong>密度估计</strong>。此外，无监督学习还可以减少数据特征的维度，以便我们可以使用二维或三维图形更加直观地展示数据信息。</p>

<table>
<thead>
<tr>
<th>监督学习</th>
<th>用途</th>
</tr>
</thead>

<tbody>
<tr>
<td>k-近邻算法</td>
<td>线性回归</td>
</tr>
<tr>
<td>朴素贝叶斯算法</td>
<td>局部加权线性回归</td>
</tr>
<tr>
<td>支持向量机</td>
<td>Ridge 回归</td>
</tr>
<tr>
<td>决策树</td>
<td>Lasso 最小回归系数估计</td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th>无监督学习</th>
<th>用途</th>
</tr>
</thead>

<tbody>
<tr>
<td>k-均值</td>
<td>最大期望算法</td>
</tr>
<tr>
<td>DBSCAN</td>
<td>Parzen 窗设计</td>
</tr>
</tbody>
</table>

<h3 id="toc_2">如何选择合适的算法</h3>

<p>首先考虑使用机器学习算法的目的。如果想要预测目标变量的值，则可以选择监督学习算法，否则可以选择无监督学习算法。确定选择监督学习算法之后，需要进一步确定目标变量的类型，如果目标变量是离散型，则可以选择分类器算法；如果目标变量是连续型的数值，则需要选择回归算法。</p>

<p>如果不想预测目标变量的值，则可以选择无监督学习算法。进一步分析是否需要将数据划分为离散的组。如果这是唯一的需求，则使用聚类算法；如果还需要估计数据与每个分组的相似程度，则需要使用密度估计算法。</p>

<p>其次需要考虑的是数据问题。对实际数据了解得越充分，越容易创建符合实际需求的应用程序。主要应该了解数据的以下特性：特征值是离散型变量还是连续型变量，特征值中是否存在缺失的值，何种原因造成缺失值，数据中是否存在异常值，某个特征发生的概率如何。</p>

<p>一般来说，发现最好算法的关键环节是反复试错的迭代过程。</p>

<h3 id="toc_3">开发机器学习应用程序的步骤</h3>

<ol>
<li><strong>收集数据</strong>。爬虫、RSS、API、设备数据。公开可用的数据源</li>
<li><strong>准备输入数据</strong>。确保数据格式符合要求</li>
<li><strong>分析输入数据</strong>。图形化展示</li>
<li><strong>训练算法</strong>。抽取知识或信息</li>
<li><strong>测试算法</strong>。评估效果</li>
<li><strong>使用算法</strong>。将算法转换为应用程序</li>
</ol>

<h2 id="toc_4">第 2 章 k-近邻算法(kNN)</h2>

<p>简单来说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。</p>

<ul>
<li>优点：精度高、对异常值不敏感、无数据输入假定</li>
<li>缺点：计算复杂度高、空间复杂度高</li>
<li>适用数据范围：数值型和标称型</li>
</ul>

<p>工作原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中对应的特征进行比较，然后算法提取样本集中前 k 个最相似的数据。最后，选择 k 个最相似数据中出现次数最多的分类，作为新数据的分类。</p>

<h3 id="toc_5">k-近邻算法的一般流程</h3>

<ol>
<li>收集数据：可以使用任何方法</li>
<li>准备数据：距离计算所需要的数值，最好是结构化的数据格式</li>
<li>分析数据：可以使用任何方法</li>
<li>训练算法：此步骤不适用于k-近邻算法</li>
<li>测试算法：计算错误率</li>
<li>使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k-近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理</li>
</ol>

<p>对未知类别属性的数据集中的每个点依次执行以下操作：</p>

<ol>
<li>计算已知类别数据集中的点与当前点之间的距离；</li>
<li>按照距离递增次序排序；</li>
<li>选取与当前点距离最小的 k 个点；</li>
<li>确定前 k 个点所在类别的出现频率</li>
<li>返回前 k 个点出现频率最高的类别作为当前点的预测分类</li>
</ol>

<p>具体可以参考 <code>AlgorithmTour/MachineLearningInAction/kNN.py</code></p>

<pre><code>import kNN
group, labels = kNN.createDataSet()
kNN.classify0([0,0], group, labels, 3)
</code></pre>

<h3 id="toc_6">使用k-近邻算法改进约会网站的配对效果</h3>

<p>海伦收集了一些约会数据，包括：</p>

<ul>
<li>每年获得的飞行常客里程数</li>
<li>玩视频游戏所耗时间百分比</li>
<li>每周消费的冰激凌公升数</li>
</ul>

<p>使用 <code>file2matrix</code> 函数把数据 <code>datingTestSet.txt</code> 读入到程序中</p>

<pre><code>reload(kNN)
datingDataMat, datingLabels = kNN.file2matrix(&#39;datingTestSet2.txt&#39;)
</code></pre>

<h4 id="toc_7">使用 Matplotlib 创建散点图</h4>

<p>在 Python 命令行环境中</p>

<pre><code>import matplotlib
import matplotlib.pyplot as plt
from numpy import array
fig = plt.figure()
ax = fig.add_subplot(111)
ax.scatter(datingDataMat[:,1], datingDataMat[:,2])
plt.show()
</code></pre>

<p>得到下图</p>

<p><img src="./_resources/mla2.3.jpg" alt="mla2.3"/></p>

<p>乱七八糟完全看不清，使用 <code>scatter</code> 函数利用标签来个性化标记</p>

<pre><code>ax.scatter(datingDataMat[:,1], datingDataMat[:,2], 15.0*array(datingLabels), 15.0*array(datingLabels))
plt.show()
</code></pre>

<p>标上颜色之后，效果会好很多，可是依然很难从中获得什么有效的信息</p>

<p><img src="./_resources/mla2.4.jpg" alt="mla2.4"/></p>

<p>(以上两张图的横轴是玩视频游戏所耗时间百分比，总州市每周消费的冰淇淋公升数)</p>

<p>如果把横轴和纵轴换成每年获取的飞行常客里程数和玩视频游戏所耗时间百分比，结论会更清晰一些</p>

<pre><code>ax.scatter(datingDataMat[:,0], datingDataMat[:,1], 15.0*array(datingLabels), 15.0*array(datingLabels))
plt.show()
</code></pre>

<p><img src="./_resources/mla2.5.jpg" alt="mla2.5"/></p>

<h4 id="toc_8">归一化数值</h4>

<p>为了避免不同的特征的数值不同所导致的影响不同，可能需要进行归一化，也就是把特征值转换成[0,1]值</p>

<h4 id="toc_9">测试算法</h4>

<p>机器学习算法一个很重要的工作就是评估算法的正确率，通常我们只提供已有数据的 90% 作为训练样本来训练分类器，而使用剩余的 10% 数据去测试分类器，检测分类器的正确率</p>

<p>之后是手写的另一个例子，就略过了，总体思想是差不多的。</p>

<h3 id="toc_10">小结</h3>

<p>k-近邻算法是分类数据最简单最有效的算法，必须保存全部数据集，如果训练数据集很大，必须使用大量的存储空间。此外，由于必须对数据集中的每个数据计算距离值，实际使用可能非常耗时。<strong>k决策树</strong>是其优化版本，可以节省大量的计算开销。</p>

<p>另一个却显示它无法给出任何数据的基础结构信息，因此我们也无法知晓平均实例样本和典型实例样本具有什么特征。使用<strong>概率测量方法</strong>可以解决这个问题。</p>

<h2 id="toc_11">第 3 章 决策树</h2>

<p>决策树的主要优势在于数据形式非常容易理解。决策树很多任务都是为了数据中所蕴含的知识信息，因此决策树可以使用不熟悉的数据集合，并从中提取出一系列规则，机器学习算法最终将使用这些机器从数据集中创造的规则。</p>

<ul>
<li>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。</li>
<li>缺点：可能会产生过度匹配问题。</li>
<li>适用数据类型：数值型和标称型。</li>
</ul>

<p>在构造决策树时，我们需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时起决定性作用。为了找到决定性的特征，划分出最好的结果，我们必须评估每个特征。完成测试之后，原始数据集就被划分为几个数据子集。这些数据子集会分布在第一个决策点的所有分支上。</p>

<h3 id="toc_12">决策树的一般流程</h3>

<ol>
<li>收集数据：可以使用任何方法</li>
<li>准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化</li>
<li>分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期</li>
<li>训练算法：构造树的数据结构</li>
<li>测试算法：使用经验树计算错误率</li>
<li>使用算法：此步骤可以适用于任何监督算法，而使用决策树可以更好地理解数据的内在含义</li>
</ol>

<p>这里使用 <a href="http://en.wikipedia.org/wiki/ID3">ID3</a> 算法划分数据集</p>

<p>划分数据集的大原则是：将无序的数据变得更加有序。组织杂乱无章数据的一种方法就是使用信息论度量信息。<strong>信息增益(information gain)</strong>和<strong>熵(entropy)</strong></p>

<p>代码在 <code>tree.py</code> 中</p>

<p>熵越高，则混合的数据也越多。另一个度量集合无序程度的方法是基尼不纯度(Gini impurity)，简单地说就是从一个数据集中随机选取子项，度量其被错误分类到其他分组里的概率。</p>

<p>抽取不同的特征，根据剩下特征熵的大小，来决定哪个特征是最重要的，然后递归生成决策树。</p>

<p>然后就是用 Matplotlib 把树画出来</p>

<h3 id="toc_13">小结</h3>

<p>决策树分类器就像带有终止块的流程图，终止块表示分类结果。开始处理数据时，我们首先需要测量集合中数据的不一致性，也就是熵，然后寻找最优方案划分数据集，直到数据集中的所有数据属于同一分类。</p>

<p>ID3 算法可以用于划分标称型数据集。构造决策树时，我们通常采用递归的方法将数据集转化为决策树。</p>

<p>决策树可能会产生过多的数据集划分，从而产生过度匹配数据集的问题。我们可以通过裁剪决策树，合并相邻的无法产生大量信息增益的叶节点，消除过度匹配的问题。</p>

<h2 id="toc_14">第 4 章 基于概率论的分类方法：朴素贝叶斯</h2>

<p>概率论是许多机器学习算法的基础，所以深刻理解这一主题就显得十分重要。</p>

<ul>
<li>优点：在数据较少的情况下仍然有效，可以处理多类问题</li>
<li>缺点：对于输入数据的准备方式较为敏感</li>
<li>适用数据类型：标称型数据</li>
</ul>

<p>机器学习的一个重要应用就是文档的自动分类。在文档分类中，整个文档是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词出现或者不出现作为一个特征，这样得到的特征数目就会跟词汇表中的词目一样多。朴素贝叶斯是用于文档分类的常用算法。</p>

<h3 id="toc_15">朴素贝叶斯的一般过程</h3>

<ol>
<li>收集数据：可以使用任何方法。这里使用 RSS 源</li>
<li>准备数据：需要数值型或者布尔型数据</li>
<li>分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好</li>
<li>训练算法：计算不同的独立特征的条件概率</li>
<li>测试算法：计算错误率</li>
<li>使用算法：一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本</li>
</ol>

<p>朴素贝叶斯的两个假设：</p>

<ul>
<li>一个特征或者单词出现的可能性与它和其他单词相邻没有关系。</li>
<li>每个特征同等重要</li>
</ul>

<p>看起来有点不合理，但是这也就是为什么要称其为“朴素”的原因。</p>

<p>朴素贝叶斯分类器通常有两种实现方式：一种基于伯努利模型实现，一种基于多项式模型实现。这里采用第一种实现方式。该实现方式中兵不考虑词在文档中出现的次数，只考虑出不出现，因此在这个意义上相当于假设词是等权重的</p>

<p>利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率。如果其中一个概率值为0，那么最后乘积也为0。为了降低这种影响，可以将所有词出现数字初始化为1，并将分母初始化为2</p>

<p>另一个遇到的问题是下溢出，这是由于太多很小的数相乘造成的，这里取对数，就可以把乘法变为加法，并且对最后结果没有影响。</p>

<h3 id="toc_16">文档词袋模型</h3>

<p>目前为止，我们将每个词的出现与否作为一个特征，这可以被描述为<strong>词集模型(set-of-words model)</strong>。如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表达的某种信息，这个方法被称为<strong>词袋模型(bag-of-words model)</strong>。在词袋中，每个单词可以出现多次，而在词集中，每个词只能出现一次。</p>

<h3 id="toc_17">过滤垃圾电子邮件</h3>

<p>准备数据：切分文本。去掉标点符号，统一大小写</p>

<p>随机选择数据的一部分作为训练集，而剩余部分作为测试集的过程称为<strong>留存交叉验证(hold-out cross validation)</strong>。为了更精确地估计分类器的错误率，就应该进行多次迭代后求出平均错误率。</p>

<p>移除停止词会降低分类错误率</p>

<h3 id="toc_18">小结</h3>

<p>对于分类来说，使用概率有时要比使用硬规则更为有效。贝叶斯概率及贝叶斯准则提供了一种利用已知值来估计位置概率的有效方法。</p>

<p>词袋模型在解决文档分类问题上比词集模型有所提高。</p>

<h2 id="toc_19">第 5 章 Logistic 回归</h2>

<p>假设现在有一些数据点，我们用一条直线对这些点进行拟合(该线称为最佳拟合直线)，这个拟合过程就称作回归。利用 Logistic 回归进行分类的主要思想是：根据现有数据对分类边界线建立回归公式，以此进行分类。</p>

<h3 id="toc_20">Logitstic 回归的一般过程</h3>

<ol>
<li>收集数据：采用任意方法收集数据</li>
<li>准备数据：由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式最佳</li>
<li>分析数据：采用任一方法对数据进行分析</li>
<li>训练算法：大部分时间将用于巡礼那，训练的目的是为了找到最佳的分类回归系数</li>
<li>测试算法：一旦训练步骤完成，分类将会很快</li>
<li><p>使用算法：首先，我们需要输入一些数据，并将其转换成对应的结构化数值；接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定它们属于哪个类别；在这之后，我们就可以在输出的类别上做一些其他分析工作</p></li>
</ol>

<ul>
<li>优点：计算代价不高，易于理解和实现</li>
<li>缺点：容易欠拟合，分类精度可能不高</li>
<li>适用数据类型：数值型和标称型</li>
</ul>

<p>我们想要的函数应该是，能接受所有的输入然后预测出类别。例如，在两个类的情况下，上述函数输出 0 或 1。或许之前有接触过<strong>海维塞德阶跃函数(Heaviside step function)</strong>，或者直接称为<strong>单位阶跃函数</strong>。可是这个函数比较难处理。不过我们可以采用一个类似的但是好处理的函数——<strong>Sigmoid 函数</strong></p>

<p><img src="./_resources/mla0.jpg" alt="mla0"/></p>

<p>为了实现 Logistic 回归的分类器，我们可以子啊每个特征上都乘以一个回归系数，然后把所有的结果值相加，将这个总和代入 Sigmoid 函数中，进而得到一个范围在[0, 1]之间的值。任何大于0.5的被分为1类，小于0.5的被归入0类，也可以看成是一种概率估计。</p>

<p><img src="./_resources/mla5.1.jpg" alt="mla5.1"/></p>

<p>所以我们现在的问题就是，最佳回归系数是多少？</p>

<h3 id="toc_21">基于最优化方法的最佳回归系数确定</h3>

<p>Sigmoid 函数的输入记为 z，由下面公式得出：z = w~0~x~0~ + w~1~x~1~ + w~2~x~2~ + ... + w~n~x~n~</p>

<p>如果采用向量的写法，就可以写成 z = w<sup>T<sup>x，其中向量</sup></sup> x 是分类器的输入数据，向量 w 也就是我们要找到的最佳参数(系数)，从而使得分类器尽可能地准确。</p>

<h4 id="toc_22">梯度上升法</h4>

<p>要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。如果梯度记为 ▽，则函数 f(x,y)的梯度由下式表示</p>

<p><img src="./_resources/mla1.jpg" alt="mla1"/></p>

<p><img src="./_resources/mla2.jpg" alt="mla2"/></p>

<p>可以看到，梯度算子总是指向函数增长最快的方向。这里所说的是移动方向，而未提到移动量的大小。该量值成为步长，记为 α。用向量来表示的话，梯度算法的迭代公式为：w := w + α▽~w~f(w)</p>

<p>该公式将一直被迭代执行，直到达到某个停止条件为止，比如迭代次数达到某个指定值或算法达到某个可以允许的误差范围。</p>

<p>为了减少运算量，可以使用<strong>随机梯度上升</strong>算法。步长应该随着迭代次数增加而不断减少，如果不是严格下降的，就接近于模拟退火算法。</p>

<p>一个判断优化算法优劣的可靠方式是看它是否收敛，也就是说参数是否达到了稳定值，是否还会不断地变化。</p>

<h4 id="toc_23">处理数据中的缺失值</h4>

<ul>
<li>使用可用特征的均值来填补缺失值</li>
<li>使用特殊值来填补缺失值，如 -1</li>
<li>忽略有缺失值的样本</li>
<li>使用相似样本的均值填补缺失值</li>
<li>使用另外的机器学习算法预测缺失值</li>
</ul>

<h3 id="toc_24">小结</h3>

<p>Logistic 回归的目的是寻找一个非线性函数 Sigmoid 的最佳拟合参数，求解过程可以由最优化算法来完成。在最优化算法中，最常用的就是梯度上升算法，而梯度上升算法又可以简化为随机梯度上升算法。</p>

<p>随机梯度上升算法与梯度上升算法的效果相当，但占用更少的计算资源。此外，随机梯度上升是一个在线算法，它可以在新数据到来时就完成参数更新，而不需要重新读取整个数据集来进行批处理运算。</p>

<h2 id="toc_25">第 6 章 支持向量机</h2>

<p>SVM 有很多实现，但是这里只关注最流行的一种，即<strong>序列最小化(Sequential Minmal Optimization, SMO)</strong>算法。在此之后，将介绍如何使用一种称为<strong>核函数(kernel)</strong>的方式将 SVM 扩展到更多数据集上。</p>

<h3 id="toc_26">基于最大间隔分隔数据</h3>

<ul>
<li>优点：泛化错误率低，计算开销不大，结果易解释</li>
<li>缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二元分类问题</li>
<li>适用数据类型：数值型和标称型</li>
</ul>

<p>将数据集分隔开来的直线称为<strong>分隔超平面(separating hyperplane)</strong>。如果数据对象是1024维的，那么就需要一个1023维的某某对象来对数据进行分隔，这个对象就叫<strong>超平面(hyperplane)</strong>，也就是分类的决策边界。分布在超平面一侧的所有数据都属于某个类别，而分布在另一侧的所有数据则属于另一个类别。</p>

<p>我们希望能找到离分隔超平面最近的点，确保它们离分隔面的距离尽可能远。这里点到分隔面的距离被称为<strong>间隔(margin)</strong>。我们希望间隔尽可能大，因为如果我们犯错或者在有限数据上训练分类器的话，我们希望分类器尽可能健壮。</p>

<p><strong>支持向量(support vector)</strong>就是离分隔超平面最近的那些点。接下来要试着最大化支持向量到分隔面的距离。</p>

<p><img src="./_resources/mla6.3.jpg" alt="mla6.3"/></p>

<p>分隔超平面的形式可以写成 w<sup>T<sup>x+b。要计算点</sup></sup> A 到分隔超平面的距离，就必须给出点到分隔面的法线或垂线的长度，值为 |w<sup>T<sup>A+b|/||w||。这里的常数</sup></sup> b 类似于 Logistic 回归中的截距 w~0~。</p>

<p>分类器接收了输入数据后，会输出一个类别标签，这相当于一个类似于 Sigmoid 的函数。下面将使用<strong>海维塞德阶跃函数</strong>对 w<sup>T<sup>x+b</sup></sup> 作用得到 f(w<sup>T<sup>x+b)，其中</sup></sup> u&lt;0 时 f(u) 输出 -1，反之输出 +1。</p>

<p>当计算数据点到分隔面的距离并确定分隔面的放置位置时，间隔是通过 label x (w<sup>T<sup>+b)来计算的。如果数据点处于正方向(+1)，w<sup>T<sup>x+b</sup></sup></sup></sup> 会是一个很大的正数，同时 label x (w<sup>T<sup>+b)也会是一个很大的正数；而处于负方向时(-1)，label</sup></sup> x (w<sup>T<sup>+b)</sup></sup> 仍然会是一个很大的正数</p>

<p>现在的目标就是找出分类器定义中的 w 和 b。为此，我们必须找到具有最小间隔的数据点，而这些数据点也就是前面提到的支持向量。一旦找到具有最小间隔的数据点，我们就需要对该间隔最大化：</p>

<p><img src="./_resources/mla3.jpg" alt="mla3"/></p>

<p>直接求解上述问题相当困难，所以需要将它转换成为另一种更容易求解的形式。</p>

<p>先考察一下大括号中的部分。由于对乘积进行优化是一件很讨厌的事情，因此我们要做的是固定其中一个因子而最大化其他因子。如果令所有支持向量的 label x (w<sup>T<sup>+b)</sup></sup> 都为 1，那么就可以通过求 ||w|| 的最大值来得到最终解。但是，并非所有数据点的 label x (w<sup>T<sup>+b)</sup></sup> 都等于 1，只有那些离分割超平面最近的点得到的值才为 1。而离超平面越远的数据点，其 label x (w<sup>T<sup>+b)</sup></sup> 的值也就越大。</p>

<p>这里的约束条件就是 label x (w<sup>T<sup>+b)</sup></sup> &gt;= 1。对于这类优化问题，有一个非常著名的求解方法，拉格朗日乘子法。通过引入拉格朗日乘子，我们就可以基于约束条件来表述原来的问题。由于这里的约束条件都是基于数据点的，因此我们就可以将超平面写成数据点的形式，优化函数就变成(这里不懂...)：</p>

<p><img src="./_resources/mla4.jpg" alt="mla4"/></p>

<blockquote>
<p>label x (w<sup>T<sup>+b)</sup></sup> 被称为点到分隔面的函数间隔，label x (w<sup>T<sup>+b)</sup></sup> / ||w|| 称为点到分隔面的几何间隔</p>

<p>尖括号表示两个向量的内积</p>
</blockquote>

<p>约束条件为</p>

<p><img src="./_resources/mla5.jpg" alt="mla5"/></p>

<p>考虑到数据不可能非常完美，就需要引入<strong>松弛变量(slack variable)</strong>来允许有些数据点可以处于分隔面错误的一侧。这样我们的优化目标就能保持仍然不变，但约束条件变成：</p>

<p><img src="./_resources/mla6.jpg" alt="mla6"/></p>

<p>这里的常数 C 用于控制“最大化间隔”和“保证大部分点的函数间隔小于1.0”这两个目标的权重。在优化算法的实现代码中，常数 C 是一个参数，因此我们就可以通过调节该参数得到不同的结果。一旦求出了所有的 α，那么分隔超平面就可以通过这些 α 来表达。这一结论十分直接，SVM 中的主要工作就是求解这些 α。</p>

<p>要理解刚才这些公式还需要大量知识，请查阅相关资料。</p>

<h3 id="toc_27">SVM 的一般流程</h3>

<ol>
<li>收集数据：可以使用任何方法</li>
<li>准备数据：需要数值型数据</li>
<li>分析数据：有助于可视化分隔超平面</li>
<li>训练算法：SVM 的大部分时间都源自训练，该过程主要实现两个参数的调优</li>
<li>测试算法：十分简单的计算过程就可以实现</li>
<li>使用算法：几乎所有分类问题都可以使用 SVM，值得一提的是，SVM 本身是一个二元分类器，对多类问题应用 SVM 需要对代码做一些修改</li>
</ol>

<h3 id="toc_28">SMO 高效优化算法</h3>

<p><strong>Platt 的 SMO 算法</strong></p>

<p>SMO 表示<strong>序列最小化(Sequential Minimal Optimization)</strong>。Platt 的 SMO 算法是将大优化问题分解为多个小优化问题来求解的。这些小优化问题往往很容易求解，并且对它们进行顺序求解的结果与将它们作为整体来求解的结果是完全一致的。</p>

<p>SMO 算法的目标是求出一系列 α 和 b，一旦求出了这些 α，就很容易计算出权重向量 w 并得到分隔超平面。</p>

<p>SMO 算法的工作原理是：每次循环中选择两个 α 进行优化处理。一旦找到一对合适的 α，那么就增大其中一个同时减小另一个。这里所谓的“合适”就是指两个 α 必须要符合一定的条件，条件之一就是这两个 α 必须要在间隔边界之外，第二个条件则是这两个 α 还没有进行过区间化处理或者不在边界上。</p>

<p>Platt SMO 算法中的外循环确定要优化的最佳 α 对。而简化版会跳过这一部分，首先在数据集上遍历每一个 α，然后在剩下的 α 集合中随机选择另一个 α，从而构建 α 对。这一点相当重要，要同时改变，因为我们有一个约束条件：</p>

<p><img src="./_resources/mla5.jpg" alt="mla5"/></p>

<p>由于改变一个 α 可能会导致该约束条件失效，因此我们总是同时改变两个 α。</p>

<p>伪代码：</p>

<pre><code>创建一个 α 向量并将其初始化为 0 向量
当迭代次数小于最大迭代次数时(外循环)
    对数据集中的每个数据向量(内循环):
        如果该数据向量可以被优化:
            随机选择另外一个数据向量
            同时优化这两个向量
            如果两个向量都不能被优化，退出内循环
    如果所有向量都没有被优化，增加迭代数量，继续下一次循环
</code></pre>

<p><strong>完整的Platt SMO算法</strong></p>

<p>在在选择第一个 α 值后，算法会通过一个内循环来选择第二个 α 值。在优化过程中，会通过<strong>最大化步长</strong>的方式来获得第二个 α 值。</p>

<h3 id="toc_29">在复杂数据上应用核函数</h3>

<p>核函数(kernel) 和 径向基函数(fadial basis function)</p>

<h4 id="toc_30">利用核函数将数据映射到高维空间</h4>

<p>从某个特征空间到另一个特征空间的映射是通过核函数来实现的。可以把核函数想象成一个<strong>包装器(wrapper)</strong>或者是<strong>接口(interface)</strong>，它能把数据从某个很难处理的形式转换成另一种较易处理的形式。</p>

<p>SVM 优化中一个特别好的地方是，所有的运算都可以写成<strong>内积(inner product)</strong>的形式。向量的内积指的是两个向量相乘，之后得到单个标量或者数值。我们可以把内积运算替换成核函数，而不必做简化处理。将内积替换成核函数的方式被称为<strong>核技巧(kernel trick)</strong>或者<strong>核变电(kernel substation)</strong>。</p>

<h4 id="toc_31">径向基核函数</h4>

<p>采用向量作为自变量的函数，基于向量距离运算输出一个标量。这个距离可以是从<0, 0>向量或者其他向量开始计算的距离，我们使用径向基函数的高斯版本，公式如下：</p>

<p><img src="./_resources/mla7.jpg" alt="mla7"/></p>

<p>上述高斯核函数将数据从其特征空间映射到更高维的空间，具体来说这里是映射到一个无穷维的空间。</p>

<p>支持向量的数目存在一个最优值。SVM 的优点在于它能对数据进行高效分类。如果支持向量太少，就可能会得到一个很差的决策边界；如果支持向量太多，也就相当于每次都利用整个数据集进行分类，这种分类方法称为 k近邻。</p>

<p>可以这么看 SVM 比 k 近邻好的地方在于，从很多数据中找到最有代表性的数据点来作为分类的依据，可以有效减少多余的计算。</p>

<h3 id="toc_32">小结</h3>

<p>支持向量机的泛化错误率较低，也就是说它具有良好的学习能力，且学到的结果具有很好的推广性。这些优点使得向量机十分流行，有些人认为它是监督学习中最好的定式算法。</p>

<p>支持向量机试图通过求解一个二次优化问题来最大化分类间隔。</p>

<p>和方法或者说核技巧会将数据(有时是非线性数据)从一个低维空间映射到一个高维空间，可以将一个在低维空间中的非线性问题转换成高维空间下的线性问题来求解。和方法不止在 SVM 中适用，还可以用于其他算法中。而其中径向基函数是一个常用的度量两个向量距离的核函数。</p>

<p>支持向量机是一个二元分类器。当用其解决多元问题时，则需要额外的方法对其进行扩展。SVM 的效果也对优化参数和所用核函数中的参数敏感。</p>

<h2 id="toc_33">第 7 章 利用 AdaBoost 元算法提高分类性能</h2>

<p><strong>元算法(meta-algorithm)</strong>是对其他算法进行组合的一种方式。某些人认为 AdaBoost 是最好的监督学习的方法，是机器学习工具箱中最强有力的工具之一。</p>

<h3 id="toc_34">基于数据集多重抽样的分类器</h3>

<p>前面已经介绍了五种不同的分类算法，它们各有优缺点。我们自然可以将不同的分类器组合起来，而这种组合结果则被称为<strong>集成方法(ensemble method)</strong>或者<strong>元算法(meta-algorithm)</strong>。使用集成方法时会有多种形式：可以是不同算法的集成，也可以是同一算法在不同设置下的集成，还可以是数据集不同部分分配给不同分类器之后的集成。</p>

<ul>
<li>优点：泛化错误率低，易编码，可以应用在大部分分类器上，无参数调整</li>
<li>缺点：对离群点敏感</li>
<li>适用数据类型：数值型和标称型</li>
</ul>

<h4 id="toc_35">bagging：基于数据随机重抽样的分类器构建方法</h4>

<p><strong>自举汇聚法(bootstrap aggregating)</strong>，也称为 bagging 方法，是在从原始数据集选择 S 次后得到 S 个新数据集的一种技术。新数据集和原数据集的大小相等。每个数据集都是通过在原始数据集中随机选择一个样本来进行替换而得到的。这一性质就允许新数据集中可以有重复的值，而原始数据集的某些值在新集合中则不再出现。</p>

<p>在 S 个数据集建好之后，将某个学习算法分贝作用域每个数据集就得到了 S 个分类器。当我们要对新数据进行分类时，就可以应用这 S 个分类器进行分类，与此同时，选择分类器投票结果中最多的类别作为最后的分类结果。</p>

<p>也有一些更先进的 bagging 方法，比如<strong>随机森林(random forest)</strong>，一些<a href="http://www.stat.berkeley.edu/%7Ebreiman/RandomForests/cc_home.htm">参考资料</a></p>

<h4 id="toc_36">boosting</h4>

<p>boosting 是一种与 bagging 很类似的技术。不论是在 boosting 还是 bagging 当中，所使用的多个分类器的类型都是一致的。但是在前者当中，不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。boosting 是通过集中关注被已有分类器错分的那些数据来获得新的分类器。</p>

<p>由于 boosting 分类的结果是基于所有分类器的加权求和结果的，因此 boosting 与 bagging 不太一样。bagging 中的分类器权重是相等的，而 boosting 中的分类器权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。</p>

<p>boosting 方法拥有多个版本，这里只关注最流行的 AdaBoost</p>

<h3 id="toc_37">AdaBoost 的一般流程</h3>

<ol>
<li>收集数据：可以使用任何方法</li>
<li>准备数据：依赖于所使用的弱分类器类型。作为弱分类器，简单分类器的效果更好</li>
<li>分析数据：可以使用任何方法</li>
<li>训练算法：AdaBoost 的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器</li>
<li>测试算法：计算分类的错误率</li>
<li>使用算法：同 SVM 一样，AdaBoost 预测两个类别中的一个。如果想把它应用到多个类别，就需要进行修改</li>
</ol>

<h3 id="toc_38">训练算法：基于错误提升分类器的性能</h3>

<p>能否使用弱分类器和多个实例来构建一个强分类器？这是一个非常有趣的理论问题。这里的“弱”意味着分类器的性能比所及猜测要略好，但是也不会好太多。AdaBoost 算法即脱胎于上述理论问题。</p>

<p>AdaBoost 是 adaptive boosting(自适应 boosting)的缩写，其运行过程如下：训练数据中的每个样本各有一个权重，这些权重构成了向量 D。一开始，这些权重都初始化成相等值。首先在训练数据上训练处一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本的权重将会提高。</p>

<p>为了从所有弱分类器中得到最终的分类结果，AdaBoost 为每个分类器都分配了一个权重值 α，这些 α 值是基于每个弱分类器的错误率进行计算的。错误率和 α 的公式为</p>

<p><img src="./_resources/mla8.jpg" alt="mla8"/></p>

<p><img src="./_resources/mla9.jpg" alt="mla9"/></p>

<p>计算出 α 值之后，可以对权重向量 D 进行更新，以使那些正确分类的样本的权重降低而错分样本的群众升高。D 的计算方法如下：</p>

<p><img src="./_resources/mla10.jpg" alt="mla10"/></p>

<p>计算出 D 之后，AdaBoost 又开始进入下一轮迭代。AdaBoost 算法会不断地重复训练和调整权重的过程，直到训练错误率为 0 或者弱分类器的数目达到用户的指定值为止。</p>

<h3 id="toc_39">构建弱分类器</h3>

<p><strong>单层决策树(decision stump, 决策树桩)</strong>是一种简单的决策树，仅基于单个特征来做决策。</p>

<p><img src="./_resources/mla11.jpg" alt="mla11"/></p>

<p>伪代码：</p>

<p><img src="./_resources/mla12.jpg" alt="mla12"/></p>

<h3 id="toc_40">完整的 AdaBoost 算法实现</h3>

<p><img src="./_resources/mla13.jpg" alt="mla13"/></p>

<h3 id="toc_41">一个实例</h3>

<p><img src="./_resources/mla14.jpg" alt="mla14"/></p>

<p>观察上表，我们会发现测试错误率在达到了一个最小值之后又开始上升了。这类现象称之为<strong>过拟合(overfitting)</strong></p>

<p>很多人都认为，AdaBoost 和 SVM 是监督机器学习中最强大的两种方法。实际上，这两者之间拥有不少相似之处。我们可以把弱分类器想象成 SVM 中的一个核函数，也可以按照最大化某个最小间隔的方式重写 AdaBoost 算法。而它们的不同就在于其所定义的间隔计算方式有所不同，因此导致的结果也不同。</p>

<h2 id="toc_42">非均衡分类问题</h2>

<p>前面所有提到的分类介绍中，我们都假设所有类别的分类代价是一样的。可是在大多数情况下不同类别的分类代价并不相等</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007992.html">
                
                  <h1>机器学习 学习指引</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<!-- MarkdownTOC -->

<ul>
<li>机器学习的四个层次

<ul>
<li>初学阶段</li>
<li>新手阶段</li>
<li>中级阶段</li>
<li>高级阶段</li>
</ul></li>
<li>最简明入门指南

<ul>
<li>何为机器学习？</li>
<li>两类机器学习算法</li>
<li>监督式学习</li>
<li>非监督式学习</li>
<li>太酷了，但是评估房价真能被看作“学习”吗？</li>
<li>让我们写代码吧!</li>
<li>步骤1</li>
<li>步骤2</li>
<li>步骤3</li>
<li>思想扰动时间</li>
<li>步骤3中的“尝试每个数字”怎么回事？</li>
<li>还有什么你随便就略过了？</li>
<li>机器学习法力无边吗？</li>
<li>怎样深入学习机器学习</li>
</ul></li>
<li>如何选择机器学习算法</li>
<li>不大明白的部分</li>
<li>一天玩转机器学习

<ul>
<li>Linux</li>
<li>Mac</li>
</ul></li>
<li>数据挖掘中的九种错误</li>
<li>十张图解释机器学习的基本概念</li>
</ul>

<!-- /MarkdownTOC -->

<h2 id="toc_0">机器学习的四个层次</h2>

<p>根据能力可以将学习过程分成四个阶段。这也是一个有助于我们将所有学习资源进行分类的好方法。</p>

<p>我之所以把初学阶段和新手阶段区分开来，是因为我想让那些完全初学者(对这个领域感兴趣的程序员)在初学阶段对机器学习有一个大致的认识，以便决定是否继续深入。</p>

<p>我们将分别探讨这四个阶段，并推荐一些能够帮助我们更好地理解机器学习和提高相关技能的资源。对学习阶段进行这样的分类只是我个人的建议，也许每个分类的前后阶段中也<br/>
有一些适合当前阶段的资源。</p>

<p>我认为对机器学习有一个整体性的认识是非常有帮助的，我也希望能听听你们的想法，通过在下面评论告诉我吧！</p>

<h3 id="toc_1">初学阶段</h3>

<p>初学者是指那些对机器学习感兴趣的程序员。他们或许已经接触过一些相关的书籍、wiki网页，或者是已经上过几节机器学习课程，但是他们并没有真正地了解机器学习。他们在学习过程感到沮丧是因为他们得到的建议往往是针对中级或高级阶段的。</p>

<p>初学者需要的是一个感性的认识而不是纯粹的代码、教科书、课程。他们首先需要对机器学习有一个是什么、为什么、怎么做的认识以此为接下来的阶段学习奠定基础。</p>

<ul>
<li>入门书籍：阅读一些为程序员而写的数据挖掘与机器学习的入门书籍，例如《机器学习:实用案例解析》、《集体智慧编程》、《数据挖掘:实用机器学习工具和技术》，这些都是很好的入门书籍，推荐一篇进一步讨论这个话题的文章：《机器学习的最佳入门学习资源》</li>
<li>相关概述视频：也可以看一些科普性质的机器学习演讲。例如： 《采访Tom Mitchel》、《Peter Norvig 在Facebook的大数据演讲》</li>
<li>与人交谈：与机器学习领域的老手交流，问问他们是如何入门的，有什么资源值得推荐，是什么让他们对机器学习如此狂热。</li>
<li>机器学习课程101：我总结了一些关于入门的观点，《为初学者准备的机器学习课程101》，如果你喜欢可以看一看。</li>
</ul>

<h3 id="toc_2">新手阶段</h3>

<p>新手是指那些已经对机器学习有一定了解的人，他们已经阅读过一些专业书籍或者是接受过完整地课程学习，并且对这个东西有很大的兴趣想做更深入的了解，想通过进一步学习去解决他们所面临的问题。</p>

<p>下面是给新手的一些资料或者建议：</p>

<ul>
<li>完成一门课程：完整地学习一门机器学习的课程，例如斯坦福大学的机器学习课程。多做课程笔记，尽可能地完成课程作业，多问问题。</li>
<li>阅读一些书籍：这里指的不是教科书，而是为上面所列举的为程序员初学者所准备的书籍。</li>
<li>掌握一门工具：学会使用一门分析工具或者类库，例如python的机器学习包Scikit-Learn、java的机器学习包WEKA、R语言或者其他类似的。具体地说，学习如何使用你在课程或书本上学来的算法，看看它们处理问题的实际效果。</li>
<li>写一写代码：动手实现一些简单的算法，例如感知机、K近邻、线性回归。试图写一些小程序去阐述你对这些算法的理解。</li>
<li>学习相关教程：完整地跟一门教程，为你所完成的小项目建立一个文件夹，其中包含数据集、脚本代码等，以便你可以随时回顾并有所收获。</li>
</ul>

<h3 id="toc_3">中级阶段</h3>

<p>在新手阶段已经阅读过一些专业书籍并完成了一些专业课程，这些人已经懂得如何使用机器学习相关的工具，并且也已经为实现机器学习算法和完成一些教程写过不少的代码了。中级阶段其实是一个自我突破的过程，可以通过建立自己的项目去探索新的技巧并在社区的交流互动中获取更多的知识。</p>

<p>中级阶段的目标是学习如何实现并使用准确、合适、健壮机器学习算法。同样，他们也在数据预处理、数据清洗、归纳总结上花了不少时间，并思考这些数据能解决什么问题。</p>

<p>下面是给中级学习者的一些资料或者建议：</p>

<ul>
<li>建立自己的小项目：自己设计小型的编程项目或者是应用机器学习算法解决问题的小实验。这就像是为探索你自己所感兴趣的技术而设计一些教程。你可以自己实现一个算法或者是提供一些实现这些算法类库的链接。</li>
<li>数据分析：习惯于从数据集中探索并总结。知道什么时候该用什么工具，获取用于探索、学习相关技术的数据。</li>
<li>阅读教科书：阅读并消化机器学习相关的教科书。这可能对理解用数学方式描述相关技术的能力有一定的要求，并且需要了解用公式的方式去对描述问题和算法。</li>
<li>编写你自己的工具：为开源的机器学习平台或类库编写插件和相关的程序包。这是学习如何实现健壮的、能用于生产环境下的算法的一个很好的锻炼机会。将你的程序包运用到项目中，将代码提交给社区进行代码审核，如果可能的话，努力将你的程序发布到开源的平台上，从大家的反馈中进一步学习。</li>
<li>竞赛：参加与机器学习有关的比赛，比如与机器学习会议有关的，或者是提供像Kaggle这样的平台的比赛。参与讨论、提问题，学习其他参赛者是如何解决问题的。将这些项目、方法和代码添加到你的项目库中。</li>
</ul>

<h3 id="toc_4">高级阶段</h3>

<p>机器学习的高级玩家是那些已经整理过大量机器学习算法或者是自己独立实现算法的人。他们或许参加过机器学习的竞赛又或许写过机器学习的程序包。他们已经阅读过许多书籍、学习过许多相关课程，对这一领域有较充分的认识，同时对自己研究的几个关键技术有很深入的了解。</p>

<p>这些高级使用者平时负责生产环境下的机器学习系统的建立、部署和维护。他们能时刻紧跟这个行业的最新动态，通过自己或他人的一线开发经验发现并了解每一种机器学习技术的细微差距。</p>

<p>下面是给高级阶段学习者的一些资料：</p>

<ul>
<li>定制开发算法：根据业务需求定制开发算法，实现会议、期刊论文中关于某个相似问题的算法。</li>
<li>自己设计算法：设计全新的算法去解决工作中 遇到的问题，这样做的目的更多的是为工作中所面临的困难找到最佳的解决方案，而不是进行该领域的前沿研究。</li>
<li>案例学习：阅读甚至是重新设计机器学习竞赛或者是其他参赛者所提供的实际案例。这些一直在谈“我是如何做到”的论文或文章中总是塞满了关于数据准备、工程实践以及使用技术的微妙技巧。</li>
<li>方法论：总结处理问题的过程并系统化，可以正式地分享出来也可以仅仅是作为个人总结。他们总有一套自己解决问题的思路并且不断地提炼和改进处理过程，试图用更好的技术来或得最佳实践。</li>
<li>学术研究：参加学术会议，阅读研究论文和学术专著，与机器学习领域的专家交流学习。他们会记录工作中所积累的经验发布到相关的期刊或者自己博客上，然后回到工作岗位继续研究。</li>
</ul>

<p>知识在不断地收获，但学习永无止境。在机器学习的征途中遇到问题时你可以随时停住脚步自己钻研问题自行解决，或者绕道而行查阅资料借用群体智慧，事实上，我希望绕道而行成为一种常态。</p>

<p>这样的学习阶段划分是以程序员的角度来规划的，这可以作为技术人员实现从入门到精通的一条线性学习路线。我很乐意收到对于这篇文章的批评建议，这样可以使文章变得更好。在特定的学习阶段你可以得到更多的学习资源，因为针对每个阶段所推荐的学习资源也仅仅是我个人的建议。</p>

<hr/>

<h2 id="toc_5">最简明入门指南</h2>

<p>在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！</p>

<p>本指南的读者对象是所有对机器学习有求知欲但却不知道如何开头的朋友。我猜很多人已经读过了“机器学习”的维基百科词条，倍感挫折，以为没人能给出一个高层次的解释。本文就是你们想要的东西。</p>

<p>本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于ML更感兴趣，任务也就完成了。</p>

<h3 id="toc_6">何为机器学习？</h3>

<p>机器学习这个概念认为，对于待解问题，你无需编写任何专门的程序代码，遗传算法（generic algorithms）能够在数据集上为你得出有趣的答案。对于遗传算法，不用编码，而是将数据输入，它将在数据之上建立起它自己的逻辑。</p>

<p>举个例子，有一类算法称为分类算法，它可以将数据划分为不同的组别。一个用来识别手写数字的分类算法，不用修改一行代码，就可以用来将电子邮件分为垃圾邮件和普通邮件。算法没变，但是输入的训练数据变了，因此它得出了不同的分类逻辑。</p>

<p><img src="./_resources/mlg1.jpg" alt="mlg1"/></p>

<p>机器学习算法是个黑盒，可以重用来解决很多不同的分类问题。</p>

<p>“机器学习”是一个涵盖性术语，覆盖了大量类似的遗传算法。</p>

<h3 id="toc_7">两类机器学习算法</h3>

<p>你可以认为机器学习算法分为两大类：<strong>监督式学习（Supervised Learning）</strong>和<strong>非监督式学习（Unsupervised Learning）</strong>。两者区别很简单，但却非常重要。</p>

<h4 id="toc_8">监督式学习</h4>

<p>假设你是一名房产经纪，生意越做越大，因此你雇了一批实习生来帮你。但是问题来了——你可以看一眼房子就知道它到底值多少钱，实习生没有经验，不知道如何估价。</p>

<p>为了帮助你的实习生（也许是为了解放你自己去度个假），你决定写个小软件，可以根据房屋大小、地段以及类似房屋的成交价等因素来评估你所在地区房屋的价值。</p>

<p>你把3个月来城里每笔房屋交易都写了下来，每一单你都记录了一长串的细节——卧室数量、房屋大小、地段等等。但最重要的是，你写下了最终的成交价：</p>

<p>这是我们的“训练数据”。</p>

<p><img src="./_resources/mlg2.jpg" alt="mlg2"/></p>

<p>我们要利用这些训练数据来编写一个程序来估算该地区其他房屋的价值：</p>

<p><img src="./_resources/mlg3.jpg" alt="mlg3"/></p>

<p>这就称为监督式学习。你已经知道每一栋房屋的售价，换句话说，你知道问题的答案，并可以反向找出解题的逻辑。</p>

<p>为了编写软件，你将包含每一套房产的训练数据输入你的机器学习算法。算法尝试找出应该使用何种运算来得出价格数字。</p>

<p>这就像是算术练习题，算式中的运算符号都被擦去了：</p>

<p><img src="./_resources/mlg4.jpg" alt="mlg4"/></p>

<p>看了这些题，你能明白这些测验里面是什么样的数学问题吗？你知道，你应该对算式左边的数字“做些什么”以得出算式右边的答案。</p>

<p>在监督式学习中，你是让计算机为你算出数字间的关系。而一旦你知道了解决这类特定问题所需要的数学方法后，你就可以解答同类的其它问题了。</p>

<h4 id="toc_9">非监督式学习</h4>

<p>让我们回到开头那个房地产经纪的例子。要是你不知道每栋房子的售价怎么办？即使你所知道的只是房屋的大小、位置等信息，你也可以搞出很酷的花样。这就是所谓的非监督式学习。</p>

<p><img src="./_resources/mlg5.jpg" alt="mlg5"/></p>

<p>即使你不是想去预测未知的数据（如价格），你也可以运用机器学习完成一些有意思的事。<br/>
这就有点像有人给你一张纸，上面列出了很多数字，然后对你说:“我不知道这些数字有什么意义，也许你能从中找出规律或是能将它们分类，或是其它什么-祝你好运！”</p>

<p>你该怎么处理这些数据呢？首先，你可以用个算法自动地从数据中划分出不同的细分市场。也许你会发现大学附近的买房者喜欢户型小但卧室多的房子，而郊区的买房者偏好三卧室的大户型。这些信息可以直接帮助你的营销。</p>

<p>你还可以作件很酷的事，自动找出房价的离群数据，即与其它数据迥异的值。这些鹤立鸡群的房产也许是高楼大厦，而你可以将最优秀的推销员集中在这些地区，因为他们的佣金更高。</p>

<p>本文余下部分我们主要讨论监督式学习，但这并不是因为非监督式学习用处不大或是索然无味。实际上，随着算法改良，不用将数据和正确答案联系在一起，因此非监督式学习正变得越来越重要。</p>

<p>老学究请看:还有很多其它种类的机器学习算法。但初学时这样理解不错了。</p>

<h3 id="toc_10">太酷了，但是评估房价真能被看作“学习”吗？</h3>

<p>作为人类的一员，你的大脑可以应付绝大多数情况，并且没有任何明确指令也能够学习如何处理这些情况。如果你做房产经纪时间很长，你对于房产的合适定价、它的最佳营销方式以及哪些客户会感兴趣等等都会有一种本能般的“感觉”。强人工智能（Strong AI）研究的目标就是要能够用计算机复制这种能力。</p>

<p>但是目前的机器学习算法还没有那么好——它们只能专注于非常特定的、有限的问题。也许在这种情况下，“学习”更贴切的定义是“在少量范例数据的基础上找出一个等式来解决特定的问题”。</p>

<p>不幸的是，“机器在少量范例数据的基础上找出一个等式来解决特定的问题”这个名字太烂了。所以最后我们用“机器学习”取而代之。</p>

<p>当然，要是你是在50年之后来读这篇文章，那时我们已经得出了强人工智能算法，而本文看起来就像个老古董。未来的人类，你还是别读了，叫你的机器仆人给你做份三明治吧。</p>

<h3 id="toc_11">让我们写代码吧!</h3>

<p>前面例子中评估房价的程序，你打算怎么写呢？往下看之前，先思考一下吧。</p>

<p>如果你对机器学习一无所知，很有可能你会尝试写出一些基本规则来评估房价，如下：</p>

<pre><code>def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
  price = 0

  # In my area, the average house costs $200 per sqft
  price_per_sqft = 200

  if neighborhood == &quot;hipsterton&quot;:
    # but some areas cost a bit more
    price_per_sqft = 400

  elif neighborhood == &quot;skid row&quot;:
    # and some areas cost less
    price_per_sqft = 100

  # start with a base price estimate based on how big the place is
  price = price_per_sqft * sqft

  # now adjust our estimate based on the number of bedrooms
  if num_of_bedrooms == 0:
    # Studio apartments are cheap
    price = price — 20000
  else:
    # places with more bedrooms are usually
    # more valuable
    price = price + (num_of_bedrooms * 1000)

 return price
</code></pre>

<p>假如你像这样瞎忙几个小时，也许会取得一点成效，但是你的程序永不会完美，而且当价格变化时很难维护。</p>

<p>如果能让计算机找出实现上述函数功能的办法，这样岂不更好？只要返回的房价数字正确，谁会在乎函数具体干了些什么呢？</p>

<pre><code>def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
  price = &lt;computer, plz do some math for me&gt;

  return price
</code></pre>

<p>考虑这个问题的一种角度是将房价看做一碗美味的汤，而汤中成分就是卧室数、面积和地段。如果你能算出每种成分对最终的价格有多大影响，也许就能得到各种成分混合起来形成最终价格的具体比例。</p>

<p>这样可以将你最初的程序（全是疯狂的if else语句）简化成类似如下的样子：</p>

<pre><code>def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
 price = 0

 # a little pinch of this
 price += num_of_bedrooms * .841231951398213

 # and a big pinch of that
 price += sqft * 1231.1231231

 # maybe a handful of this
 price += neighborhood * 2.3242341421

 # and finally, just a little extra salt for good measure
 price += 201.23432095

 return price
</code></pre>

<p>请注意那些用粗体标注的神奇数字——.841231951398213, 1231.1231231,2.3242341421, 和201.23432095。它们称为权重。如果我们能找出对每栋房子都适用的完美权重，我们的函数就能预测所有的房价！</p>

<p>找出最佳权重的一种笨办法如下所示：</p>

<h4 id="toc_12">步骤1</h4>

<p>首先，将每个权重都设为1.0：</p>

<pre><code>def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
  price = 0

  # a little pinch of this
  price += num_of_bedrooms * 1.0

  # and a big pinch of that
  price += sqft * 1.0

  # maybe a handful of this
  price += neighborhood * 1.0

  # and finally, just a little extra salt for good measure
  price += 1.0

  return price
</code></pre>

<h4 id="toc_13">步骤2</h4>

<p>将每栋房产带入你的函数运算，检验估算值与正确价格的偏离程度：</p>

<p><img src="./_resources/mlg6.jpg" alt="mlg6"/></p>

<p>例如：上表中第一套房产实际成交价为25万美元，你的函数估价为17.8万，这一套房产你就差了7.2万。</p>

<p>再将你的数据集中的每套房产估价偏离值平方后求和。假设数据集中有500套房产交易，估价偏离值平方求和总计为86,123,373美元。这就反映了你的函数现在的“正确”程度。</p>

<p>现在，将总计值除以500，得到每套房产的估价偏离平均值。将这个平均误差值称为你函数的代价。</p>

<p>如果你能调整权重使得这个代价变为0，你的函数就完美了。它意味着，根据输入的数据，你的程序对每一笔房产交易的估价都是分毫不差。而这就是我们的目标——尝试不同的权重值以使代价尽可能的低。</p>

<h4 id="toc_14">步骤3</h4>

<p>不断重复步骤2，尝试所有可能的权重值组合。哪一个组合使得代价最接近于0，它就是你要使用的，你只要找到了这样的组合，问题就得到了解决!</p>

<h4 id="toc_15">思想扰动时间</h4>

<p>这太简单了，对吧？想一想刚才你做了些什么。你取得了一些数据，将它们输入至三个通用的简单步骤中，最后你得到了一个可以对你所在区域的房屋进行估价的函数。房价网，要当心咯！<br/>
但是下面的事实可能会扰乱你的思想：</p>

<ol>
<li>过去40年来，很多领域（如语言学/翻译学）的研究表明，这种通用的“搅动数据汤”（我编造的词）式的学习算法已经胜过了需要利用真人明确规则的方法。机器学习的“笨”办法最终打败了人类专家。</li>
<li>你最后写出的函数真是笨，它甚至不知道什么是“面积”和“卧室数”。它知道的只是搅动，改变数字来得到正确的答案。</li>
<li>很可能你都不知道为何一组特殊的权重值能起效。所以你只是写出了一个你实际上并不理解却能证明的函数。</li>
<li>试想一下，你的程序里没有类似“面积”和“卧室数”这样的参数，而是接受了一组数字。假设每个数字代表了你车顶安装的摄像头捕捉的画面中的一个像素，再将预测的输出不称为“价格”而是叫做“方向盘转动度数”，这样你就得到了一个程序可以自动操纵你的汽车了！</li>
</ol>

<p>太疯狂了，对吧？</p>

<h4 id="toc_16">步骤3中的“尝试每个数字”怎么回事？</h4>

<p>好吧，当然你不可能尝试所有可能的权重值来找到效果最好的组合。那可真要花很长时间，因为要尝试的数字可能无穷无尽。</p>

<p>为避免这种情况，数学家们找到了很多聪明的办法来快速找到优秀的权重值，而不需要尝试过多。下面是其中一种：</p>

<p>首先，写出一个简单的等式表示前述步骤2：</p>

<p>这是你的代价函数。</p>

<p><img src="./_resources/mlg7.jpg" alt="mlg7"/></p>

<p>接着，让我们将这同一个等式用机器学习的数学术语（现在你可以忽略它们）进行重写：</p>

<p>θ表示当前的权重值。 J(θ) 意为“当前权重值对应的代价”。</p>

<p><img src="./_resources/mlg8.jpg" alt="mlg8"/></p>

<p>这个等式表示我们的估价程序在当前权重值下偏离程度的大小。如果将所有赋给卧室数和面积的可能权重值以图形形式显示，我们会得到类似下图的图表：</p>

<p><img src="./_resources/mlg9.jpg" alt="mlg9"/></p>

<p>代价函数的图形像一支碗。纵轴表示代价。</p>

<p>图中蓝色的最低点就是代价最低的地方——即我们的程序偏离最小。最高点意味着偏离最大。所以，如果我们能找到一组权重值带领我们到达图中的最低点，我们就找到了答案！</p>

<p><img src="./_resources/mlg10.jpg" alt="mlg10"/></p>

<p>因此，我们只需要调整权重值使我们在图上能向着最低点“走下坡路”。如果对于权重的细小调节能一直使我们保持向最低点移动，那么最终我们不用尝试太多权重值就能到达那里。</p>

<p>如果你还记得一点微积分的话，你也许记得如果你对一个函数求导，结果会告诉你函数在任一点的斜率。换句话说，对于图上给定一点，它告诉我们那条路是下坡路。我们可以利用这一点朝底部进发。</p>

<p>所以，如果我们对代价函数关于每一个权重求偏导，那么我们就可以从每一个权重中减去该值。这样可以让我们更加接近山底。一直这样做，最终我们将到达底部，得到权重的最优值。（读不懂？不用担心，接着往下读）。</p>

<p>这种找出最佳权重的办法被称为批量梯度下降，上面是对它的高度概括。如果想搞懂细节，不要害怕，继续深入下去吧。</p>

<p>当你使用机器学习算法库来解决实际问题，所有这些都已经为你准备好了。但明白一些具体细节总是有用的。</p>

<h3 id="toc_17">还有什么你随便就略过了？</h3>

<p>上面我描述的三步算法被称为多元线性回归。你估算等式是在求一条能够拟合所有房价数据点的直线。然后，你再根据房价在你的直线上可能出现的位置用这个等式来估算从未见过的房屋的价格。这个想法威力强大，可以用它来解决“实际”问题。</p>

<p>但是，我为你展示的这种方法可能在简单的情况下有效，它不会在所有情况下都有用。原因之一是因为房价不会一直那么简单地跟随一条连续直线。</p>

<p>但是，幸运的是，有很多办法来处理这种情况。对于非线性数据，很多其他类型的机器学习算法可以处理（如神经网络或有核向量机）。还有很多方法运用线性回归更灵活，想到了用更复杂的线条来拟合。在所有的情况中，寻找最优权重值这一基本思路依然适用。</p>

<p>还有，我忽略了过拟合的概念。很容易碰上这样一组权重值，它们对于你原始数据集中的房价都能完美预测，但对于原始数据集之外的任何新房屋都预测不准。这种情况的解决之道也有不少（如正则化以及使用交叉验证数据集）。学会如何处理这一问题对于顺利应用机器学习至关重要。</p>

<p>换言之，基本概念非常简单，要想运用机器学习得到有用的结果还需要一些技巧和经验。但是，这是每个开发者都能学会的技巧。</p>

<h3 id="toc_18">机器学习法力无边吗？</h3>

<p>一旦你开始明白机器学习技术很容易应用于解决貌似很困难的问题（如手写识别），你心中会有一种感觉，只要有足够的数据，你就能够用机器学习解决任何问题。只需要将数据输入进去，就能看到计算机变戏法一样找出拟合数据的等式。</p>

<p>但是很重要的一点你要记住，机器学习只能对用你占有的数据实际可解的问题才适用。</p>

<p>例如，如果你建立了一个模型来根据每套房屋内盆栽数量来预测房价，它就永远不会成功。房屋内盆栽数量和房价之间没有任何的关系。所以，无论它怎么去尝试，计算机也推导不出两者之间的关系。</p>

<p><img src="./_resources/mlg11.jpg" alt="mlg11"/></p>

<p>你只能对实际存在的关系建模。</p>

<h3 id="toc_19">怎样深入学习机器学习</h3>

<p>我认为，当前机器学习的最大问题是它主要活跃于学术界和商业研究组织中。对于圈外想要有个大体了解而不是想成为专家的人们，简单易懂的学习资料不多。但是这一情况每一天都在改善。</p>

<p>吴恩达教授（Andrew Ng）在Coursera上的机器学习免费课程非常不错。我强烈建议由此入门。任何拥有计算机科学学位、还能记住一点点数学的人应该都能理解。</p>

<p>另外，你还可以下载安装SciKit-Learn，用它来试验成千上万的机器学习算法。它是一个python框架，对于所有的标准算法都有“黑盒”版本。</p>

<h2 id="toc_20">如何选择机器学习算法</h2>

<p>常规指南，经验之谈</p>

<p><strong>训练集有多大？</strong></p>

<p>小训练集：高偏差/低方差的分类器(比如朴素贝叶斯)要比低偏差/高方差的分类器(比如k最近邻)具有优势，因为后者容易过拟合。然而随着训练集的增大，低偏差/高方差的分类器将开始具有优势(更低的渐进误差)，因为高偏差分类器对于提供准确模型不那么给力</p>

<p>这一点也可以看做是生成模型和判别模型的差别</p>

<p><strong>常用算法的优缺点</strong></p>

<p>朴素贝叶斯: 巨尼玛简单，你只要做些算术就好了。倘若条件独立性假设确实满足，朴素贝叶斯分类器将会比判别模型，譬如逻辑回归收敛得更快，因此你只需要更少的训练数据。就算该假设不成立，朴素贝叶斯分类器在实践中仍然有着不俗的表现。如果你需要的是快速简单并且表现出色，这将是个不错的选择。其主要缺点是它学习不了特征间的交互关系（比方说，它学习不了你虽然喜欢甄子丹和姜文的电影，却讨厌他们共同出演的电影《关云长》的情况）。</p>

<p>逻辑回归: 有很多正则化模型的方法，而且你不必像在用朴素贝叶斯那样担心你的特征是否相关。与决策树与支持向量机相比，你还会得到一个不错的概率解释，你甚至可以轻松地利用新数据来更新模型（使用在线梯度下降算法）。如果你需要一个概率架构（比如简单地调节分类阈值，指明不确定性，或者是要得得置信区间），或者你以后想将更多的训练数据快速整合到模型中去，使用它吧。</p>

<p>决策树: 易于解释说明。它可以毫无压力地处理特征间的交互关系并且是非参数化的，因此你不必担心异常值或者数据是否线性可分（举个例子，决策树能轻松处理好类别A在某个特征维度x的末端，类别B在中间，然后类别A又出现在特征维度x前端的情况）。它的一个缺点就是不支持在线学习，于是在新样本到来后，决策树需要全部重建。另一个缺点是容易过拟合，但这也就是诸如随机森林（或提升树）之类的集成方法的切入点。另外，随机森林经常是很多分类问题的赢家（通常比支持向量机好上那么一点，我认为），它快速并且可调，同时你无须担心要像支持向量机那样调一大堆参数，所以最近它貌似相当受欢迎。</p>

<p>支持向量机: 高准确率，为避免过拟合提供了很好的理论保证，而且就算数据在原特征空间线性不可分，只要给个合适的核函数，它就能运行得很好。在动辄超高维的文本分类问题中特别受欢迎。可惜内存消耗大，难以解释，运行和调参也有些烦人，所以我认为随机森林要开始取而代之了。</p>

<p><strong>但是</strong></p>

<p>尽管如此，回想一下，好的数据却要优于好的算法，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响（此时就根据速度和易用性来进行抉择）。</p>

<h2 id="toc_21">不大明白的部分</h2>

<ul>
<li>SVM</li>
<li>AdaBoost</li>
</ul>

<p>只要学习机器学习，一定会看的书籍我推荐一下:</p>

<ul>
<li>Mitchell 的《机器学习》。Mitchell是机器学习的鼻祖，第一个提出机器学习概念的人。这本书很薄，很简单。内容很陈旧，但是都是机器学习的经典问题。而且，这本书概念清晰正确(很可贵啊，又简单又正确的书，说明作者功力很强)。</li>
<li>Simon Haykin的《神经网络与机器学习》。 事实上，现在常见的很多机器学习算法都发端于神经网络，像SVM，深度学习，CNN等等。这本书详细的介绍了神经网络及其相关算法的所有细节。如果想深入了解的话，可以看一下。只想运用的话，也可以随便翻翻算法的介绍。</li>
<li>AIMA，《人工智能：一种现代的方法》。基本上学术界的人们都认为机器学习是人工智能学科的下属分支(另一部分人认为是统计学或者数学的分支)，所以，一本人工智能的书也是学习机器学习可以参考的方面。</li>
</ul>

<hr/>

<h2 id="toc_22">一天玩转机器学习</h2>

<p>步骤</p>

<ol>
<li>下载Anaconda套件，把python和195个库一键安装，<a href="http://t.cn/z8BFH8S%EF%BC%8C%E4%B8%8D%E5%BF%85%E8%87%AA%E5%B7%B1%E6%8A%98%E8%85%BE%E5%90%84%E7%A7%8D%E5%8C%85%E5%AE%89%E8%A3%85%E4%BA%86%EF%BC%9B">http://t.cn/z8BFH8S，不必自己折腾各种包安装了；</a></li>
<li>复制这儿的scikit-learn的notebook教程， <a href="http://t.cn/RANQ9SD%EF%BC%8C">http://t.cn/RANQ9SD，</a> 运行 ipython notebook打开.ipynb文件开始边看边学吧</li>
</ol>

<p>Anaconda is a completely free Python distribution (including for commercial use and redistribution). It includes over 195 of the most popular Python packages for science, math, engineering, data analysis.</p>

<h3 id="toc_23">Linux</h3>

<p>INSTALLATION</p>

<p>After downloading the installer, in the shell execute:</p>

<pre><code>bash Anaconda-2.2.0-Linux-x86_64.sh
</code></pre>

<p>Note that you should type <q>bash</q>, regardless of whether or not you are actually using the bash shell.</p>

<h3 id="toc_24">Mac</h3>

<p>NSTALLATION</p>

<p>After downloading the installer, double click the .pkg file and follow the instructions on the screen.</p>

<p>COMMAND-LINE INSTALLS:</p>

<p>After downloading the installer, in the shell execute:</p>

<pre><code>bash Anaconda-2.2.0-MacOSX-x86_64.sh
</code></pre>

<p>Note that you should type <q>bash</q>, regardless of whether or not you are actually using the bash shell.</p>

<h2 id="toc_25">数据挖掘中的九种错误</h2>

<p>只关注训练数据 训练样本之外的数据才是真正 重要的。安德森医疗中心的研究人员在十年前使用神经网络来检测癌症。相对于训练样本，他们的检验样本表现不佳，但还算不错的。但他们认为应该加大神经网络 的训练时间，结果检验样本的表现比以前更为糟糕。这就是一个很典型的过度拟合的案例。避免过度拟合的重要手段是保留数据。一些有用的方法包括：自举法 （bootstrap）、多重交叉检验（cross-validation）、刀切法（jackknife）、留一法（leave-one-out）。</p>

<p>只依赖一种技术 有 句老话说：如果你手里只有一把锤子，那么看任何东西都象是一个钉子。在不同的问题背景下，模型的效果是不同的，你必须有一整套工具才能从中选择一种最优 的。对同一个问题，至少你得比较新旧两种方法的优劣。相对于专业知识和数据的优良性，单一的建模技术不一定能解决很大问题。John Elder等人在1997年用五种算法对六类数据集进行了比较研究，结果发现没有一种算法能够通吃所有的数据。所以说，一把钥匙开一把锁。</p>

<p>错误的建模目标 计算机只能理解你的算法，但没法理解现实中的问题。只有依靠人的背景知识才能将问题“翻译”成适当的算法。例如建模中通常的目标是使误差平方和最小化，但这在股票收益预测中就不一定合适。所以对于特定的问题需要订制特定的评估函数。</p>

<p>只关注数据本身 数据挖掘者认为，要让数据自己说话，不要被先验的知识所约束。但这句话有时候却是错误的，因为现实中的数据只是现实世界一种映射和抽样，其中可能包括了实验错误、观察错误、记录错误等等。如果你完全相信数据而不借助于专业背景知识，你得出的结论也往往是荒谬的。</p>

<p>错误的输入变量 曾 经有一家咨询公司建立了一个投资模型以预测市场的变动，其准确率居然高达70%。后来发现该模型只是一个简单的三日均线，而且它的模型里用未来的价格来预 测今天的价格，这显然是荒诞可笑的。一般来讲，模型的准确率如果出奇的高，你需要仔细检查输入变量中是否包括了不应有的未来指标。</p>

<p>删除异常样本 异 常值和杠杆点会极大地影响模型结果和趋势。然而，你不能随意删除它们，因为这异常值可能意味着惊人的发现。统计学家John Aitchison就回顾多年前他在研究南极上空辐射水平时，曾将一个峰值作为误差删除掉。但事实上，这个异常的峰值揭示了南极上空臭氧层空洞的存在。所 以在建模时，进行数据可视化能有助于判断研究中异常值的特性。</p>

<p>简单外推 在 线性回归中，我们用一条线将一些点连接起来，然后估计这些已知点之间的值，这是合理的，但在已知数据的边界之外进行估计是危险的，特别是对于非线性模型， 这种简单的外推更是不可取的。除此之外，还有另一类形式的“外推”也是不合理的，例如从小样本中得到的特征外推到大样本中，从低维空间中得到的结论外推到 高维空间中。</p>

<p>错误的抽样 有很多数据挖掘问题中，感兴趣的样本数总是罕见的。例如信用卡欺诈问题，欺诈发生的数量相对于整体数据几乎就是沧海一栗。但很多算法对于这种非平衡数据是没有多大效果的。所以一种方法就是将罕见的样本进行再抽样，以人工形成平衡。但随意这样再平衡也是错误的。</p>

<p>对模型过于相信 正如George Box说过，所有的模型都是错误的，但有些是有用的。</p>

<hr/>

<h2 id="toc_26">十张图解释机器学习的基本概念</h2>

<p>在解释机器学习的基本概念的时候，我发现自己总是回到有限的几幅图中。以下是我认为最有启发性的条目列表。</p>

<p><img src="./_resources/tenml1.jpg" alt="tenm" class="mw_img_left" style="width:1px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Test and training error: 为什么低训练误差并不总是一件好的事情呢：ESL 图2.11.以模型复杂度为变量的测试及训练错误函数。</p>

<hr/>

<p><img src="./_resources/tenml2.jpg" alt="tenm" class="mw_img_left" style="width:2px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Under and overfitting: 低度拟合或者过度拟合的例子。PRML 图1.4.多项式曲线有各种各样的命令M，以红色曲线表示，由绿色曲线适应数据集后生成。</p>

<hr/>

<p><img src="./_resources/tenml3.jpg" alt="tenm" class="mw_img_left" style="width:3px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Occam’s razor</p>

<p>ITILA 图28.3.为什么贝叶斯推理可以具体化奥卡姆剃刀原理。这张图给了为什么复杂模型原来是小概率事件这个问题一个基本的直观的解释。水平轴代表了可能的数据集D空间。贝叶斯定理以他们预测的数据出现的程度成比例地反馈模型。这些预测被数据D上归一化概率分布量化。数据的概率给出了一种模型Hi,P(D|Hi)被称作支持Hi模型的证据。一个简单的模型H1仅可以做到一种有限预测，以P(D|H1)展示；一个更加强大的模型H2，举例来说，可以比模型H1拥有更加自由的参数，可以预测更多种类的数据集。这也表明，无论如何，H2在C1域中对数据集的预测做不到像H1那样强大。假设相等的先验概率被分配给这两种模型，之后数据集落在C1区域，不那么强大的模型H1将会是更加合适的模型。</p>

<hr/>

<p><img src="./_resources/tenml4.jpg" alt="tenm" class="mw_img_left" style="width:4px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Feature combinations：</p>

<p>(1)为什么集体相关的特征单独来看时无关紧要，这也是（2）线性方法可能会失败的原因。从Isabelle Guyon特征提取的幻灯片来看。</p>

<hr/>

<p><img src="./_resources/tenml5.jpg" alt="tenm" class="mw_img_left" style="width:5px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Irrelevant features:</p>

<p>为什么无关紧要的特征会损害KNN，聚类，以及其它以相似点聚集的方法。左右的图展示了两类数据很好地被分离在纵轴上。右图添加了一条不切题的横轴，它破坏了分组，并且使得许多点成为相反类的近邻。</p>

<hr/>

<p><img src="./_resources/tenml6.jpg" alt="tenm" class="mw_img_left" style="width:6px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Basis functions</p>

<p>非线性的基础函数是如何使一个低维度的非线性边界的分类问题，转变为一个高维度的线性边界问题。Andrew Moore的支持向量机SVM(Support Vector Machine)教程幻灯片中有：一个单维度的非线性带有输入x的分类问题转化为一个2维的线性可分的z=(x,x<sup>2)问题。</sup></p>

<hr/>

<p><img src="./_resources/tenml7.jpg" alt="tenm" class="mw_img_left" style="width:7px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Discriminative vs. Generative:</p>

<p>为什么判别式学习比产生式更加简单：PRML 图1.27.这两类方法的分类条件的密度举例，有一个单一的输入变量x（左图），连同相应的后验概率（右图）。注意到左侧的分类条件密度p(x|C1)的模式，在左图中以蓝色线条表示，对后验概率没有影响。右图中垂直的绿线展示了x中的决策边界，它给出了最小的误判率。</p>

<hr/>

<p><img src="./_resources/tenml8.jpg" alt="tenm" class="mw_img_left" style="width:8px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Loss functions:</p>

<p>学习算法可以被视作优化不同的损失函数：PRML 图7.5. 应用于支持向量机中的“铰链”错误函数图形，以蓝色线条表示，为了逻辑回归，随着错误函数被因子1/ln(2)重新调整，它通过点（0，1），以红色线条表示。黑色线条表示误分，均方误差以绿色线条表示。</p>

<hr/>

<p><img src="./_resources/tenml9.jpg" alt="tenm" class="mw_img_left" style="width:9px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Geometry of least squares:</p>

<p>ESL 图3.2.带有两个预测的最小二乘回归的N维几何图形。结果向量y正交投影到被输入向量x1和x2所跨越的超平面。投影y<sup>代表了最小二乘预测的向量。</sup></p>

<hr/>

<p><img src="./_resources/tenml10.jpg" alt="tenm" class="mw_img_left" style="width:10px;display: block; float: left; margin: 0px 8px 8px 0px;"/></p>

<p>Sparsity:</p>

<p>为什么Lasso算法（L1正规化或者拉普拉斯先验）给出了稀疏的解决方案（比如：带更多0的加权向量）：ESL 图3.11.lasso算法的估算图像(左)以及岭回归算法的估算图像（右）。展示了错误的等值线以及约束函数。分别的，当红色椭圆是最小二乘误差函数的等高线时，实心的蓝色区域是约束区域|β1| + |β2| ≤ t以及β1<sup>2^</sup> + β2<sup>2^</sup> ≤ t2。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007861.html">
                
                  <h1>机器学习基石 学习笔记</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Hsuan-Tien Lin <a href="mailto:htlin@csie.ntu.edu.tw">htlin@csie.ntu.edu.tw</a></p>

<!-- MarkdownTOC -->

<ul>
<li>Roadmap</li>
<li>Lecture 1 The Learning Problem

<ul>
<li>从学习到机器学习</li>
<li>Machine Learning

<ul>
<li>三个关键</li>
</ul></li>
<li>学习问题</li>
</ul></li>
<li>Lecture 2 Learn to Answer Yes/No

<ul>
<li>select g from H</li>
<li>Perceptron Learning Algorithm</li>
<li>Cyclic PLA</li>
<li>Linear Separability 线性可分</li>
<li>PLA Fact: W~t~ Gets More Aligned with W~f~</li>
<li>PLA Fact: W~t~ Does Not Grow Too</li>
<li>一个习题</li>
<li>More about PLA</li>
<li>Learning with <strong>Noisy Data</strong></li>
<li>Pocket Algorithm</li>
</ul></li>
<li>Lecture 3: Types of Learning

<ul>
<li>Different Output Space</li>
<li>Different Label</li>
<li>Different Protocol</li>
<li>Different Input Space</li>
</ul></li>
<li>Lecture 4: Feasibility of Learning

<ul>
<li>Hoeffding&#39;s Inequality</li>
<li>Connect to Learning</li>
</ul></li>
<li>Lecture 5: Training versus Testing

<ul>
<li>Two Central Questions</li>
<li>Trade-off on M</li>
<li>Where Did M Come From</li>
<li>How Many Lines Are There?</li>
<li>Effective Number of Lines</li>
<li>Dichotomies: Mini-hypothesis</li>
<li>Growth Function

<ul>
<li>Growth Function for Positive Rays</li>
<li>Growth Fucntion for Positive Intervals</li>
<li>Growth Function for Convex Sets</li>
</ul></li>
<li>The Four Growth Functions

<ul>
<li>Break Point of H</li>
</ul></li>
</ul></li>
<li>Lecture 6: Theory of Generalization

<ul>
<li>Restriction of Break Point</li>
<li>Bounding Function</li>
<li>BAD Bound for General H

<ul>
<li>Step 1: Replace E~out~ by E~in~&#39;</li>
<li>Step 2: Decompose H by Kind</li>
<li>Step 3: Use Hoeffding without Replacement</li>
</ul></li>
<li>Vapnik-Chervonenkis (VC) bound:</li>
</ul></li>
<li>Lecture 7: The VC Dimension

<ul>
<li>More on Vapnik-Chervonenkis(VC) Bound</li>
<li>VC Dimension</li>
<li>VC Dimension and Learning</li>
<li>2D PLA Revisited</li>
<li>VC Dimension of Perceptrons</li>
<li>证明 d~vc~ &gt;= d+1</li>
<li>证明 d~vc~ &lt;= d+1</li>
<li>Degrees of Freedom</li>
<li>VC Bound Rephrase: Penalty for Model Complexity</li>
<li>THE VC Message</li>
<li>VC Bound Rephrase: Sample Complexity</li>
<li>Looseness of VC Bound</li>
</ul></li>
<li>Lecture 8: Noise and Error

<ul>
<li>Target Distribution P(y|x)</li>
<li>Error Measure</li>
<li>Two Important Pointwise Error Measures</li>
<li>Choice of Error Measure</li>
<li>Weighted Classification</li>
<li>Minimizing E~in~ for Weighted Classification</li>
</ul></li>
<li>Lecture 9: Linear Regression

<ul>
<li>The Error Measure</li>
<li>Matrix Form of E~in~(w)</li>
<li>The Gradient ▽E~in~(w)</li>
<li>Optimal Linear Regression Weights</li>
<li>Linear Regression Algorithm</li>
<li>Is Linear Regression a &#39;Learning Algorithm&#39;?</li>
<li>Benefit of Analytic Solution: &#39;Simpler-than-VC&#39; Guarantee</li>
<li>Geometric View of <strong>Hat Matrix</strong></li>
<li>The Learning Curve</li>
<li>Linear Classification vs. Linear Regression</li>
</ul></li>
<li>Lecture 10: Logistic Regression

<ul>
<li>Logistic Function</li>
<li>Three Linear Models</li>
<li>Likelihood</li>
<li>Cross-Entropy Error</li>
<li>Minimizing E~in~(w)</li>
<li>Iterative Optimization</li>
<li>Choice of η</li>
<li>Putting Everything Together</li>
</ul></li>
<li>Lecture 11: Linear Models for Classification

<ul>
<li>Linear Models Revisited</li>
<li>Error-Functions Revisited</li>
<li>Theoretical Implication of Upper Bound</li>
<li>Two Iterative Optimization Schemes</li>
<li>Stochastic Gradient Descent (SGD)</li>
<li>Multiclass Classification</li>
<li>One-Versus-All (OVA) Decomposition</li>
<li>One-versus-one(OVO) Decomposition</li>
</ul></li>
<li>Lecture 12: Nonlinear Transformation

<ul>
<li>Circular Separable</li>
<li>Linear Hypothesis in Z-Space</li>
<li>The Nonlinear Transform Steps</li>
<li>Computation/Storage Price</li>
<li>Model Complexity Price</li>
<li>polynomial Transform Revisited</li>
</ul></li>
<li>Lecture 13: Hazard of Overfitting

<ul>
<li>Case Study</li>
<li>Learning Curves Revisited</li>
<li>A Detailed Experiment</li>
</ul></li>
<li>Lecture 14: Regularization

<ul>
<li>Matrix Form of Regularized Regression Problem</li>
<li>The Lagrange Multiplier</li>
<li>Augmented Error</li>
<li>The Result</li>
<li>Legendre Polynomials</li>
<li>Regularization and VC Theory</li>
<li>Another View of Augmented Error</li>
<li>General Regularizers Ω(w)</li>
<li>L2 and L1 Regularizer</li>
<li>The Optimal λ</li>
</ul></li>
<li>Lecture 15: Validation

<ul>
<li>Comparison between E~in~ and E~test~</li>
<li>The Dilemma about K</li>
<li>Leave-One-Out Cross Validation</li>
<li>Disadvantages of Leave-One-Out Estimate</li>
<li>V-fold Cross Validation</li>
<li>Final Words on Validation</li>
</ul></li>
<li>Lecture 16: Three Learning Principles

<ul>
<li>Occam&#39;s Razor</li>
<li>Simple Model</li>
<li>Sampling Bias</li>
<li>Visual Data Snooping</li>
<li>Dealing with Data Snooping</li>
<li>Power of Three</li>
</ul></li>
</ul>

<!-- /MarkdownTOC -->

<h2 id="toc_0">Roadmap</h2>

<ul>
<li>Lecture 1: The Learning Problem

<ul>
<li><u>A</u> takes <u>D</u> and <u>H</u> to get <u>g</u></li>
</ul></li>
<li>Lecture 2: Learning to Answer Yes/No

<ul>
<li>Perceptron Hypothesis Set</li>
<li>Perceptron Learning Algorithm, PLA</li>
<li>Guarantee of PLA</li>
<li>Non-Separable Data</li>
</ul></li>
<li>Lecture 3: Types of Learning

<ul>
<li>Learning with Different Output Space y

<ul>
<li>[classification],[regression], structured</li>
</ul></li>
<li>Learning with Different Data Lable y~n~

<ul>
<li>[supervised], un/semi-supervised, reinforcement</li>
</ul></li>
<li>Learning with Different Protocol f -&gt; (x~n~,y~n~)

<ul>
<li>[batch], online, active</li>
</ul></li>
<li>Learning with Different Input Space X

<ul>
<li>[concrete], raw, abstract</li>
</ul></li>
</ul></li>
<li>Lecture 4: Feasibility of Learning

<ul>
<li>Learning is Impossible?</li>
<li>Probability to the Rescue</li>
<li>Connection to Learning</li>
<li>Connection to Real Learning</li>
</ul></li>
<li>Lecture 5: Training versus Testing

<ul>
<li>Recap and Preview

<ul>
<li>two questions: E~out~(g) ≈ E~in~(g), and E~in~(g) ≈ 0</li>
</ul></li>
<li>Effective Number of Lines

<ul>
<li>at most 14 through the eye of 4 inputs</li>
</ul></li>
<li>Effective Number of Hypothesis

<ul>
<li>at most m~H~(N) through the eye of N inputs</li>
</ul></li>
<li>Break Point

<ul>
<li>when m~H~(N) becomes &#39;non-exponential&#39;</li>
</ul></li>
</ul></li>
<li>Lecture 6: Theory of Generalization

<ul>
<li>Restriction of Break Point

<ul>
<li>break point &#39;breaks&#39; consequent points</li>
</ul></li>
<li>Bounding Function: Basic Cases

<ul>
<li>B(N, k) bounds m~H~(N) with break point k</li>
</ul></li>
<li>Bounding Function: Inductive Cases

<ul>
<li>B(N, k) is poly(N)</li>
</ul></li>
<li>A Pictorial Proof

<ul>
<li>m~H~(N) can replace M with a few changes</li>
</ul></li>
</ul></li>
<li>Lecture 7: The VC Dimension

<ul>
<li>Definition of VC Dimension

<ul>
<li>maximum non-break point</li>
</ul></li>
<li>VC Dimension of

<ul>
<li>d~vc~(H) = d + 1</li>
</ul></li>
<li>Physical Intuition of VC Dimension

<ul>
<li>d~vc~ ≈ #free parameters</li>
</ul></li>
<li>Interpreting VC Dimension

<ul>
<li>loosely: model complexity &amp; sample complexity</li>
</ul></li>
</ul></li>
<li>Lecture 8: Noise and Error

<ul>
<li>Noise and Probability Target

<ul>
<li>can replace f(x) by P(y|x)</li>
</ul></li>
<li>Error Measure

<ul>
<li>affect &#39;ideal&#39; target</li>
</ul></li>
<li>Algorithmic Error Measure

<ul>
<li>user-dependent -&gt; plausible or friendly</li>
</ul></li>
<li>Weighted Classification

<ul>
<li>easily done by virtual &#39;example copying&#39;</li>
</ul></li>
</ul></li>
<li>Lecture 9: Linear Regression

<ul>
<li>Linear Regression Problem

<ul>
<li>use hyperplanes to approximate real values</li>
</ul></li>
<li>Linear Regression Algorithm

<ul>
<li>analytic solution with pseudo-inverse</li>
</ul></li>
<li>Generalization Issue

<ul>
<li>E~out~ - E~in~ ≈ 2(d+1)/N on average</li>
</ul></li>
<li>Linear Regression for Binary Classification

<ul>
<li>0/1 error &lt;= squared error</li>
</ul></li>
</ul></li>
<li>Lecture 10: Logistic Regression

<ul>
<li>Logistic Regression Problem

<ul>
<li>P(+1|x) as target and θ(w<sup>T<sup>x)</sup></sup> as hypothesis</li>
</ul></li>
<li>Logistic Regression Error

<ul>
<li>cross-entropy(negative log likelihood)</li>
</ul></li>
<li>Gradient of Logistic Regression Error

<ul>
<li>θ-weighted sum of data vectors</li>
</ul></li>
<li>Gradient Descent

<ul>
<li>roll downhill by -▽E~in~(w)</li>
</ul></li>
</ul></li>
<li>Lecture 11: Linear Models for Classification

<ul>
<li>Linear Models for Binary Classification

<ul>
<li>three models useful in different ways</li>
</ul></li>
<li>Stochastic Gradient Descent

<ul>
<li>follow negative stochastic gradient</li>
</ul></li>
<li>Multiclass via Logistic Regression

<ul>
<li>predict with maximum estimated P(k|x)</li>
</ul></li>
<li>Multiclass via Binary Classification

<ul>
<li>predict the tournament champion</li>
</ul></li>
</ul></li>
<li>Lecture 12: Nonlinear Transformation

<ul>
<li>Quadratic Hypothesis

<ul>
<li>linear hypothesis on quadratic-transformed data</li>
</ul></li>
<li>Nonlinear Transform

<ul>
<li>happy linear modeling after Z = ø(X)</li>
</ul></li>
<li>Price of Nonlinear Transform

<ul>
<li>computation/storage/[model complexity]</li>
</ul></li>
<li>Structured Hypothesis Sets

<ul>
<li>linear/simpler model first</li>
</ul></li>
</ul></li>
<li>Lecture 13: Hazard of Overfitting

<ul>
<li>What is Overfitting

<ul>
<li>lower E~in~ but higher E~out~</li>
</ul></li>
<li>The Role of Noise and Data Size

<ul>
<li>overfitting &#39;easily&#39; happens!</li>
</ul></li>
<li>Deterministic Noise

<ul>
<li>what H cannot capture acts like noise</li>
</ul></li>
<li>Dealing with Overfitting

<ul>
<li>data cleaning/pruning/hinting, and more</li>
</ul></li>
</ul></li>
<li>Lecture 14: Regularization

<ul>
<li>Regularized Hypothesis Set

<ul>
<li>original H + constraint</li>
</ul></li>
<li>Weight Decay Regularization

<ul>
<li>add (λ/N)w<sup>T<sup>w</sup></sup> in E~aug~</li>
</ul></li>
<li>Regularization and VC Theory

<ul>
<li>regularization decreases d~EFF~</li>
</ul></li>
<li>General Regularizers

<ul>
<li>target-dependent, [plausible], or [friendly]</li>
</ul></li>
</ul></li>
<li>Lecture 15: Validation

<ul>
<li>Model Selection Problem

<ul>
<li>dangerous by E~in~ and dishonest by E~test~</li>
</ul></li>
<li>Validation

<ul>
<li>select with E~val~(D~train~) while returning A~m*~(D)</li>
</ul></li>
<li>Leave-One-Out Cross Validation

<ul>
<li>huge computation for almost unbiased estimate</li>
</ul></li>
<li>V-Fold Cross Validation

<ul>
<li>reasonable computation and performance</li>
</ul></li>
</ul></li>
<li>Lecture 16: Three Learning Principles

<ul>
<li>Occam&#39;s Razor

<ul>
<li>simple, simple, simple!</li>
</ul></li>
<li>Sampling Bias

<ul>
<li>match test scenario as much as possible</li>
</ul></li>
<li>Data Snooping

<ul>
<li>any use of data is &#39;contamination&#39;</li>
</ul></li>
<li>Power of Three

<ul>
<li>relatives, bounds, models, tools, principles</li>
</ul></li>
</ul></li>
</ul>

<h2 id="toc_1">Lecture 1 The Learning Problem</h2>

<p>从基础学习 what every machine learning user should know</p>

<ul>
<li>When Can Machines Learn? illustrative + technical</li>
<li>Why Can Machines Learn? theoretical + illustrative</li>
<li>How Can Machines Learn? technical + practical</li>
<li>How Can Machines Learn Better? practical + theorietical</li>
</ul>

<p>知其然也知其所以然</p>

<h3 id="toc_2">从学习到机器学习</h3>

<ul>
<li>学习的过程：observations -&gt; <strong>learning</strong> -&gt; skill</li>
<li>机器学习的过程：data -&gt; <strong>ML</strong> -&gt; skill(improved performance measure)</li>
<li>skill: improve some <strong>performance measure</strong></li>
</ul>

<h3 id="toc_3">Machine Learning</h3>

<ul>
<li>improving some perormance mearsure with experience computed from data</li>
<li>an alternative route to build complicated systems</li>
</ul>

<h4 id="toc_4">三个关键</h4>

<ul>
<li>exists some &#39;underlying pattern&#39; to be learned, so performance measure can be improved. 要有东西可学</li>
<li>but no programmable definition, so &#39;ML&#39; is needed</li>
<li>somehow there is data about the pattern. 要有大量数据</li>
</ul>

<h3 id="toc_5">学习问题</h3>

<ul>
<li>输入 x</li>
<li>输出 y</li>
<li>目标函数 target function f: X-&gt;Y</li>
<li>data D={(x~1~,y~1~),(x~2~,y~2~),...,(x~n~,y~n~)}</li>
<li>机器学习可能得到的假设 g:X-&gt;Y</li>
<li><p>{(x~n~, y~n~)} from f -&gt; ML -&gt; g</p>

<p><img src="./_resources/mlf1.jpg" alt="learning flow"/></p></li>
<li><p>f 我们不知道</p></li>
<li><p>g 越接近 f 越好</p></li>
<li><p>A takes D and H to get g</p></li>
<li><p>related to DM, AI and Stats</p></li>
</ul>

<h2 id="toc_6">Lecture 2 Learn to Answer Yes/No</h2>

<ul>
<li>每一个样本的数据可以看成一个向量，可以给每一个向量计算出一个加权得分，每一个维度有一个权重。</li>
<li>把 threshold 收进公式中，可以得到一个统一的表达，最后的得分等于两个向量相乘</li>
<li><img src="./_resources/mlf2.jpg" alt="mlf2"/></li>
<li>perceptrons &lt;-&gt; linear(binary) classifiers 线性分类器</li>
</ul>

<h3 id="toc_7">select g from H</h3>

<ul>
<li>H = all possible perceptrons, g = ? 从这么多可能的线之中，选出一条最好的，最能区分数据的</li>
<li>先要求 g 和 f 在已有数据上结果最接近, g(x~n~) = f(x~n~) = y~n~</li>
<li>难点在于，H 很大，有无数种可能的线(分类器)</li>
<li>从第一条线 g~0~ 开始，不断进行修正，可以认为是一开始的权重向量 w~0~</li>
</ul>

<h3 id="toc_8">Perceptron Learning Algorithm</h3>

<ul>
<li>For t = 0, 1, ... 这里 t 是轮数，因为会迭代很多次</li>
<li>找到 w~t~ 的一个分类错误的点(x~n(t)~, y~n(t)~), 即 sign(w~t~<sup>T<sup>x~n(t)~)</sup></sup> 不等于 y~n(t)~</li>
<li>试着去改正这个错误 w~t+1~ &lt;- w~t~ + y~n(t)~x~n(t)~ until no more mistakes</li>
<li>返回最后得到的 w 为 g, 这个 w 称为 w~pla~</li>
</ul>

<h3 id="toc_9">Cyclic PLA</h3>

<ul>
<li>For t = 0,1,...</li>
<li>find the next mistake of wt called (x~n(t)~, y~n(t)~), aka sign(w~t~<sup>T<sup>x~n(t)~)</sup></sup> 不等于 y~n(t)~</li>
<li>correct the mistake by w~t+1~ &lt;- w~t~ + y~n(t)~x~n(t)~</li>
<li>until a full cycle of not encountering mistakes</li>
<li>可以采用标准的遍历，或者也可以是预先计算好的随机顺序</li>
</ul>

<h3 id="toc_10">Linear Separability 线性可分</h3>

<ul>
<li>if PLA halts, (necessary condition) D allows some w(一条用来区分的线) to make no mistake</li>
<li>有一条线可以区分数据，即有解，有解的时候 PLA 算法才会停</li>
</ul>

<h3 id="toc_11">PLA Fact: W~t~ Gets More Aligned with W~f~</h3>

<ul>
<li>线性可分，则存在一条完美的直线 W~f~(即目标函数) 使得 y~n~ = sign(W~f~<sup>T^</sup> x~n~)</li>
<li>也就是 y~n~ 的符号，与 W~f~<sup>T^</sup> 和 x~n~ 的乘积(也就是 x~n~ 到直线 W~f~ 的距离)的符号，一定是相同的</li>
<li><img src="./_resources/mlf3.jpg" alt="mlf3"/></li>
<li>W~t~ 为当前次迭代的直线，找出一个错误的点，然后做更新</li>
<li>通过不等式可以得到，下一次迭代得到的直线，会更加接近于完美的直线 W~f~ ，因为乘积越来越大了(但是乘积还需要考虑向量的长度，这里说的是角度，下面就是说长度)</li>
</ul>

<h3 id="toc_12">PLA Fact: W~t~ Does Not Grow Too</h3>

<ul>
<li>W~t~ changed only when mistake</li>
<li>也就是只有在 sign(W~t~<sup>T^</sup> x~n(t)~) 不等于 y~n(t)~ 也就是 y~n(t)~w~t<sup>T<sup>x~n(t)~</sup></sup> &lt;= 0</li>
<li><img src="./_resources/mlf4.jpg" alt="mlf4"/></li>
<li>平方之后来看长度的公式，蓝色部分通过上面的推导可知是小于等于零的</li>
<li>y~n~ 是正负 1，所以下一次迭代的向量的长度的增长是有限的，最多增长 x~n~<sup>2^</sup> 那么多(也就是长度最大的向量)</li>
<li>然后推导出来 w~t~ 确实是越来越靠近 w~f~ 的</li>
</ul>

<h3 id="toc_13">一个习题</h3>

<ul>
<li><img src="./_resources/mlf5.jpg" alt="mlf5"/></li>
<li>具体怎么推导的呢，研究了半个多小时终于弄清楚了，如下</li>
<li>W~f~ 是理论上完美的那条线，w~t~ 是第 t 次迭代得到的那条线，而因为这两条线最好结果就是完全平行，所以有

<ul>
<li>(W~f~<sup>T^</sup> / || W~f~ ||) * (w~t~ / || w~t~ ||) 的最大值为 1 (<code>eq1</code>)</li>
</ul></li>
<li>由前面 PPT 得到的两个公式：

<ul>
<li>W~f~<sup>T<sup>w~t+1~</sup></sup> &gt;= W~f~<sup>T<sup>w~t~</sup></sup> + min~n~y~n~W~f~<sup>T<sup>x~n~</sup></sup> (<code>eq2</code>)</li>
<li>w~t+1~<sup>2^</sup> &lt;= w~t~<sup>2^</sup> + max(n)x~n~<sup>2^</sup> (<code>eq3</code>)</li>
</ul></li>
<li>因为是迭代 T 次，把 <code>eq2</code> 和 <code>eq3</code> 代入到 <code>eq1</code> 中

<ul>
<li>W~f~<sup>T<sup>w~t~</sup></sup> / || w~f~ || 这部分就是条件里的 p，因为迭代 T 次，所以分子变成 T·p</li>
<li>分子是 || w~t~ ||，根据 <code>eq3</code> 可知迭代 T 次后为 √(T·R<sup>2<sup>)</sup></sup></li>
</ul></li>
<li>又因为 <code>eq1</code> 的最大值为1，可以求出 T 的范围，得到答案</li>
</ul>

<h3 id="toc_14">More about PLA</h3>

<ul>
<li>Guarantee: as long as <strong>linear separable</strong> and <strong>correct by mistake</strong>

<ul>
<li>inner product of w~f and w~t grows fast; length of w~t grows slowly</li>
<li>PLA &#39;lines&#39; are more and more align with W~f~ -&gt; halts</li>
</ul></li>
<li>Pros

<ul>
<li>Simple to implement, fast, works in any dimensin d</li>
</ul></li>
<li>Cons

<ul>
<li><strong>&#39;Assumes&#39; linear separable D</strong> to halt(property unknown in advance)</li>
<li>Not fully sure <strong>how long halting takes</strong>(p depends on W~f~) -though practically fast</li>
</ul></li>
<li>What if D not linear separable?</li>
</ul>

<h3 id="toc_15">Learning with <strong>Noisy Data</strong></h3>

<ul>
<li><img src="./_resources/mlf6.jpg" alt="mlf6"/></li>
<li>Line with Noise Tolerance

<ul>
<li><img src="./_resources/mlf7.jpg" alt="mlf7"/></li>
<li>在看到的数据中，找犯错误最少的一条(但是这是一个很难的问题)</li>
</ul></li>
</ul>

<h3 id="toc_16">Pocket Algorithm</h3>

<ul>
<li>modify PLA algorithm (black lines) by <strong>keeping best weights in pocket</strong></li>
<li><img src="./_resources/mlf8.jpg" alt="mlf8"/></li>
<li>例题时间</li>
<li><img src="./_resources/mlf9.jpg" alt="mlf9"/></li>
</ul>

<h2 id="toc_17">Lecture 3: Types of Learning</h2>

<h3 id="toc_18">Different Output Space</h3>

<ul>
<li>二元分类与多元分类</li>
<li>例子：Patient Recovery Prediction Problem

<ul>
<li>binary classification: patient features -&gt; sick or not</li>
<li>multiclass classification: patient features -&gt; which type of cancer</li>
<li>regression(回归分析)

<ul>
<li>patient features -&gt; how many days before recovery</li>
<li>compnay data -&gt; stock price</li>
<li>climate data -&gt; temperature</li>
</ul></li>
</ul></li>
<li>统计上有很多工具也可以放到机器学习里来用</li>
<li>Structured Learning

<ul>
<li>Sequence Tagging Problem 词性标注</li>
<li>protein data -&gt; protein folding</li>
<li>speech data -&gt; speech parse tree</li>
</ul></li>
</ul>

<h3 id="toc_19">Different Label</h3>

<ul>
<li>监督式学习

<ul>
<li><img src="./_resources/mlf10.jpg" alt="mlf10"/></li>
</ul></li>
<li>非监督式学习

<ul>
<li><img src="./_resources/mlf11.jpg" alt="mlf11"/></li>
</ul></li>
<li>其他一些非监督式学习

<ul>
<li><img src="./_resources/mlf12.jpg" alt="mlf12"/></li>
<li>diverse, with possibly very different performance goals</li>
</ul></li>
<li>半监督式学习

<ul>
<li>只提供有限信息，只标记一部分，蓝色的是没有标记的，其他颜色是标记出来的</li>
<li><img src="./_resources/mlf13.jpg" alt="mlf13"/></li>
<li>leverage unlabeled data to avoid &#39;expensive&#39; labeling</li>
</ul></li>
</ul>

<h3 id="toc_20">Different Protocol</h3>

<ul>
<li>Reinforcement Learning

<ul>
<li>惩罚错误判断，鼓励正确判断</li>
<li>learn with <strong>partial/implicit information</strong>(often sequentially)</li>
</ul></li>
<li>Batch Learning 填鸭式教育

<ul>
<li><img src="./_resources/mlf14.jpg" alt="mlf14"/></li>
<li>batch learning: <strong>a very common protocol</strong></li>
</ul></li>
<li>Online 老师教书

<ul>
<li>hypothesis &#39;improves&#39; through receiving data instances sequentially</li>
<li>PLA can be easily adapted ton online protocol</li>
<li>reinforcement learning is often done online</li>
</ul></li>
<li>Active Learning

<ul>
<li><img src="./_resources/mlf15.jpg" alt="mlf15"/></li>
</ul></li>
</ul>

<h3 id="toc_21">Different Input Space</h3>

<ul>
<li>Concrete features: the &#39;easy&#39; ones for ML</li>
<li>Raw features -&gt; meaning of digit(比方说笔迹识别，把图像转换成数字化的信息，可以是对称性或者密度，或者直接转化成二维数组，越抽象，对于机器来说就越困难)

<ul>
<li>often need human or machines to <strong>convert to concrete ones</strong></li>
<li>要么是人工来做，要么就是 deep learning 自动来做</li>
</ul></li>
<li>Abstract features: <strong>no</strong> physical meaning, even harder for ML

<ul>
<li>比方说评分预测问题(KDDCup 2011)</li>
<li>need <strong>feature conversion</strong>/extraction/construction</li>
</ul></li>
</ul>

<h2 id="toc_22">Lecture 4: Feasibility of Learning</h2>

<ul>
<li>Inferring Something Unknown

<ul>
<li>diificult to infer <strong>unknown target f outside D</strong> in learning</li>
<li>抽样调查</li>
</ul></li>
<li><strong>Hoeffding&#39;s Inequality</strong>

<ul>
<li>只是给出一个比较高的上限</li>
<li>probably approximately correct(PAC)</li>
</ul></li>
</ul>

<h3 id="toc_23">Hoeffding&#39;s Inequality</h3>

<p>用一个从罐子里取玻璃球作为例子，有两种玻璃球：橙色和绿色。假设：</p>

<pre><code>橙色的概率为 u
则绿色的概率为 1-u
但 u 具体是多少我们不知道
</code></pre>

<p>然后我们从中取出 <code>N</code> 个样本：</p>

<pre><code>橙色的比例为 v
则绿色的比例为 1-v
这时我们是知道 v 具体是多少的
</code></pre>

<blockquote>
<p>Does <strong>in-sample v</strong> say anything about out-of-sample u?</p>
</blockquote>

<ul>
<li>Possibly not: sample can be mostly green while bin is mostly orange</li>
<li>Probably yes: in-sample v likely <strong>close to</strong> unknown u</li>
</ul>

<blockquote>
<p>Formally, what does v say about u?</p>
</blockquote>

<pre><code>u = orange probability in bin
v = orange fraction in sample
</code></pre>

<p><img src="./_resources/mlf16.jpg" alt="mlf16"/></p>

<p>抽样数量足够大的时候，抽样得到的概率 v 和实际概率 u 相差的概率会很小(Heoffding&#39;s Inequality)</p>

<p>The statement <code>v = u</code> is <strong>probably approximately correct</strong>(PAC)</p>

<p>根据上面的公式我们知道，其实要知道抽样得到的概率 v 和实际概率 u 相差多少，只跟误差和抽样的数量有关。</p>

<p>If <strong>large N</strong>, can <strong>probably</strong> infer unknown u by known v</p>

<h3 id="toc_24">Connect to Learning</h3>

<table>
<thead>
<tr>
<th>瓶中的情况</th>
<th>对应到 Learning</th>
</tr>
</thead>

<tbody>
<tr>
<td>unknown orange prob. u</td>
<td>fixed hypothesis h(x) ? target f(x)</td>
</tr>
<tr>
<td>marble in bin</td>
<td>x 在 X 中</td>
</tr>
<tr>
<td>orange</td>
<td>h is wrong -&gt; h(x) 不等于 f(x) aka orange</td>
</tr>
<tr>
<td>green</td>
<td>h is right -&gt; h(x) 等于 f(x) aka green</td>
</tr>
<tr>
<td>size-N sample from bin</td>
<td>check h on D = {(x~n~, y~n~)} 这里 y~n~ 就是 f(x~n~)</td>
</tr>
</tbody>
</table>

<p><img src="./_resources/mlf17.jpg" alt="mlf17"/></p>

<p><img src="./_resources/mlf18.jpg" alt="mlf18"/></p>

<p>E~out~(h) 对应于 总体概率 u，E~in~(h) 对应于抽样概率 v</p>

<p><img src="./_resources/mlf19.jpg" alt="mlf19"/></p>

<p>Does not depend on E~out~(h),<strong>no need to know E~out~(h)</strong></p>

<p>E~in~(h) = E~out~(h) is <strong>probably approximately correct</strong>(PAC)</p>

<p><img src="./_resources/mlf20.jpg" alt="mlf20"/></p>

<p><strong>BAD</strong> sample: <strong>E~in~ and E~out~ far away</strong></p>

<p>can get <strong>worse</strong> when involving &#39;choice&#39;</p>

<p>Hoeffding 保证的是出现 Bad Sample 的机会不会很大</p>

<p><img src="./_resources/mlf21.jpg" alt="mlf21"/></p>

<p>什么意思呢？如果hypothesis set是有有限种选择，训练样本够多，那么不管学习算法A怎么选择，样本的判别结果都会与总体的一致。那么，如果学习算法设计为寻找样本中错误率最小的，那么刚刚的推论PAC就能保证选出来的g与f是约等于的。</p>

<p>也就是说，当有 M 个 hypothesis 的时候，对应的误差也会变大，但是依然可以找到一个情况，此时</p>

<p>E~in~(g) = E~out~(g) is <strong>PAC, regardless of A</strong></p>

<p>Most reasonable A(like PLA/pocket): pick the h~m with **lowest E~in~(h~m~) as g</p>

<p><img src="./_resources/mlf22.jpg" alt="mlf22"/></p>

<p>不过仍然有一个遗留问题，刚刚的推论是在hypothesis set有限的前提下，那类似于PLA的hypothesis set是无穷的又如何呢？不用紧张，以后会证明这个问题。现在至少在有限的情形下证明了，这是一个很好的出发点。</p>

<h2 id="toc_25">Lecture 5: Training versus Testing</h2>

<p><img src="./_resources/mlf23.jpg" alt="mlf23"/></p>

<h3 id="toc_26">Two Central Questions</h3>

<p><img src="./_resources/mlf24.jpg" alt="mlf24"/></p>

<ul>
<li>Can we make sure that E~out~(g) is close enough to E~in~(g)</li>
<li>Can we make E~in~(g) small enough?</li>
</ul>

<h3 id="toc_27">Trade-off on M</h3>

<p>M 也就是 hypothesis 的集合，对于不同的值，对于上面两个问题有两个不同的解答</p>

<table>
<thead>
<tr>
<th>Small M</th>
<th>Large M</th>
</tr>
</thead>

<tbody>
<tr>
<td>Yes! P[BAD] &lt;= 2·M·exp(...)</td>
<td>No! P[BAD] &lt;= 2·M·exp(...)</td>
</tr>
<tr>
<td>No! too few choices</td>
<td>Yes!, many choices</td>
</tr>
</tbody>
</table>

<p>这样就两难了，M 小的时候，可以保证 E~out~(g) 和 E~in~(g) 足够接近，但是不能保证 E~in~(g) 足够小；M 大的时候则是相反的情况。如何选择正确的 M 呢？尤其是 M 可能是无限多的情况怎么办呢？</p>

<p>现在的情况就是这个公式和 M 有关</p>

<p><img src="./_resources/mlf25.jpg" alt="mlf25"/></p>

<p>所以想办法能不能把可能无限大的 M，弄成有限的数量 m~H</p>

<p><img src="./_resources/mlf26.jpg" alt="mlf26"/></p>

<h3 id="toc_28">Where Did M Come From</h3>

<p><img src="./_resources/mlf27.jpg" alt="mlf27"/></p>

<p>之前的讨论中，我们直接把概率的 or 转化为概率的相加，因为我们假设这些 BAD case 不大可能会重叠，但是当 M 很大的时候，这种做法(Uniform Bound)就不行了。为什么呢？</p>

<p>因为假如 h~1 很接近于 h~2~,则 E~out~(h~1~) 会很接近 E~out~(h~2~)，并且很有可能 E~in~(h~1~) = E~in~(h~2~)</p>

<p>Union bound <strong>over-estimating</strong> 很多重复的也被计算进去了。那么对于这种情况，如果我们能 group similar hypothesis by <strong>kind</strong>，就可以减少误差。</p>

<h3 id="toc_29">How Many Lines Are There?</h3>

<p>考虑平面上所有的线 H = {all lines in R<sup>2<sup>}</sup></sup></p>

<ul>
<li>How many lines? 无限多条</li>
<li>How many <strong>kinds of</strong> lines if viewd from one input vector x~1?

<ul>
<li>两种，一种划分 x~1 是圈，另一种划分 x~1 是叉</li>
<li>2 kinds: h~1~-like(x~1~) = o or h~2~-like(x~1~) = x</li>
</ul></li>
</ul>

<p>如果从两个点的角度来看呢？有 4 种线，x~1 和 x~2 的组合可能是：oo, xx, xo, ox</p>

<p>三个点的情况下呢？通常情况下有 8 种线，x~1~, x~2~, x~3~ 的组合可能是：ooo, xxx, oox, xxo, oxo, xox, oxx, xoo</p>

<p>但是如果三点共线的话，就只有 6 种线了。</p>

<p>四个点的情况下呢？至多只有 14 种线了。(指的是线性可分的线的种类的数量)</p>

<h3 id="toc_30">Effective Number of Lines</h3>

<p>maximum kinds of lines with respect to N inputs x~1~, x~2~, ..., x~N~ -&gt; <strong>effective number of lines</strong> 可能的有效划分的线种类数量</p>

<p><img src="./_resources/mlf28.jpg" alt="mlf28"/></p>

<p>这里用 <code>effective(N)</code> 代替了原来的 <code>M</code>，如果 <code>effective(N)</code> 远小于 2<sup>N</sup> 的话，那么就可能解决无穷条线的问题了</p>

<h3 id="toc_31">Dichotomies: Mini-hypothesis</h3>

<p><img src="./_resources/mlf29.jpg" alt="mlf29"/></p>

<p>用 Dichotomies Set 的大小来代替 M，但是现在会依赖于不同点的选取，需要做进一步的修改</p>

<h3 id="toc_32">Growth Function</h3>

<p><img src="./_resources/mlf30.jpg" alt="mlf30"/></p>

<p>注意这里这个 m~H~(N) 是重要的符号</p>

<h4 id="toc_33">Growth Function for Positive Rays</h4>

<p><img src="./_resources/mlf31.jpg" alt="mlf31"/></p>

<p>N+1</p>

<h4 id="toc_34">Growth Fucntion for Positive Intervals</h4>

<p><img src="./_resources/mlf32.jpg" alt="mlf32"/></p>

<p>0.5N<sup>2</sup> + 0.5N + 1</p>

<h4 id="toc_35">Growth Function for Convex Sets</h4>

<p><img src="./_resources/mlf33.jpg" alt="mlf33"/></p>

<p><img src="./_resources/mlf34.jpg" alt="mlf34"/></p>

<h3 id="toc_36">The Four Growth Functions</h3>

<p><img src="./_resources/mlf35.jpg" alt="mlf35"/></p>

<h4 id="toc_37">Break Point of H</h4>

<p>指的是增长函数中第一个有希望的点(也就是增长趋势放缓的点)，比方说之前三个点我们可以做出 8 种线，但是四个点的时候却不能做出 16 种线，所以 4 就是一个 break point。</p>

<p><img src="./_resources/mlf36.jpg" alt="mlf36"/></p>

<h2 id="toc_38">Lecture 6: Theory of Generalization</h2>

<p>E~out~ ≈ E~in~ possible if <strong>m~H~(N) breaks somewhere</strong> and <strong>N large enough</strong></p>

<p>growth function m~H~(N): max number of dichotomies</p>

<p><img src="./_resources/mlf37.jpg" alt="mlf37"/></p>

<h3 id="toc_39">Restriction of Break Point</h3>

<p>what &#39;must be true&#39; when <strong>minimum break point</strong> k = 2</p>

<ul>
<li>N = 1: every m~H~(N) = 2 by definition</li>
<li>N = 2: every m~H~(N) &lt; 4 by definition (so **maximum possible = 3)</li>
<li>N = 3: <strong>maximum possible = 4 远小于 2<sup>3^</sup></strong></li>
</ul>

<p>既然如此，换一个角度来考虑的话那么更General的情况是：如果现在已知minimum break point k = 2，在样本量N不同的情况下对应的Dichotomies大小又是如何的状况呢？k = 2这里的意义就是说任意的两个样本点都无法被shatter到（shatter到的意思：n个样本点的2<sup>n个情形都能出现，这里就是指2个样本点的4种情形都能出现）。</sup></p>

<p>break point k <strong>restricts maximum possible m~H~(N) a lot</strong> for N &gt; k</p>

<p>idea: m~H~(N) &lt;= <strong>maximum possible m~H~(N) given k</strong> &lt;= poly(N) N 的多项式时间</p>

<p>m~H~(N)跟我们实际上的 hypothesis set 有关，我们不如来算一下 m~H~(N)在有某一个break point的前提下，到底能产生多少种可能性。如果最多的可能性，也即 m~H~(N)的最大值也是一个多项式的话，那么就可以放心大胆的说 m~H~(N)也是多项式的。进而，如果能将这个多项式的 m~H~(N) 成功地放进我们原来的 Hoeffding 不等式的话，也许我们就可以说在PLA这样的无穷 hypothesis set 上的 Learning 是做得到的。</p>

<h3 id="toc_40">Bounding Function</h3>

<p><strong>bounding function B(N, k)</strong>: maximum possible m~H~(N) when break point = k</p>

<ul>
<li>combinatorial quantity: maximum number of length-N vectors with (o, x) while <strong>no shatter any length-k</strong> subvectors</li>
<li>irrelevant of the details of H.</li>
</ul>

<p>new goal: B(N, k) &lt;= poly(N)?</p>

<p>B(N, k) &lt;= B(N-1, k) + B(N-1, k-1)</p>

<p>now we have <strong>upper bound</strong> of bounding function</p>

<p><img src="./_resources/mlf38.jpg" alt="mlf38"/></p>

<ul>
<li>simple induction using <strong>boundary and inductive formula</strong></li>
<li>for fixed k, B(N, k) upper bounded by poly(N) -&gt; **m~H~(N) is poly(N) if break point exists</li>
<li><code>&lt;=</code> can be <code>=</code> actually</li>
</ul>

<h3 id="toc_41">BAD Bound for General H</h3>

<p><img src="./_resources/mlf39.jpg" alt="mlf39"/></p>

<p>具体的证明主要分以下几步</p>

<h4 id="toc_42">Step 1: Replace E~out~ by E~in~&#39;</h4>

<p><img src="./_resources/mlf40.jpg" alt="mlf40"/></p>

<p>第一步，想办法将式子中的 E~out~(h) 替换掉。hypothesis set只要有一个 h 发生坏事情，也就是 E~in~(h) 与 E~out~(h) 差别很大，我们就说这个训练数据 D 不是好的数据，我们希望坏数据 D 发生的概率不要太高。</p>

<ul>
<li>E~in~(h) finitely many, E~out~(h) infinitely many</li>
<li>How? sample <strong>verification set D&#39;</strong> of size N to calculate E~in~&#39;</li>
<li>BAD h of E~in~ - E~out~ 可以大概近似于 BAD h of E~in~ - E~in~&#39;</li>
</ul>

<p>这样一来 evil E~out~ removed by verification with <strong>ghost data</strong></p>

<h4 id="toc_43">Step 2: Decompose H by Kind</h4>

<p>想办法将 Hypothesis set 换成某一个 h。如下图所示，现在在乎的所有和 BAD 有关的只是 E~in~(h) 和 E~in~(h)&#39; 来决定了。也就是说，如果 h 在 D 与 D’ 上做出一样的 dichotomy 的话，那么 E~in~(h) 和 E~in~(h)&#39; 就会长一样。所以我只要把所有的 hypothesis set 分成 |H(x1, x2…, x’1, x’2…)| 这么多类就好，也就是在这 2N 个点上有多少种 Dichotomies 就好了。这样的话最多最多有 m~H~(2N) 种，把每一种抓一个代表出来我们就可以使用 union bound 了。</p>

<p><img src="./_resources/mlf41.jpg" alt="mlf41"/></p>

<p><img src="./_resources/mlf42.jpg" alt="mlf42"/></p>

<p>use m~H~(2N) to calculate BAD-overlap properly</p>

<h4 id="toc_44">Step 3: Use Hoeffding without Replacement</h4>

<p><img src="./_resources/mlf43.jpg" alt="mlf43"/></p>

<p><img src="./_resources/mlf44.jpg" alt="mlf44"/></p>

<p>use <strong>Hoeffding</strong> after zooming to fixed h</p>

<p>现在我们已经是固定的 h，想知道两次 sampling 的差别。就好像我们先有 2N 个样本的例子，我们抓 N 个出来然后比较剩下的 N 个；或者说我们抓 N 个出来，比较它跟所有 2N 个的平均是多少。如果想要 E~in~(h) 和 E~in~(h)&#39; 相差 alpha 的话，那么 E~in~(h) 与所有人的平均需要相差 alpha/2。那怎么知道 E~in~(h) 与所有 2N 的差别呢？没错，就是使用 Hoeffding 不等式来解决，只不错这次罐子变得更小，变得有限的 2N 个了。</p>

<h3 id="toc_45">Vapnik-Chervonenkis (VC) bound:</h3>

<p><img src="./_resources/mlf45.jpg" alt="mlf45"/></p>

<h2 id="toc_46">Lecture 7: The VC Dimension</h2>

<p>if <strong>finite d~vc~</strong>, <strong>large N</strong>, and <strong>low E~in~</strong></p>

<p>如果成长函数在 k 处有 break point，那么这个成长函数会被一个上限函数所限制，这个上限函数又会被某个多项式限制，这个多项式是 k-1 次方</p>

<p><img src="./_resources/mlf46.jpg" alt="mlf46"/></p>

<p><img src="./_resources/mlf47.jpg" alt="mlf47"/></p>

<h3 id="toc_47">More on Vapnik-Chervonenkis(VC) Bound</h3>

<p><img src="./_resources/mlf48.jpg" alt="mlf48"/></p>

<p><img src="./_resources/mlf49.jpg" alt="mlf49"/></p>

<h3 id="toc_48">VC Dimension</h3>

<p>the formal name of <strong>maximum non-</strong>break point</p>

<p><img src="./_resources/mlf50.jpg" alt="mlf50"/></p>

<ul>
<li>N &lt;= d~vc~ -&gt; H can shatter some N inputs</li>
<li>k &gt; d~vc~ -&gt; k is a break point for H</li>
</ul>

<p>if N &gt;= 2, d~vc~ &gt;= 2, m~H~(N) &lt;= N 的 d~vc~ 次方</p>

<p><img src="./_resources/mlf51.jpg" alt="mlf51"/></p>

<p>good: <strong>finite d~vc~</strong></p>

<h3 id="toc_49">VC Dimension and Learning</h3>

<p><strong>finite d~vc~ -&gt; g will generalize E~out~(g) ≈ E~in~(g)</strong></p>

<ul>
<li>regardless of learning algorithm A</li>
<li>regardless of input distribution P</li>
<li>regardless of target function f</li>
</ul>

<p><img src="./_resources/mlf52.jpg" alt="mlf52"/></p>

<h3 id="toc_50">2D PLA Revisited</h3>

<p>如果现在 2D 里面我们的数据是 <strong>linearly separable D</strong>，那么 <strong>PLA can converge</strong>，也就是说，当迭代次数 T 足够大的时候，我们可以找到一条线，这条线把所有 data 正确分类，也就是 <strong>E~in~(g)=0</strong>。</p>

<p>如果这些 data 是从某个分布中(具体是什么分布不重要)以及某个target function得来的，即 <strong>with x~n~ ~ P and y~n~ = f(x~n~)</strong>，我们有很大的机会说他们的 E~in~(g) 和 E~out~(g) 是很接近的，因为我们知道了 d~vc~ 是有限的。当 N 很大的时候，可以知道 <strong>E~out~(g) ≈ E~in~(g)</strong></p>

<p><img src="./_resources/mlf53.jpg" alt="mlf53"/></p>

<p>那么问题来了: general PLA for x with <strong>more than 2 features</strong> 怎么办呢</p>

<h3 id="toc_51">VC Dimension of Perceptrons</h3>

<ul>
<li>1D perceptro (pos/neg rays): d~vc~ = 2</li>
<li>2D perceptrons: d~vc~ = 3

<ul>
<li>如何证明的呢？</li>
<li>三个点的情况下，我们找到一种方式可以shatter，于是 d~vc~ &gt;= 3</li>
<li>四个点的情况下，我们发现所有方式都不可以shatter，于是 d~vc~ &lt;= 3</li>
<li>于是 d~vc~ = 3</li>
</ul></li>
<li>d-D perceptrons: d~vc~ ? d+1 如何证明呢</li>
</ul>

<h3 id="toc_52">证明 d~vc~ &gt;= d+1</h3>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf54.jpg" alt="mlf54"/></p>

<p>There are <strong>some d+1 inputs</strong> we can shatter</p>

<p><img src="./_resources/mlf55.jpg" alt="mlf55"/></p>

<p>注意：X <strong>invertible</strong></p>

<p>怎么样可以保证 shatter 呢，对于任何一组输入 y，存在这样的 w 保证 Xw 的符号等于 y</p>

<p><img src="./_resources/mlf56.jpg" alt="mlf56"/></p>

<p>&#39;special&#39; X can be shattered -&gt; d~vc~ &gt;= d+1</p>

<h3 id="toc_53">证明 d~vc~ &lt;= d+1</h3>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf57.jpg" alt="mlf57"/></p>

<p>要证明所有可能性都不行。</p>

<p>linear dependence <strong>restricts dichotomy</strong></p>

<p><img src="./_resources/mlf58.jpg" alt="mlf58"/></p>

<p>&#39;general&#39; X no-shatter -&gt; d~vc~ &lt;= d+1</p>

<h3 id="toc_54">Degrees of Freedom</h3>

<ul>
<li>hypothesis parameters w = (w~0~, w~1~,..., w~d~): creates degrees of freedom</li>
<li>hypothesis quantity M = |H|: &#39;analog&#39; degrees of freedom</li>
<li>hypothesis &#39;power&#39; d~vc~ = d+1: <strong>effective &#39;binary&#39; degrees of freedom</strong></li>
</ul>

<p>物理意义是 hypothesis set 在做二元分类的时候有多少自由度(就是有多少可控的参数)</p>

<p>我们发现，d+1 实际上就是perceptron 的维度，所以 VC dimension 就和 perceptron 的维度联系起来了。hypothesis set 是由 d+1 维的 w 来表示的，而这些 w 可以代表着 hypothesis 的自由度 degrees of freedom。所以 VC dimension 的物理意义就是 effective ‘binary’ degrees of freedom，hypothesis set 在作二元分类的状况下到底有多少的自由度。同时也就象征着 powerfulness of H，到底能够产生多少的dichotomies。</p>

<p>d~vc~(H): powerfullness of H</p>

<p><img src="./_resources/mlf59.jpg" alt="mlf59"/></p>

<p>practical rule of thumb: <strong>d~vc~ ≈ #free parameters(but not always)</strong></p>

<p><strong>using the right d~vc~ (or H) is important</strong></p>

<h3 id="toc_55">VC Bound Rephrase: Penalty for Model Complexity</h3>

<p>VC dimension的一种意义是表征着 model complexity。</p>

<p><img src="./_resources/mlf60.jpg" alt="mlf60"/></p>

<p>坏事情发生的机会很小，也就是好事情发生的机会很大</p>

<p><img src="./_resources/mlf61.jpg" alt="mlf61"/></p>

<p>信赖区间，一般比较在意右边的部分，考虑最坏情况。</p>

<p>根号里面的部分是 penalty for <strong>model complexity</strong> Ω(N, H, δ)</p>

<h3 id="toc_56">THE VC Message</h3>

<p><img src="./_resources/mlf62.jpg" alt="mlf62"/></p>

<p><strong>powerful H</strong> not always good</p>

<h3 id="toc_57">VC Bound Rephrase: Sample Complexity</h3>

<p>VC bound还有另外的一种含义：Sample Complexity样本复杂度。</p>

<p><img src="./_resources/mlf63.jpg" alt="mlf63"/></p>

<p>prictical rule of thumb: <strong>N ≈ 10d~vc~ often enough!</strong></p>

<h3 id="toc_58">Looseness of VC Bound</h3>

<p><img src="./_resources/mlf64.jpg" alt="mlf64"/></p>

<p><strong>philosophical message</strong> of VC bound important for improving ML</p>

<h2 id="toc_59">Lecture 8: Noise and Error</h2>

<p>learning can happen with <strong>target distribution P(y|x)</strong> and <strong>low E~in~ w.r.t. err</strong></p>

<p>噪声是容易出现的，人工标记错误；同一个数据不同人工标记不同；训练数据收集可能不精准等等原因。那么在有噪声的时候，我们之前推导的 VC bound 是否仍然能作用的很好？</p>

<p>回想一下，VC bound 的核心：我们不知道一个罐子里有多少橘色的弹珠，不过我们抓一把出来就可以估计橘色的弹珠有多少，这些橘色的弹珠就是我们犯错误的地方。噪声的影响就是特别的弹珠，弹珠的颜色不是固定的，譬如弹珠40%是橘色的，60%的时候是绿色的。那这时候我们如何知道罐子大致的橘色的比例是多少呢。</p>

<p><img src="./_resources/mlf65.jpg" alt="mlf65"/></p>

<h3 id="toc_60">Target Distribution P(y|x)</h3>

<p>也就是说，只要我们的每个训练数据 y 来自某一个 joint distribution P(y|x)，我们在训练的时候和测试的时候都符合 P(y|x)，那么这个 VC bound 的大架构还是有效的。P(y|x) 通常叫做 <strong>target distribution</strong>，对于每一个 x 可以做一个它最理想的预测 <strong>mini-target</strong> 是什么。它告诉我们最理想的预测 <strong>ideal mini-target</strong> 是什么，另外不理想的就是 noise 。例如 P(o|x) = 0.7, P(x|x) = 0.3，也就是说现在拿了一颗弹珠它是圈圈概率是0.7，请问你是要猜圈圈还是要猜叉叉。当然最好猜它是圈圈，那么错误率就是0.3。</p>

<p>那么之前固定的 target f 可以认为是目前 target distribution 的一种特例，这时候P(y|x) = 1 for y = f(x)也就是完全没有噪声。使用 target distribution 的时候和之前是用 target function 的时候基本上没有什么太大的不一样。</p>

<p>所以回头来看，我们 Learning 的目标分为两个部分了 predict <strong>ideal mini-target(w.r.t. P(y|x))</strong> on <strong>often-seen inputs(w.r.t. P(x))</strong>，一个是原先的 P(x)，它告诉我们哪些点是重要的常常会被抽样到也就是在 E~in~(h) 里经常出现；另外一个是 P(y|x)，它告诉我们最理想的 mini-target 是什么。在常见的点上的预测要做的表现好，这就是 machine learning 做的事情。</p>

<p><img src="./_resources/mlf66.jpg" alt="mlf66"/></p>

<p>新的流程，区别在于左上角不再是一个固定的 target function 而是一个 target distribution，要保证训练和测试的数据都是从同一个分布产生的。</p>

<p>VC still works.</p>

<h3 id="toc_61">Error Measure</h3>

<p>final hypothesis g ≈ f</p>

<p>如何衡量 g 跟 f 是长的很像的呢？之前使用的是 E~out~(g)，有三个特性：<strong>out of sample</strong> 衡量的是还没有看过或者是未来抽样出来的x，<strong>point-wise</strong> 可以在每一个x上个别衡量，最后做抽样的平均就可以了，<strong>classification</strong> 二元分类考虑的就是对或者不对。实际上有很多的错误衡量的方式，不过为了简单起见大部分的主要集中在 point-wise 的方式。</p>

<p><img src="./_resources/mlf67.jpg" alt="mlf67"/></p>

<p><img src="./_resources/mlf68.jpg" alt="mlf68"/></p>

<h3 id="toc_62">Two Important Pointwise Error Measures</h3>

<p><img src="./_resources/mlf69.jpg" alt="mlf69"/></p>

<p>那有哪些 Point-wise 的错误衡量方式呢？0/1 error 通常用在分类上，分对还是分错；平方的 error 通常用在回归分析，计算错误的距离。未来会讲更多不同错误衡量方式。不同的错误衡量方式，会影响到最理想的 mini-target，也就是最好的 f 会长什么样。</p>

<p>VC 理论对于很多不同的 hypothesis set 还有很多不同的错误衡量方式来说都会 work。也就是说，不管是 classification 还是 regression，不只是0/1的错误衡量，都能得到类似的 VC bound。详细的数学推导太过于繁复，大家没有必要都走过一遍。</p>

<p>0/1 找最大概率的那个；平方 找加权平均值</p>

<p>于是新的 Learning Flow 会加上 Error Message 的部分</p>

<p><img src="./_resources/mlf70.jpg" alt="mlf70"/></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf71.jpg" alt="mlf71"/></p>

<h3 id="toc_63">Choice of Error Measure</h3>

<p>这些错误的衡量到底哪里来的呢？想象一个指纹分类系统，分类器可能会犯两种错误：false accept，应该要说不可以用，但是分类器说可以用；false reject，明明应该可以用，但是分类器说不可以用。其实也就是我们在分类中常说的 false positive 和 false negative，只是台湾和大陆的叫法不同而已。对于这两种错误的类型，之前的 0/1 error penalizes both types equally。然而，在实际应用中，两种错误带来的影响可能很不一样。</p>

<p><img src="./_resources/mlf72.jpg" alt="mlf72"/></p>

<p>但是很多时候错误衡量的具体权重是不太能确定的，所以在设计算法的时候常常要采用替代的方式。一种替代方式是找一些有意义的错误衡量，例如之前 Pocket PLA 在进行 0/1 分类时如果分不对就认为是噪声，想办法让噪声最小也就是 0/1 error 最小(NP hard问题之前有提到)。以及以后会讲到的距离平方的方式，想办法高斯噪声最小；另外一种替代方式会更 friendly，例如很容易求出解，或者凸优化的目标函数等。</p>

<p><img src="./_resources/mlf73.jpg" alt="mlf73"/></p>

<h3 id="toc_64">Weighted Classification</h3>

<p>不同的错误有不同的惩罚</p>

<p><img src="./_resources/mlf74.jpg" alt="mlf74"/></p>

<p>weighted classification: <strong>different &#39;weight&#39; for different (x, y)</strong></p>

<h3 id="toc_65">Minimizing E~in~ for Weighted Classification</h3>

<p>目标还是让 E~in~<sup>w<sup>h</sup></sup> 越小越好</p>

<p><img src="./_resources/mlf75.jpg" alt="mlf75"/></p>

<p><img src="./_resources/mlf76.jpg" alt="mlf76"/></p>

<p>一种比较机械的方式就是，在训练开始前，我们将{(x,y) | y=-1} 的数据复制1000倍之后再开始学习，后面的步骤与传统的 pocket 方法一模一样。然而，从效率、计算资源的角度考虑，通常不会真的将 y=-1 的数据拷贝 1000 倍，实际中一般采用”virtual copying”。</p>

<p><img src="./_resources/mlf77.jpg" alt="mlf77"/></p>

<p>只要保证：randomly check -1 example mistakes with 1000 times more probability。也就是说，pocket 随机访问-1错误点的几率在概率上要比非权重PLA算法时访问-1错误点的几率高了1000倍。</p>

<p>systematic route(called &#39;reduction&#39;) can be applied to many other algorithm</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf78.jpg" alt="mlf78"/></p>

<p>总之，我们选择好适合特定应用的error measure: err，然后在训练时力求最小化err，即，我们要让最后的预测发生错误的可能性最小（错误测量值最小），这样的学习是有效的。</p>

<h2 id="toc_66">Lecture 9: Linear Regression</h2>

<p><img src="./_resources/mlf102.jpg" alt="mlf102"/></p>

<p>例如，信用卡额度预测问题：特征是用户的信息（年龄，性别，年薪，当前债务，…），我们要预测可以给该客户多大的信用额度。 这样的问题就是回归问题。目标值 y 是实数空间 R。线性回归的假设 hypothesis 是 h(x) = w<sup>T<sup>x</sup></sup></p>

<p>For x = (x~0~, x~1~, x~2~,..., x~d~) &#39;features of customer&#39;, approximate the <strong>desired credit limit</strong> with a <strong>weighted</strong> sum:</p>

<p><img src="./_resources/mlf79.jpg" alt="mlf79"/></p>

<p>怎么理解？向量 x 就代表客户的不同信息，然后通过这个 hypothesis，也就是不同的权重向量 w，相乘得到一个实数</p>

<p>h(x): like <strong>perceptron</strong>, but without the <strong>sign</strong></p>

<p><strong>linear regression</strong>: find lines/hyperplanes with small <strong>residuals</strong></p>

<h3 id="toc_67">The Error Measure</h3>

<p><img src="./_resources/mlf80.jpg" alt="mlf80"/></p>

<p>这里之所以可以直接用 w 代替 h，因为每个不同的 hypothesis 实际上就是对应不同的权重</p>

<p>所以现在的问题就是最小化 E~in~(w)</p>

<h3 id="toc_68">Matrix Form of E~in~(w)</h3>

<p><img src="./_resources/mlf81.jpg" alt="mlf81"/></p>

<p>然后就可以得到下面的式子：</p>

<p><img src="./_resources/mlf82.jpg" alt="mlf82"/></p>

<p>这是一个连续可微凸函数，要找到最低点，表示不管到哪个方向都没有办法更低，也就是对应点的梯度(在每个方向上做偏微分)为零</p>

<p><img src="./_resources/mlf83.jpg" alt="mlf83"/></p>

<p>找到一个 W~LIN~,在各个方向偏微分为零</p>

<h3 id="toc_69">The Gradient ▽E~in~(w)</h3>

<p><img src="./_resources/mlf84.jpg" alt="mlf84"/></p>

<p>假设我们的 w 是一维的，那么上面的式子就变成了一个一元二次方程，求微分就很简单，对 w 求导即可。如果 w 是一个向量，那么就可以按照如下的方式来进行对梯度的求解(其实和一维的情况很像)</p>

<p><img src="./_resources/mlf85.jpg" alt="mlf85"/></p>

<p>所以整个式子是这么写：</p>

<p>▽E~in~(w) = 2/N * (X<sup>T<sup>Xw</sup></sup> - X<sup>T<sup>y)</sup></sup></p>

<h3 id="toc_70">Optimal Linear Regression Weights</h3>

<p>task: find W~LIN~ such that ▽E~in~(w) = 2/N * (X<sup>T<sup>Xw</sup></sup> - X<sup>T<sup>y)</sup></sup> = 0</p>

<p><img src="./_resources/mlf86.jpg" alt="mlf86"/></p>

<p>如果 X<sup>T<sup>X</sup></sup> 可逆的话，那么问题很简单(有唯一解)，可以直接求出 W~LIN~，并且大部分情况可能是如此。如果不可逆的话，就有很多组解，但是依然可以找到 pseudo-inverse，因此找到 W~LIN~</p>

<p><img src="./_resources/mlf87.jpg" alt="mlf87"/></p>

<p>实际上，无论哪种情况，我们都可以很容易得到结果。因为许多现成的机器学习/数学库帮我们处理好了这个问题，只要我们直接调用相应的计算函数即可。有些库中把这种广义求逆矩阵运算成为 pseudo-inverse。</p>

<h3 id="toc_71">Linear Regression Algorithm</h3>

<p><img src="./_resources/mlf88.jpg" alt="mlf88"/></p>

<p>有比较好的 pseudo-inverse 的话，这个算法非常简单有效</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf89.jpg" alt="mlf89"/></p>

<h3 id="toc_72">Is Linear Regression a &#39;Learning Algorithm&#39;?</h3>

<p><img src="./_resources/mlf90.jpg" alt="mlf90"/></p>

<p>从某些角度来说，不算是，但是从某些角度来说，也是学习的算法</p>

<p><img src="./_resources/mlf91.jpg" alt="mlf91"/></p>

<p>if E~out~(W~LIN~) is good, learning &#39;happened&#39;!</p>

<h3 id="toc_73">Benefit of Analytic Solution: &#39;Simpler-than-VC&#39; Guarantee</h3>

<p><img src="./_resources/mlf92.jpg" alt="mlf92"/></p>

<p>接下来，我们试图求一下E~in~，E~out~ 的平均范围，会比求解VC bound更为简单。</p>

<h3 id="toc_74">Geometric View of <strong>Hat Matrix</strong></h3>

<p><img src="./_resources/mlf93.jpg" alt="mlf93"/></p>

<p>N 维的空间里，y 是在 N 维空间里的向量，那么我要做预测也就是y<sup>hat^</sup> = Xw~LIN~，w 做的事情就是把 X 的每一个 column 作线性组合，X 的每一个 column 也是一个N维的向量。也就是说，X 拿出每个 column 可以展开成在 N 维度里面一个小的空间，然后 y<sup>hat^</sup> 会在这个空间里面。Linear Regression 要做什么？希望y与y<sup>hat<sup>的差别越小越好，也就是</sup></sup> y – y<sup>hat^</sup> 垂直于这个小空间的时候。所以，H 这个矩阵的作用就是把任何一个向量 y 投影到 X 所展开的那个空间里；I-H 的作用就是求解任何一个向量 y 对于 X 所展开的空间的余数。</p>

<p>trace(I-H) 对角线上的值加起来是多少。trace(I – H)的物理意义：我们原来有一个n个自由度的向量，现在我们将其投影到d+1维的空间（因为X有d+1个向量展开），然后取余数，剩下的自由度最多就是N – (d + 1)。</p>

<p><img src="./_resources/mlf94.jpg" alt="mlf94"/></p>

<p>注意到 E~in~ 算的是y – y<sup>hat<sup>，即垂直于平面的距离。而另一个角度来说，y</sup></sup> 可以认为是真实的 f(X) + noise的向量，我们会发现将 noise 投影在平面上求解的垂直于平面的距离实际上也就是 y – y<sup>hat<sup>。也就是说，我们现在要求解的</sup></sup> E~in~ 其实就是把I – H 这个线性的变换用在 noise 上面。于是就可以得到E~in~的平均范围，E~out~ 平均范围的求解会相对复杂这里省略。</p>

<h3 id="toc_75">The Learning Curve</h3>

<p><img src="./_resources/mlf95.jpg" alt="mlf95"/></p>

<p>通过 E~in~ 和 E~out~ 的式子通常就，可以画出一个图通常叫做学习曲线。所以，所谓的 generalization error 也就是 E~in~ 与 E~out~ 的差距，平均来说就是 2(d+1)/N。如果还记得的话，在有 d+1 个自由度时，VC bound最坏情况下是 d+1。所以 Linear regression的 学习真的已经发生了。</p>

<p>linear regression (LinReg): learning &#39;happened&#39;!</p>

<p><strong>一个习题</strong></p>

<p>H: projection y to y<sup>hat^</sup></p>

<p><img src="./_resources/mlf96.jpg" alt="mlf96"/></p>

<h3 id="toc_76">Linear Classification vs. Linear Regression</h3>

<p><img src="./_resources/mlf97.jpg" alt="mlf97"/></p>

<p><img src="./_resources/mlf98.jpg" alt="mlf98"/></p>

<p>那能否直接用 Linear regression 来解分类问题就好？听起来有点道理。</p>

<p><img src="./_resources/mlf99.jpg" alt="mlf99"/></p>

<p>之所以能够通过线程回归的方法来进行二值分类，是由于回归的 squared error 是分类的 0/1 error 的上界(平方的错误一定比0/1的错误大)</p>

<p><img src="./_resources/mlf100.jpg" alt="mlf100"/></p>

<p>用一个宽松一点但是更好算的限制来简化。</p>

<p>我们通过优化 squared error，一定程度上也能得到不错的分类结果；或者，更好的选择是，将回归方法得到的 w 作为二值分类模型的初始 w 值。</p>

<p>W~LIN~: useful baseline classifier, or as initial PLA/pocket vector 用作一开始的 w~0~，就可以加速 PLA/pocket 的运算</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf101.jpg" alt="mlf101"/></p>

<h2 id="toc_77">Lecture 10: Logistic Regression</h2>

<p><strong>gradient descent</strong> on <strong>cross-entropy error</strong> to get good <strong>logistic hypothesis</strong></p>

<p>有一组病人的数据，我们需要预测他们在一段时间后患上心脏病的“可能性”，就是我们要考虑的问题。通过二值分类，我们仅仅能够预测病人是否会患上心脏病，不同于此的是，现在我们还关心患病的可能性，即 f(x) = P(+1|x)，取值范围是区间 [0,1]。</p>

<p>然而，我们能够获取的训练数据却与二值分类完全一样，x 是病人的基本属性，y 是 +1(患心脏病)或 -1（没有患心脏病）。输入数据并没有告诉我们有关“概率” 的信息。在二值分类中，我们通过 w*x 得到一个 ”score” 后，通过取符号运算 sign 来预测 y 是 +1 或 -1。而对于当前问题，我们如过能够将这个 score 映射到[0,1] 区间，问题似乎就迎刃而解了。</p>

<p>same data as hard binary classification, different <strong>target function</strong></p>

<p>我们手上的数据可以看成是我们想要资料的有噪声的版本，在噪声的基础上我们来找到最接近真实的情况</p>

<p><img src="./_resources/mlf103.jpg" alt="mlf103"/></p>

<p>同样是根据权重算出一个分数，但是会通过另一个函数θ 来把这个分数映射到0到1的区间</p>

<h3 id="toc_78">Logistic Function</h3>

<p><img src="./_resources/mlf104.jpg" alt="mlf104"/></p>

<p>平滑可微 S 形函数</p>

<p><img src="./_resources/mlf105.jpg" alt="mlf105"/></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf106.jpg" alt="mlf106"/></p>

<h3 id="toc_79">Three Linear Models</h3>

<p>linear scoring functions: s = w<sup>T<sup>x</sup></sup></p>

<p><img src="./_resources/mlf107.jpg" alt="mlf107"/></p>

<p>how to define <strong>E~in~(w) for logistic regression</strong>?</p>

<h3 id="toc_80">Likelihood</h3>

<p>在机器学习假设中，数据集 D 是由 f 产生的，我们可以按照这个思路，考虑 f 和假设 h 生成训练数据 D 的概率是多少？首先要产生 x~1~，概率是 P(x~1~)，然后产生 y~1~，概率是 P(y~1~ | x~1~)。</p>

<p><img src="./_resources/mlf108.jpg" alt="mlf108"/></p>

<p>这里可以对 P(o|x~1~) P(x|x~2~) ...进行代换，变成下面的形式</p>

<p><img src="./_resources/mlf109.jpg" alt="mlf109"/></p>

<p>如何想要 h 与 f 很接近的话，那么 h 产生数据 D 的可能性与 f 真正产生这些数据的可能性就会很接近，训练数据的客观存在的，显然越有可能生成该数据集的假设越好。也就是 h 产生数据 D 的可能性是最高的。</p>

<p><img src="./_resources/mlf110.jpg" alt="mlf110"/></p>

<p>logistic hypothesis有一个数学上的特性：1 - h(x) = h(-x)。所以 likelihood(h) 就可以化简为如下图所示，其中灰色的 P(x) 是一系列的常数。所以，likelihood(logistic h) 正比于如下的连乘。</p>

<p><img src="./_resources/mlf111.jpg" alt="mlf111"/></p>

<p>利用上面的特性替换之后：</p>

<p><img src="./_resources/mlf112.jpg" alt="mlf112"/></p>

<h3 id="toc_81">Cross-Entropy Error</h3>

<p>把上面的公式用 w 和 θ 代入之后，可以得到下面的公式</p>

<p><img src="./_resources/mlf113.jpg" alt="mlf113"/></p>

<p>前面有 h(x) = θ(w<sup>T<sup>x)</sup></sup></p>

<p>但是这里是连乘，不是特别好处理，我们这里取对数，就可以把连乘变成连加</p>

<p><img src="./_resources/mlf114.jpg" alt="mlf114"/></p>

<p>之前我们都做的是最小化，所以增加一个负号，变成最小化，然后在除以一个 N，做一个常数的 scaling</p>

<p><img src="./_resources/mlf115.jpg" alt="mlf115"/></p>

<p>把 θ 具体代入到上面的公式，就可以得到</p>

<p><img src="./_resources/mlf116.jpg" alt="mlf116"/></p>

<p>err(w, x, y) = ln(1 + exp(-ywx)) <strong>cross-entropy error</strong></p>

<p>是一个 point-wise 的 error function</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf117.jpg" alt="mlf117"/></p>

<h3 id="toc_82">Minimizing E~in~(w)</h3>

<p><img src="./_resources/mlf118.jpg" alt="mlf118"/></p>

<p>我们已经推导完了E~in~(w)，接下来的事情就是想办法找到 w 使得E~in~(w)是最小的。幸运的是，LR 的这个函数是 convex 的。求解最小值就是找到谷底梯度为0的地方。</p>

<p><img src="./_resources/mlf119.jpg" alt="mlf119"/></p>

<p>第一步就是求梯度 ▽E~in~(w)</p>

<p><img src="./_resources/mlf120.jpg" alt="mlf120"/></p>

<p>一步一步求解偏微分，微积分连锁率。这个是其中一个 component 的推导，然后对于整体来说，可以写成如下形式：用 x~n~ 代替 x~n,i~</p>

<p><img src="./_resources/mlf121.jpg" alt="mlf121"/></p>

<p>到这一步我们想要的就是让这个梯度为零</p>

<p><img src="./_resources/mlf122.jpg" alt="mlf122"/></p>

<p>可以把梯度看成是一个以 θ 为权重的 y~n~x~n~ 的加权平均</p>

<p><img src="./_resources/mlf123.jpg" alt="mlf123"/></p>

<p>梯度什么时候是 0？第一个可能是所有的 θ 都是零，也就是说 y~n~w<sup>T<sup>x~n~</sup></sup> 要接近正无限大；但是正常来说更多的是 weighted sum = 0，non-linear equation of w</p>

<p>这是一个困难的问题</p>

<p>想要上式等于零，一种情况是sigmoid 项恒为0，也就是所有的 ywx &gt;&gt; 0，这时要求数据时线性可分的（不能有噪音）。否则，需要迭代优化。回忆一下之前revised PLA求解超平面直观的优化方法：</p>

<p><img src="./_resources/mlf124.jpg" alt="mlf124"/></p>

<p><img src="./_resources/mlf125.jpg" alt="mlf125"/></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf126.jpg" alt="mlf126"/></p>

<p>最小，代表 w 在 当前的 xy 上是错的，犯错的得到的权重特别大，梯度某种角度也代表了犯错在哪里。</p>

<h3 id="toc_83">Iterative Optimization</h3>

<p><img src="./_resources/mlf127.jpg" alt="mlf127"/></p>

<p>梯度下降法是最经典、最常见的优化方法之一。要寻找目标函数曲线的波谷，采用贪心法：想象一个小人站在半山腰，他朝哪个方向跨一步，可以使他距离谷底更近（位置更低），就朝这个方向前进。这个方向可以通过微分得到。选择足够小的一段曲线，可以将这段看做直线段，那么有</p>

<p><img src="./_resources/mlf128.jpg" alt="mlf128"/></p>

<p>这样就把一个非线性的优化问题利用泰勒展开，变成了一个线性的问题，在η够小的时候。</p>

<p><img src="./_resources/mlf129.jpg" alt="mlf129"/></p>

<p>所以，我们真正要要求解的是 v 乘上梯度如何才能越小越好。也就是 v 与梯度是完全的相反方向。想象一下：如果一条直线的斜率 k&gt;0，说明向右是上升的方向，应该向左走；反之，斜率 k&lt;0，向右走。</p>

<p>gradient descent: a simple &amp; popular optimization tool</p>

<h3 id="toc_84">Choice of η</h3>

<p><img src="./_resources/mlf130.jpg" alt="mlf130"/></p>

<p>η better be <strong>monotonic of</strong> || ▽E~in~(w~t~) ||</p>

<p>解决的方向问题，步幅η也很重要。步子太小的话，速度太慢；过大的话，容易发生抖动，可能到不了谷底。显然，距离谷底较远（位置较高）时，步幅大些比较好；接近谷底时，步幅小些比较好（以免跨过界）。距离谷底的远近可以通过梯度（斜率）的数值大小间接反映，接近谷底时，坡度会减小。因此，我们希望步幅与梯度数值大小正相关。原式子可以改写为：</p>

<p><img src="./_resources/mlf131.jpg" alt="mlf131"/></p>

<h3 id="toc_85">Putting Everything Together</h3>

<p><img src="./_resources/mlf132.jpg" alt="mlf132"/></p>

<p>similar time complexity to <strong>pocket</strong> per iteration</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf133.jpg" alt="mlf133"/></p>

<p>看前面的公式一个一个代入，最后后面是一样的，系数是 0.1 * θ(0) = 0.1 * 0.5 = 0.05，所以选第三个答案</p>

<h2 id="toc_86">Lecture 11: Linear Models for Classification</h2>

<h3 id="toc_87">Linear Models Revisited</h3>

<p>linear scoring functions: s = w<sup>T<sup>x</sup></sup></p>

<p><img src="./_resources/mlf134.jpg" alt="mlf134"/></p>

<p>can linear regression or logistic regression <strong>help linear classification</strong>?</p>

<h3 id="toc_88">Error-Functions Revisited</h3>

<p><img src="./_resources/mlf135.jpg" alt="mlf135"/></p>

<p>为了更方便地比较三个 model，对其 error function 做一定处理。接下来我们要做的事情就是看看这些 Error Function 跟 ys 的关系，在此之前我们先看看ys 的物理意义：y 代表正确与否 correctness，s 代表正确或错误的程度 score。</p>

<p><img src="./_resources/mlf136.jpg" alt="mlf136"/></p>

<p><strong>Visulaizing Error Functions</strong></p>

<p>通过曲线来比较三个error function （注意：为了让Logistic Error Function 完全压在 0/1 的 Error Function 上，一般 cross-entropy 变为以2为底的 scaled cross-entropy），这样很容易通过比较三个 error function 来得到分类的 0/1 error 的上界。</p>

<p><img src="./_resources/mlf137.jpg" alt="mlf137"/></p>

<h3 id="toc_89">Theoretical Implication of Upper Bound</h3>

<p><img src="./_resources/mlf138.jpg" alt="mlf138"/></p>

<p><strong>Regression for Classification</strong></p>

<p><img src="./_resources/mlf139.jpg" alt="mlf139"/></p>

<p>线性分类(PLA)、线性回归、逻辑回归的优缺点比较：</p>

<ul>
<li>PLA

<ul>
<li>优点：在数据线性可分时高效且准确。</li>
<li>缺点：只有在数据线性可分时才可行，否则需要借助POCKET 算法（没有理论保证）。</li>
</ul></li>
<li>线性回归

<ul>
<li>优点：最简单的优化（直接利用矩阵运算工具）</li>
<li>缺点：y*s 的值较大时，与0/1 error 相差较大(loose bound)。</li>
</ul></li>
<li>逻辑回归

<ul>
<li>优点：比较容易优化（梯度下降）</li>
<li>缺点：y*s 是非常小的负数时，与0/1 error 相差较大。</li>
</ul></li>
</ul>

<p>实际中，逻辑回归用于分类的效果优于线性回归的方法和 POCKET 算法。线性回归得到的结果w 有时作为其他几种算法的初值。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf140.jpg" alt="mlf140"/></p>

<p>不 scale 之前有一部分是在 err 1/0 曲线之下的</p>

<h3 id="toc_90">Two Iterative Optimization Schemes</h3>

<p><img src="./_resources/mlf141.jpg" alt="mlf141"/></p>

<p>每一轮迭代，logistic regression 的复杂度比 PLA 大很多(因为每次都要过一遍所有的点)，所以有没有一个办法，能降低复杂度呢？</p>

<h3 id="toc_91">Stochastic Gradient Descent (SGD)</h3>

<p>传统的随机梯度下降更新方法如下。每次更新都需要遍历所有data，当数据量太大或者一次无法获取全部数据时，这种方法并不可行。</p>

<p><img src="./_resources/mlf142.jpg" alt="mlf142"/></p>

<p>我们希望用更高效的方法解决这个问题，基本思路是：只通过一个随机选取的数据(xn,yn) 来获取“梯度”，以此对 w 进行更新。这种优化方法叫做随机梯度下降。</p>

<p><img src="./_resources/mlf143.jpg" alt="mlf143"/></p>

<p>利用期望值的性质，在减少计算量的同时，保持比较高的正确率</p>

<p>stochastic gradient = true gradient + zero-mean &#39;noise&#39; directions</p>

<p><img src="./_resources/mlf144.jpg" alt="mlf144"/></p>

<p>这种方法在统计上的意义是：进行足够多的更新后，平均的随机梯度与平均的真实梯度近似相等。</p>

<p><img src="./_resources/mlf145.jpg" alt="mlf145"/></p>

<p>注意：在这种优化方法中，一般设定一个足够大的迭代次数，算法执行这么多的次数时我们就认为已经收敛（防止不收敛的情况），η经验上的取值在0.1附近会比较合适。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf146.jpg" alt="mlf146"/></p>

<h3 id="toc_92">Multiclass Classification</h3>

<p>One Class at a Time</p>

<p><img src="./_resources/mlf148.jpg" alt="mlf148"/></p>

<p>这方法有一个问题，就是用简单的二值分类，在交叉和没有覆盖到的区域，会有冲突，所以最要用 Soft 的方式，也就是用概率来表示。</p>

<p><img src="./_resources/mlf147.jpg" alt="mlf147"/></p>

<p>与二值分类不同的是，我们如何将这些Model延伸来做多类别的分类。一种直观的解决方法是将其转化为多轮的二值分类问题：任意选择一个类作为+1，其他类都看做-1，在此条件下对原数据进行训练，得到w；经过多轮训练之后，得到多个 w，如下图得到四个分类器，每个都是一个概率的分类器。</p>

<p>可以看到下面的是一个概率，w~[k]~<sup>T^</sup> 表示第 k 个分类器，其实连 θ 都不用考虑(因为是单调的)，直接比较大小即可</p>

<h3 id="toc_93">One-Versus-All (OVA) Decomposition</h3>

<p><img src="./_resources/mlf149.jpg" alt="mlf149"/></p>

<p>对于某个x，在有些时候4个分类器中只会有1个分类器说x就是它的类别；不过对于中间区域的点，4个分类器似乎都会说不是它们的类别，那该如何分类呢？这个时候，就将其分到可能性最大的那个类（例如逻辑回归对于x 属于某个类会有一个概率估计）。如果目标类别是k 个类标签，我们需要k 轮训练，得到k 个w。这种方法叫做One-Versus-All (OVA)。</p>

<p>它的最大缺点是，目标类很多时，每轮训练面对的数据往往非常不平衡(unbalanced)，因为每次训练都是当前类别的概率与其他K-1个类别的概率比较，会严重影响训练准确性。multinomial (‘coupled’) logistic regression 考虑了这个问题，感兴趣的话自学下吧。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf150.jpg" alt="mlf150"/></p>

<p>注意这个过程可以很容易并行</p>

<h3 id="toc_94">One-versus-one(OVO) Decomposition</h3>

<p>既然这样，One-Versus-All 会出现 Unbalanced 的情况，那么有一种方法叫做 One-Versus-One(OVO)尝试解决这个问题。</p>

<p>基本方法：每轮训练时，任取两个类别，一个作为+1，另一个作为-1，其他类别的数据不考虑，这样，同样用二值分类的方法进行训练；目标类有k个时，需要 <code>k*(k-1)/2</code> 轮训练，得到 <code>k*(k-1)/2</code> 个分类器。</p>

<p><strong>Multiclass Prediction: Combine Pairwise Classifiers</strong></p>

<p><img src="./_resources/mlf151.jpg" alt="mlf151"/></p>

<p>预测：对于某个x，用训练得到的 <code>k*(k-1)/2</code> 个分类器分别对其进行预测，哪个类别被预测的次数最多，就把它作为最终结果。即通过“循环赛”的方式来决定哪个“类”是冠军。</p>

<p><img src="./_resources/mlf152.jpg" alt="mlf152"/></p>

<p>显然，这种方法的优点是每轮训练面对更少、更平衡的数据，而且可以用任意二值分类方法进行训练；缺点是需要的轮数太多(k*(k-1)/2)，占用更多的存储空间，而且预测也更慢。</p>

<p>OVA 和 OVO 方法的思想都很简单，可以作为以后面对多值分类问题时的备选方案，并且可以为我们提供解决问题的思路。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf153.jpg" alt="mlf153"/></p>

<p>10 个类别，需要 <code>10*(10-1)/2 = 45</code> 个分类器，然后因为每个分类器只需要 2N/10 份的资料，所以一次计算的消耗是 N/5 的三次方，相乘之后就是第二个答案</p>

<h2 id="toc_95">Lecture 12: Nonlinear Transformation</h2>

<p><img src="./_resources/mlf154.jpg" alt="mlf154"/></p>

<p>二元分类视觉上像切一条线，数学上来说就是用输入 x 乘上某个向量 w 然后得到一个分数 s，这种模型很有好处，复杂度可控(d~vc~限制)，但是有限制，可能有些数据，没办法用线来切开。</p>

<p>how to <strong>break the limit</strong> of linear hypothesis?</p>

<h3 id="toc_96">Circular Separable</h3>

<p><img src="./_resources/mlf155.jpg" alt="mlf155"/></p>

<p>re-derive <strong>Circular</strong>-PLA, <strong>Circular</strong>-Regression</p>

<p>x~1~ 与 x~2~ 就是某个输入的横纵坐标(这里只考虑二维情况)</p>

<p>对于上面的例子，我们可以假设分类器是一个圆心在原点的正圆，圆内的点被分为+1，圆外的被分为-1，于是有：</p>

<p><img src="./_resources/mlf156.jpg" alt="mlf156"/></p>

<p>在上面的式子中，将 (0.6, -1, -1) 看做向量 w，将(1, x1<sup>2,</sup> x2<sup>2)</sup> 看做向量z，这个形式和传统的线性假设很像。可以这样理解，原来的 x-空间的点都映射到了 z-空间，这样，在 x-空间中线性不可分的数据，在 z-空间中变得线性可分；然后，我们在新的 z-空间中进行线性假设。</p>

<h3 id="toc_97">Linear Hypothesis in Z-Space</h3>

<p><img src="./_resources/mlf157.jpg" alt="mlf157"/></p>

<p><img src="./_resources/mlf158.jpg" alt="mlf158"/></p>

<p>在数学上，通过参数 w 的取值不同，上面的假设可以得到正圆、椭圆、双曲线、常数分类器，它们的中心都必须在原点。如果想要得到跟一般的二次曲线，如圆心不在原点的圆、斜的椭圆、抛物线等，则需要更一般的二次假设。</p>

<p><img src="./_resources/mlf159.jpg" alt="mlf159"/></p>

<p>具体参数 w 的产生，就是把空间转换函数的不同变量的不同次数项一个一个对应写下来。可以参考上图的例子。</p>

<p>对于找个通用的模型来说，直线可以看成是一个退化的特例</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf160.jpg" alt="mlf160"/></p>

<h3 id="toc_98">The Nonlinear Transform Steps</h3>

<p>Good Quadratic Hypothesis</p>

<p><img src="./_resources/mlf161.jpg" alt="mlf161"/></p>

<p>具体步骤如下：</p>

<p><img src="./_resources/mlf162.jpg" alt="mlf162"/></p>

<p><img src="./_resources/mlf163.jpg" alt="mlf163"/></p>

<p>也就是说，在操作上实际上不是往左边的箭头，而是往右边的箭头。往右边的箭头告诉我x-空间的每一个点都可以映射到z-空间，然后我等z-空间的线性分类告诉我分类结果。</p>

<p>如上的流程里面有两个比较关键可以选择的事情：如何做feature transform；选择怎样的linear model。这里的非线性转换其实也是特征转换(feature transform)，在特征工程里很常见。Feature transform 看起来很强大，就像打开了潘多拉的盒子，我们突然一下子可以做更多更多的事情了。不过听起来这么强大，到底有没有什么代价呢？且听下回分解。</p>

<p>not new, not just polynomial:</p>

<p>raw(pixels) (<strong>domain knowledge</strong>)-&gt; <strong>concrete(intensity, symmetry)</strong></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf164.jpg" alt="mlf164"/></p>

<h3 id="toc_99">Computation/Storage Price</h3>

<p>所谓”有得必有失“，将特征转换到高次空间，我们需要付出学习代价（更高的模型复杂度）。x-空间的数据转换到z-空间之后，新的假设中的参数数量也比传统线性假设多了许多：</p>

<p><img src="./_resources/mlf165.jpg" alt="mlf165"/></p>

<p>Q large -&gt; <strong>difficult to compute/store</strong></p>

<h3 id="toc_100">Model Complexity Price</h3>

<p><img src="./_resources/mlf166.jpg" alt="mlf166"/></p>

<p>Q large -&gt; <strong>large d~vc~</strong></p>

<p>那么如何选择呢？</p>

<p><img src="./_resources/mlf167.jpg" alt="mlf167"/></p>

<p>在两个关键问题上没有办法兼得</p>

<p>根据之前分析过的，VC dimension 约等于自由变量(参数)的数量，所以新假设的 d~vc~ 急速变大，也就是模型复杂大大大增加。回顾机器学习前几讲的内容，我们可以有效学习的条件是</p>

<ol>
<li>E~in~(g) 约等于 E~out~(g)</li>
<li>E~in~(g) 足够小。</li>
</ol>

<p>当模型很简单时，d~vc~ 很小，我们更容易满足（1）而不容易满足（2）；反之，模型很复杂时，d~vc~ 很大），更容易满足（2）而不容易满足（1）。看来选择合适复杂度的 model 非常 trick。</p>

<p>careful about <strong>your brain&#39;s model complexity</strong></p>

<p>观察是不可靠的，依靠的是人的学习，已经受主观影响了，所以</p>

<p><img src="./_resources/mlf168.jpg" alt="mlf168"/></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf169.jpg" alt="mlf169"/></p>

<p>(d+2)x(d+1)/2 - 1</p>

<p>注意这里把一个实数空间映射到了一个50次的多项式，因此复杂度增加到了一千多维，这就会带来很高的计算代价</p>

<h3 id="toc_101">polynomial Transform Revisited</h3>

<p>前面我们分析的非线性转换都是多项式转换(polynomial transform)。我们将二次假设记为 H~2~，k次假设记为 H~k~。显然，高次假设的模型复杂度更高。如下图所示，低次假设的模型是包含在高次假设的模型里面的。当Hypothesis之间有这样的互相包含的关系的时候，我们将它叫做hypothesis set的一个结构。</p>

<p><img src="./_resources/mlf170.jpg" alt="mlf170"/></p>

<p>也就是说，高次假设对数据拟合得更充分，E~in~ 更小；然而，由于付出的模型复杂度代价逐渐增加，E~out~ 并不是一直随着 E~in~ 减小。</p>

<p>所以并不是高维度就好，而是应该找到一个折中。</p>

<p><img src="./_resources/mlf171.jpg" alt="mlf171"/></p>

<p>实际工作中，通常采用的方法是：先通过最简单的模型（线性模型）去学习数据，如果 E~in~ 很小了，那么我们就认为得到了很有效的模型；否则，转而进行更高次的假设，一旦获得满意的 E~in~ 就停止学习（不再进行更高次的学习）。</p>

<p><img src="./_resources/mlf172.jpg" alt="mlf172"/></p>

<p>总结为一句话：<strong>linear/simpler model first</strong>! simple, efficient, <strong>safe</strong>, and <strong>workable</strong>!</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf173.jpg" alt="mlf173"/></p>

<h2 id="toc_102">Lecture 13: Hazard of Overfitting</h2>

<p>overfitting happens with <strong>excessive power</strong>, <strong>stochastic/deterministic noise</strong>, and <strong>limited data</strong></p>

<p>Bad Generalization</p>

<p><img src="./_resources/mlf174.jpg" alt="mlf174"/></p>

<p>这是什么意思呢，假设我们在一个二次空间里有五个点，如果我们想要找到的拟合函数是二次多项的话，可以看做是真实的值加上一些小小的噪声(也就是有一些 E~in~ 但并不大)。当然我们也可以用上面的方法把他们转到四次多项式上，那么五个点，四次多项式，有唯一解并且保证了 E~in~(g) = 0，可是与此同时，我们可以看到这条四次多项式和target函数差距很大，E~out~(g) 会非常大。</p>

<p>bad generalization: <strong>low E~in~, high E~out~</strong></p>

<p><img src="./_resources/mlf175.jpg" alt="mlf175"/></p>

<p><strong>overfitting</strong>: low<strong>er</strong> E~in~, high<strong>er</strong> E~out~</p>

<p>简单的说就是这样一种学习现象：VC dimension 太大的时候，E~in~ 很小，E~out~ 却很大。而另外一方面，E~in~ 和 E~out~ 都很大的情况叫做 Under-fitting。这是机器学习中两种常见的问题。这里的fitting指的就是 E~in~ 。上图中，竖直的虚线左侧是”underfitting”, 左侧是”overfitting”。</p>

<p>发生overfitting 的主要原因是：使用过于复杂的模型(d~vc~ 很大)；数据噪音；有限的训练数据。</p>

<p>用开车来比喻的话</p>

<p><img src="./_resources/mlf176.jpg" alt="mlf176"/></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf177.jpg" alt="mlf177"/></p>

<h3 id="toc_103">Case Study</h3>

<p>两组数据，一组由一个十次多项式生成，带噪声；另一组由一个五十次多项式生成，不带噪声；然后我们用二次和十次多项式去拟合，来看看结果如何</p>

<p><img src="./_resources/mlf178.jpg" alt="mlf178"/></p>

<p>overfitting from g~2~ to g~10~? <strong>both yes</strong></p>

<p>可以看到在 E~in~ 部分，g~2~ 要比 g~10~ 大，毕竟是十次多项式；可以要比 E~out~ 的时候，g~10~ 就变得太大了，发生了 overfitting</p>

<p>如上图所示，我们可以分别从噪声与 Data Size 的角度理解地简单些：</p>

<p>有噪音时，更复杂的模型会尽量去覆盖噪音点，即对数据过拟合！这样，即使训练误差E~in~ 很小(接近于零)，由于没有描绘真实的数据趋势，E~out~ 反而会更大。即噪音严重误导了我们的假设。</p>

<p>还有一种情况，如果数据是由我们不知道的某个非常非常复杂的模型产生的，实际上有限的数据很难去“代表”这个复杂模型曲线。我们采用不恰当的假设去尽量拟合这些数据，效果一样会很差，因为部分数据对于我们不恰当的复杂假设就像是“噪音”，误导我们进行过拟合。</p>

<p>如下面的例子，假设数据是由50次幂的曲线产生的（下图右边，without噪声），与其通过10次幂的假设曲线去拟合它们，还不如采用简单的2次幂曲线来描绘它的趋势。</p>

<p><img src="./_resources/mlf179.jpg" alt="mlf179"/></p>

<p>以退为进 philosophy: <strong>concession</strong> for <strong>advantage</strong></p>

<h3 id="toc_104">Learning Curves Revisited</h3>

<p><img src="./_resources/mlf180.jpg" alt="mlf180"/></p>

<p>在样本数量比较小的时候，低次项多项式反而效果会更好。没有太多数据的话，不妨直接用简单的 hypothesis</p>

<p>在没有 noise 的情况下，情况依然是二次的比较好</p>

<p><img src="./_resources/mlf181.jpg" alt="mlf181"/></p>

<p>当你要学习的东西是很复杂的时候，其实这个复杂度本身就是 noise，因为无论二次还是十次都没办法完全拟合</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf182.jpg" alt="mlf182"/></p>

<h3 id="toc_105">A Detailed Experiment</h3>

<p>什么时候需要小心 overfit 会发生</p>

<p>我们在 target function 上加一个高斯噪声，然后来研究不同的噪声强度对于 overfitting 的影响</p>

<p><img src="./_resources/mlf183.jpg" alt="mlf183"/></p>

<p>某个次方的多项式叫做 Q~f~ 比如说十次多项式就是 Q~10~</p>

<p><img src="./_resources/mlf184.jpg" alt="mlf184"/></p>

<p>红色表示非常 overfit，蓝色表示没有多少 overfit，</p>

<p><img src="./_resources/mlf185.jpg" alt="mlf185"/></p>

<p>可见，数据规模一定时，随机噪音越大，或者确定性噪音越大（即目标函数越复杂），越容易发生overfitting。总之，容易导致overfitting 的因素是：数据过少；随机噪音过多；确定性噪音过多；假设过于复杂(excessive power)。</p>

<p>对于最后一点解释一下，右边这个图与左边的图有一些小小的不一样：靠下部分说明好像 Q~f~ 往小的方向走的时候也会有overfit的现象出现。大家知道我们 overfit 的衡量方式是 E~out~(g~10~) – E~out~(g~2~)，当 target function 是10次多项式以下的时候，那么学习器 g~10~ 就太强了。</p>

<p>overfitting &#39;easily&#39; happens</p>

<p><img src="./_resources/mlf186.jpg" alt="mlf186"/></p>

<p>如果我们的假设空间不包含真正的目标函数f(X)（未知的），那么无论如何 H 无法描述f(X) 的全部特征。这时就会发生确定性噪音。它与随机噪音是不同的。例如，目标函数是50次的多项式，而hypothesis是10次多项式的话，一定找个target function有某些地方是没办法被任何一个hypothesis所描述的。我们可以类比的理解它：在计算机中随机数实际上是“伪随机数”，是通过某个复杂的伪随机数算法产生的，因为它对于一般的程序都是杂乱无章的，我们可以把伪随机数当做随机数来使用。确定性噪音的哲学思想与之类似。</p>

<p>philosophy: when teaching a kid, perhaps better not to use examples from a complicated target function</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf187.jpg" alt="mlf187"/></p>

<p>对应导致过拟合发生的几种条件，我们可以想办法来避免过拟合。</p>

<p><img src="./_resources/mlf188.jpg" alt="mlf188"/></p>

<p>all very <strong>practical</strong> techniques to combat overfitting</p>

<p>假设过于复杂(excessive d~vc~) =&gt; start from simple model</p>

<p>随机噪音 =&gt; 数据清洗(Data Cleaning/Pruning)：将错误的label 纠正或者删除错误的数据。possibly helps, but <strong>effect varies</strong></p>

<p>数据规模太小 =&gt; 收集更多数据，或根据某种规律“伪造”更多数据（Data hinting）：例如，在数字识别的学习中，将已有的数字通过平移、旋转等，变换出更多的数据。</p>

<p>正规化(regularization) 也是限制模型复杂度的方法，在下一讲介绍。其他解决过拟合的方法在后面几讲介绍。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf189.jpg" alt="mlf189"/></p>

<p>要保证对称性，跟 target 函数一致</p>

<h2 id="toc_106">Lecture 14: Regularization</h2>

<p>minimizes <strong>augmented error</strong>, where the added <strong>regularizer</strong> effectively <strong>limits model complexity</strong></p>

<p>发生 Overfitting 的一个重要原因可能是假设过于复杂了，我们希望在假设上做出让步，用稍简单的模型来学习，避免 Overfitting。例如，原来的假设空间是10次曲线，很容易对数据过拟合；我们希望它变得简单些，比如 w 向量只保持三个分量（其他分量为零）。</p>

<p><img src="./_resources/mlf190.jpg" alt="mlf190"/></p>

<p><img src="./_resources/mlf191.jpg" alt="mlf191"/></p>

<p>step back = <strong>constrain</strong></p>

<p>也就是 Hypothesis Set 需要从高阶 step back 到低阶，例如从从10次多项式 H~10~ 走回到2次多项式 H~2~，如下图左所示。实际上就是代表在原来的Learning问题上加上一些限制Constraint。</p>

<p><img src="./_resources/mlf192.jpg" alt="mlf192"/></p>

<p>如果现在将左图的限制放松一些，如下右图所示。</p>

<p><img src="./_resources/mlf193.jpg" alt="mlf193"/></p>

<p>boolean operation 的最优化是困难的(上图右边的 s.t. 部分，那个类似方括号的操作)</p>

<p>可是，右上图中的优化问题是 NP-Hard 的。如果对 w 进行更soft/smooth 的约束，可以使其更容易优化。我们将此时的假设空间记为H(C)，这是“正则化的Hypothesis Set”。如果我们能够顺利地解决下图的最佳化问题，找出一个好的 w~REG~ 的话，那么就是regularized hypothesis。</p>

<p><img src="./_resources/mlf194.jpg" alt="mlf194"/></p>

<p>把一个离散的替换成一个连续的，方便优化</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf195.jpg" alt="mlf195"/></p>

<p>前面可以知道向量 w~q~<sup>2^</sup> 的和要小于 H(C) 中的 C，答案三不符合这个条件</p>

<h3 id="toc_107">Matrix Form of Regularized Regression Problem</h3>

<p><img src="./_resources/mlf196.jpg" alt="mlf196"/></p>

<p>把回归问题写成矩阵的形式</p>

<h3 id="toc_108">The Lagrange Multiplier</h3>

<p>那如何求解这个优化问题呢？先来看看我们新加入的这个限制对优化问题造成了怎样的影响。原来没有限制的时候，只需要让目标函数沿着梯度的反方向一路滚下去知道梯度=0。那加入了限制之后，也就是说w需要在一个红色的球里滚动，如下图所示。可以想象，大部分的时候我们需要的解都是在球的边界附近，只要梯度与w不是平行的，目标函数就仍然可以向谷底滚一点点，可以得到一个更好的解。也就是说，最优的结果是梯度与 w~REG~是平行的。</p>

<p><img src="./_resources/mlf197.jpg" alt="mlf197"/></p>

<p>w~lin~: 做 linear regression 的解</p>

<p>我们现在要做的是在一定限制里求解，所以解必须在圆圈里。在边缘的带点只能在垂直于球的法向量的方向上滚。如果梯度的反方向和 w 不平行，那么在可以滚的方向上会有一个分量，就可以沿着允许的方向滚。</p>

<p>直到 ▽E~in~(w~REG~) 和 w~REG~ 平行，才算是找到了最优解</p>

<p>也就是满足最下面的公式(拉格朗日参数 λ)</p>

<h3 id="toc_109">Augmented Error</h3>

<p><img src="./_resources/mlf198.jpg" alt="mlf198"/></p>

<p><strong>ridge regression</strong></p>

<p>minimizing <strong>unconstrained E~aug~</strong> effectively minimizes some <strong>C-constrained</strong> E~in~</p>

<p><img src="./_resources/mlf199.jpg" alt="mlf199"/></p>

<p>我们要求解的话，就要找出 w~REG~，然后看看有没有一个相对应的 λ，让这两个向量是平行的。观察下面这个式子发现，梯度是原来 E~in~ 的微分，只要对 w~REG~ 做积分，那么就可以得到原来的目标函数的等价形式。</p>

<p>求梯度等于零，实际上就是找原函数的最小值在哪里</p>

<p>加上的这一项通常叫做regularizer。如果给定了 λ (λ&gt;=0，因为它代表两个向量长度的比值而 λ = 0则就代表无限制的原问题)，那么就可以通过解这个优化问题得到 w~REG~。也就是说，我们不再需要去求解之前的那个 constrained C 的优化问题了，对于使用者来说，指定 C 与指定 λ 来说没有什么区别。</p>

<p>也就是原来的条件成为了目标函数的一部分了</p>

<h3 id="toc_110">The Result</h3>

<p><img src="./_resources/mlf200.jpg" alt="mlf200"/></p>

<p>一点点的 regularization 也会有很好的效果</p>

<p>总之，λ 越大，希望的 w 越短越好(因为在最小化问题中相当于在惩罚长的 w)，对应的常数 C 越小，模型越倾向于选择更小的 w 向量。这种正规化成为 weight-decay regularization，它对于线性模型以及进行了非线性转换的线性假设都是有效的。</p>

<h3 id="toc_111">Legendre Polynomials</h3>

<p>另外补充一下，虽然 regularization 可以跟任何的transform做搭配，课件中的实验为了结果更明显一些，其实在transform的时候加入了一点小技巧。naive 多项式的transform有一些小小的缺点：如果|x| &lt;= 1，高次 x<sup>Q^</sup> 是很小的数字，要想它在hypothesis中发挥影响力则需要很大的 w，这就与 regularization 目的（将w压到很小）背道而驰。也就是说 regularization 会过度地惩罚了高次的 x<sup>Q^</sup> ，这里用的技巧就叫做 legendre polynomials，如下图所示。</p>

<p><img src="./_resources/mlf201.jpg" alt="mlf201"/></p>

<p>找一些互相垂直的基底，用原来的多项式做垂直化(系数会有一些改变，补偿呗过分惩罚的高次项分数)，效果会更好</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf202.jpg" alt="mlf202"/></p>

<ul>
<li>λ = 0则就代表无限制的原问题</li>
<li>C 很大，表示条件很宽松，也包含了线性回归的解</li>
</ul>

<h3 id="toc_112">Regularization and VC Theory</h3>

<p><img src="./_resources/mlf203.jpg" alt="mlf203"/></p>

<p>根据 VC Bound 理论，E~in~ 与 E~out~ 的差距是模型的复杂度。也就是说，假设越复杂（d~vc~ 越大），E~out~ 与 E~in~ 相差就越大，违背了我们学习的意愿。</p>

<h3 id="toc_113">Another View of Augmented Error</h3>

<p><img src="./_resources/mlf204.jpg" alt="mlf204"/></p>

<p>E~aug~ 跟 VC 其实有一些异同，E~aug~ 新加入的那项可以认为是某个单一 hypothesis 有多复杂；而 VC 则表示整个hypothesis set有多复杂。也许，E~aug~ 是一个比原来的 E~in~ 的更好的代理。</p>

<p>minimizing E~aug~:</p>

<ul>
<li>(heuristically) operating with the better proxy;</li>
<li>(technically) enjoying flexibility of whole H</li>
</ul>

<p><img src="./_resources/mlf205.jpg" alt="mlf205"/></p>

<p>对于某个复杂的假设空间 H，d~vc~ 可能很大；通过正规化，原假设空间变为正规化的假设空间 H(C)。与 H 相比，H(C) 是受正规化的“约束”的，因此实际上 H(C) 没有 H 那么大，也就是说 H(C) 的 VC维比 原 H 的VC维要小，也就是 Effective VC Dimension。因此，E~out~ 与 E~in~ 的差距变小。</p>

<p>不仅考虑了 Hypothesis set，也考虑了算法怎么做选择，就可以得到一个更优化的 VC Dimension</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf206.jpg" alt="mlf206"/></p>

<h3 id="toc_114">General Regularizers Ω(w)</h3>

<p>want: constrait in the <strong>&#39;direction&#39; of target function</strong></p>

<p>刚刚讲到的regularizer都集中在weight decay上面，那如果想要换更一般的regularizer呢。指导我们更好地设计正规项的原则：最好能告诉target function在哪一个方向。</p>

<p><img src="./_resources/mlf207.jpg" alt="mlf207"/></p>

<ul>
<li>target-dependent(symmetry)：如果知道target function的特性，也许可以放进去。例如如果想要的是比较接近偶次方函数，加上的regularizer就是让奇次方的w越小越好。</li>
<li>plausible(sparsity)：有说服力的，例如比较平滑或者简单的regularizer。因为regularization主要是为了解决overfitting</li>
<li>friendly(optimize)：方便优化求解。</li>
</ul>

<p>当然，就算选择了一个不太好的regularizer，还有lamda = 0的保护，最差就是不用它而已。</p>

<p>regularizer 和 error measure 的方向很像，三个不同的面向</p>

<p><strong>机器学习是一门非常重实践的学科，要多写代码</strong></p>

<h3 id="toc_115">L2 and L1 Regularizer</h3>

<p><img src="./_resources/mlf208.jpg" alt="mlf208"/></p>

<p>那接下来来看一下L2与L1的regularizer。L2非常的平滑，也易于求解。那L1的特点呢？它也是convex的，不过不是处处可微。不过L1的解常常会是sparse的，也就是w中会有很多的0，因为它的解常常会发生在顶点处。</p>

<p><strong>L1 useful if needing sparse solution</strong></p>

<h3 id="toc_116">The Optimal λ</h3>

<p><img src="./_resources/mlf209.jpg" alt="mlf209"/></p>

<p>那 λ 应该如何选择？λ 当然不是越大越好！选择合适的 λ 也很重要，它收到随机噪音和确定性噪音的影响，噪音越大，需要的 λ 越大。那具体要如何选择呢？且听下回分解。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf210.jpg" alt="mlf210"/></p>

<h2 id="toc_117">Lecture 15: Validation</h2>

<p>(crossly) reserve <strong>validation data</strong> to simulate testing procedure for <strong>model selection</strong></p>

<p>机器学习的每个模型都有各式各样的参数。即使只是对于二元分类，学习算法上可以选择PLA，LR等；很多学习算法都是iterative的，需要决定迭代次数；可能需要决定每一次迭代走多大，例如梯度下降；或者有很多的transform，例如线性、二次等；同时 regularizer 又有很多的选择 L1/L2；再来 regularizer 到底要加多强的 λ。况且这些选择是组合起来的，那么我们怎么做出正确的选择？</p>

<p><img src="./_resources/mlf211.jpg" alt="mlf211"/></p>

<p>in addition to your <strong>favorite</strong> combination, may need to try other combinations to get a good <strong>g</strong></p>

<p><img src="./_resources/mlf212.jpg" alt="mlf212"/></p>

<p>把模型选择问题一般化一下，就是如下的定义：有 M 个模型，每个模型有其对应的 Hypothesis set 以及学习算法A，希望选出某一个模型得到的g，它的 E~out~(g) 是最小的。但是 E~out~ 不知道，无法以其作为标准。</p>

<p><img src="./_resources/mlf213.jpg" alt="mlf213"/></p>

<p>根据 E~in~(g) 最小来选择模型也是行不通的。一方面容易造成 overfitting；另一方面，假设有两个模型PK：算法 A~1~ 在 H~1~ 上让 E~in~ 最小；算法 A~2~ 在 H~2~ 上让 E~in~ 最小。最后选出来的 g 的效果是在 H~1~∪H~2~ 上让 E~in~ 最小，也就说额外增加了model complexity，容易造成bad generalization。</p>

<p><strong>selecting by E~in~ is dangerous</strong></p>

<p><img src="./_resources/mlf214.jpg" alt="mlf214"/></p>

<p>通过测试数据来选择模型是自欺欺人的。如果能找到一些测试数据，来看看哪一个模型的表现更好就选择哪个。如果用这样的方式，可以得到Hoeffding的理论保证如下图。看起来很棒，可是问题是我们找不到测试数据，测试数据就像考卷，不可能说考试之前就发下来的。</p>

<p><strong>selecting by E~test~ is infeasible and cheating</strong></p>

<h3 id="toc_118">Comparison between E~in~ and E~test~</h3>

<p><img src="./_resources/mlf215.jpg" alt="mlf215"/></p>

<p>那，将这两者结合一下：把训练数据留一部分下来作为测试数据，用其他的训练数据来训练模型，然后用测试数据来测试模型的表现好坏。这是legal cheating。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf216.jpg" alt="mlf216"/></p>

<p>根据上面的分析，原来的训练数据分割出一部分作为测试数据，也被叫做validation set。同样，也会有 Hoeffding 不等式的保证。</p>

<p><img src="./_resources/mlf217.jpg" alt="mlf217"/></p>

<p>为了和原来的 E~out~ 作比较，我们知道更多的训练数据一般来说会有更好的 E~out~。所以很大程度上来说也就有如下的保证。</p>

<p><img src="./_resources/mlf218.jpg" alt="mlf218"/></p>

<p>先把数据切成两个部分，训练集和测试集，用训练集训练出最好的模型，再把所有的数据放到最好的模型上训练，这样就可以找到用更多数据训练出来的最佳模型(不是 g<sup>-^</sup> 了)</p>

<p><img src="./_resources/mlf219.jpg" alt="mlf219"/></p>

<p>我们来看看 validation 有没有用，横轴是 validatoin set 的大小，纵轴是 Expected E~out~(越低越好)，如果用 in-sample 会得到的那条横线；如果作弊用 E~test~ 会得到最下面的虚线；如果只用训练集，那么会得到 g<sup>-<sup>；如果选出最佳之后再用全部的数据集，会得到</sup></sup> g。</p>

<p>我们可以看到用 g 的时候，实际上是很有用的。但是 g<sup>-^</sup> 有时候比用 E~in~ 还糟糕，为什么呢？因为当测试集太大，训练集就会太小，效果就不好</p>

<h3 id="toc_119">The Dilemma about K</h3>

<p><img src="./_resources/mlf220.jpg" alt="mlf220"/></p>

<p>那 Validation Set 的大小 K 应该如何选择？选择的 K 应该尽可能地让这三个 Error 约等式成立。通常情况下，K 取 N/5。</p>

<p><img src="./_resources/mlf221.jpg" alt="mlf221"/></p>

<p>注意到加入Validation的方式花的时间比原来25N<sup>2要来的小，因为训练模型的数据更少了。</sup></p>

<h3 id="toc_120">Leave-One-Out Cross Validation</h3>

<p>考虑一个极端的情形，取非常小的K = 1。小的K可以让 E~out~(g) 与 E~out~(g-)非常接近，不过之前那个约等式右边希望 E~out~(g-) 与 E~val~(g-)接近就很难满足了。那我们来看看能不能克服这个问题。</p>

<p><img src="./_resources/mlf222.jpg" alt="mlf222"/></p>

<p>e~n~ 表示取第 n 笔数据作为 validation data，所得到的 E~val~(g-)。e~n~ 到底能不能告诉我们 E~out~(g)有多好呢？一个 e~n~ 当然不行，那把每笔数据都作为一次 validation data 然后平均起来，选择平均 Error 最小的作为最后的g，这样的方式叫做 cross validation。</p>

<p>E~loocv~(H, A) ≈ E~out~(g)</p>

<p><img src="./_resources/mlf223.jpg" alt="mlf223"/></p>

<p>那 Leave-one-out Cross Validation 有何理论保证呢？或者它能不能告诉我们最在乎的事情 E~out~(g)有多好。假设有一个算法和1000笔数据拿来做 Leave-one-out Cross Validation，然后对各式各样的1000笔数据来做取一个平均。证明跟 E~out~(N-1)的平均值是可以连接的。因为 E~out~(g-) 与 E~out~(g) 几乎是一样的，前者是1000笔数据做出来的，后者是999笔数据做出来的。</p>

<p>e~n~前面的符号表示期望值</p>

<p>所以，我们得到了一个几乎完全没有偏见的针对 E~out~(g)的衡量方式。也就是说，Leave-one-out Cross Validation在选择模型上会比 E~in~ 来的更有效。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf224.jpg" alt="mlf224"/></p>

<h3 id="toc_121">Disadvantages of Leave-One-Out Estimate</h3>

<p><img src="./_resources/mlf225.jpg" alt="mlf225"/></p>

<p>很明显，一方面，Leave-One-Out Cross Validation大大增加了计算的复杂度，实际应用上上可能不太行；另一方面，对于二元分类来说，分类结果在0与1之间跳动，Leave-One-Out求一个平均值。对这个平均值来说，这些0与1的跳动是很大的，希望用平均的方式把这些很大的跳动消掉，其实还是不太容易。</p>

<p>这两个问题使得这个方法在实际上并不是特别常用</p>

<h3 id="toc_122">V-fold Cross Validation</h3>

<p>how to <strong>decrease computation need</strong> for cross validation?</p>

<p><img src="./_resources/mlf226.jpg" alt="mlf226"/></p>

<p>practical rule of thumb: V = 10</p>

<p>为了降低计算复杂度，将训练资料分为V份，取其中V-1做训练，另外1份做validation。这种方式通常叫做V-fold Cross Validation，实际上V通常取10。</p>

<h3 id="toc_123">Final Words on Validation</h3>

<p><strong>Selecting Validation Tool</strong></p>

<ul>
<li><strong>V-Fold</strong> generally preferred over single validation if computation allows</li>
<li><strong>5-Fold or 10-Fold</strong> generally works well: not necessary to trade V-Fold with Leave-One-Out</li>
</ul>

<p><strong>Nature of Validation</strong></p>

<ul>
<li>all training models: select among hypotheses</li>
<li>all validation schemes: select among finalists</li>
<li>all testing methods: just evaluate</li>
</ul>

<p>validation still more optimistic than testing</p>

<p>do not fool yourself and others, <strong>report test result</strong>, not <strong>best validation result</strong></p>

<p>Traning 就像初赛，各个模型都从 Hypothesis Set 中选出最合适的h；Validation就像复赛，从多种模型的scheme中选出一个最优的。这两步都是在进行模型选择，之后的testing methods都只是在对模型进行estimate了。也因为Validation还是在做选择，只要做选择就会有数据的污染等等，所以Validation仍然比testing要乐观。对于模型来说，testing的表现才是真正要看重的，而不是最好的validation的表现。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf227.jpg" alt="mlf227"/></p>

<h2 id="toc_124">Lecture 16: Three Learning Principles</h2>

<h3 id="toc_125">Occam&#39;s Razor</h3>

<blockquote>
<p>An explanation of the data should be made as simple as possible, but no simpler.</p>

<p>Entities must not be muliplied beyond necessity. -- William of Occam</p>
</blockquote>

<p><strong>Occam&#39;s razor</strong> for trimming down unnecessary explanation</p>

<p>The simplest model that fits the data is aslo the most plausible</p>

<p>它的哲学意义蛮有名的，比喻剃掉过分的解释。在机器学习里面的意思就是：对训练数据最简单的解释就是最好的。那么问题来了，什么叫做简单的模型和解释；以及为什么确定简单的就是最好的？</p>

<p>曾今定义过 simple hypothesis：看起来很简单，例如一个大大的圆而不是弯弯曲曲的曲线；只需要少数的参数，圆心和半径就能确定这个 hypothesis长什么样子。也曾今定义过 simple model(也就是Hypothesis Set)：有效的hypothesis数量不是很多，成长函数长的很慢。</p>

<h3 id="toc_126">Simple Model</h3>

<p><img src="./_resources/mlf228.jpg" alt="mlf228"/></p>

<p>simple: **small hypothesis/model complexity</p>

<p><strong>Simple is Better</strong></p>

<p><img src="./_resources/mlf229.jpg" alt="mlf229"/></p>

<p>那为什么简单是好的呢？直觉的解释如下：想象有一个简单的model，同时给你一堆随机产生的没什么规律的训练数据。这时候你的 model 只有很小的机会能够找到 E~in~ 是0，杂乱的训练数据导致大部分的时候都没办法分开。那反过来说，如果今天有一组训练数据用你的 simple model 可以分开，这表明了你的数据是有显著性的，是有规律的数据。而用复杂的模型，则是达不到这样的效果的。</p>

<p>direct action: <strong>linear first</strong></p>

<p>always ask whether <strong>data over-modeled</strong></p>

<p>所以根据这个锦囊妙计出发，先试线性的模型；选择模型之前永远要想一想是否尽可能地用了最简单的模型。</p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf230.jpg" alt="mlf230"/></p>

<h3 id="toc_127">Sampling Bias</h3>

<p>抽样有偏差的时候，学习算法产生的结果也会有偏差，这样的情形叫做Sampling bias。VC理论里的一个假设就是：训练数据与测试数据来自于同一个分布。不然的话，学习可能没办法做的很好。那怎么办呢？</p>

<p>实用的建议：了解你的测试环境，让你的训练环境跟测试环境尽可能地接近。举例来说，如果测试环境是last user records，也就是时间轴上靠后的使用者资料，那么训练的时候应该要想办法对时间轴上靠后的数据的权重加强一下。或者，做validation的时候也选择late user records靠后的用户资料。</p>

<p>If the data is sampled in a biased way, learning will produce a similarly biased outcome.</p>

<p>techincal explanation: data from P~1~(x, y) but test under P~2~ ≠ P~1~: <strong>VC fails</strong></p>

<p>philosophical explanation: study Math but test English: no strong test guarantee</p>

<p>&#39;minor&#39; VC assumption: data and testing <strong>both iid from P</strong></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf231.jpg" alt="mlf231"/></p>

<h3 id="toc_128">Visual Data Snooping</h3>

<p>第三个锦囊妙计就是不要偷看数据。例如之前我们通过观察数据发现圆圈可能是一个好的hypothesis，这其实忽略了人脑的VC dimension。当然实际情况下，偷看资料可能经常发生，不只有使用眼睛的方式。</p>

<p>学习中使用数据的任何过程，都是间接地让你偷看到数据。偷看到数据的表现以后，在下决策去做任何的一件事都要想到，这个数据已经因为你的决策选择过程而多出了很多的model complexity而污染。</p>

<p>所以，在实际操作中，要谨慎地处理Data Snooping这件事情。要做到完全不偷看数据很难，一个折中的方式是做validation。另外，在实际操作中如果要做什么决定的时候尽量避免用数据来做决定，要先把domain knowledge变成feature放进去而不是看完数据再放专业知识进去。然后，要时刻存着怀疑之心，时刻要有一个感觉经过多少过程得到这些结果，结果到底可能被污染的多严重。</p>

<p>If a data set has affected any step in the learning process, its ability to assess the outcome has been compromised.</p>

<h3 id="toc_129">Dealing with Data Snooping</h3>

<ul>
<li>truth - <strong>very hard to avoid</strong>, unless being extremely honest</li>
<li>extremely honest: <strong>lock your test data in same</strong></li>
<li><p>less honest: <strong>reserve validation and use cautiously</strong></p></li>
<li><p>be blind: avoid <strong>making modeling decision by data</strong></p></li>
<li><p>be suspicious: interpret research results (including your onw) by proper <strong>feeling of contamination</strong></p></li>
</ul>

<p>careful balance between <strong>data driven modeling(snooping)</strong> and <strong>validation (no-snooping)</strong></p>

<p><strong>一个习题</strong></p>

<p><img src="./_resources/mlf232.jpg" alt="mlf232"/></p>

<h3 id="toc_130">Power of Three</h3>

<p>Three Related Fields</p>

<p><img src="./_resources/mlf233.jpg" alt="mlf233"/></p>

<p>Three Theoretical Bounds</p>

<p><img src="./_resources/mlf234.jpg" alt="mlf234"/></p>

<p>Three Linear Models</p>

<p><img src="./_resources/mlf235.jpg" alt="mlf235"/></p>

<p>Three Key Tools</p>

<p><img src="./_resources/mlf236.jpg" alt="mlf236"/></p>

<p>Three Learning Principles</p>

<p><img src="./_resources/mlf237.jpg" alt="mlf237"/></p>

<p>三个相关的领域：</p>

<ul>
<li>Data Mining：从大量的数据里找出一些有兴趣的特性。它跟ML是高度相关的。</li>
<li>Artificial Intelligence：想让机器做一些有智慧的事情。ML是实现AI的一种方法。</li>
<li>Statistics：从数据里做一些推论的动作。是ML的工具。</li>
</ul>

<p>三个理论保证：</p>

<ul>
<li>Hoeffding不等式：针对单个hypothesis的抽样</li>
<li>Multi-Bin Hoeffding：针对M个hypothesis</li>
<li>VC Bound：针对整个hypothesis set。</li>
</ul>

<p>三个模型：</p>

<ul>
<li>PLA/Pocket：二元分类</li>
<li>Linear regression：线性回归，公式解</li>
<li>Logistic regression：分类概率</li>
</ul>

<p>三个重要工具：</p>

<ul>
<li>Feature Transform：通过映射到高维空间，将E_in变小。</li>
<li>Regularization：反其道而行，想让VC Dimension变小一点，但是可能E_in会变大一些。</li>
<li>Validation：留下干净的数据来做模型的选择。</li>
</ul>

<p>三个锦囊妙计：</p>

<ul>
<li>Occam’s Razer：simple is good。</li>
<li>Sampling Bias：training matches testing。</li>
<li>Data Snooping：honesty is best policy。</li>
</ul>

<p>Three Future Directions</p>

<p><img src="./_resources/mlf238.jpg" alt="mlf238"/></p>

<p>未来的学习方向：将在后续的机器学习技法课程中讲解。一个是更多不一样的转换方式，不止有多项式的转换；一个是更多的正则化的方式；再来就是不是那么多的Label，譬如说要做无监督的学习应该要如何来做等等。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007753.html">
                
                  <h1>机器学习中的重要概念</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>这里主要包括机器学习中的一些基本方法和概念的介绍。</p>

<!-- MarkdownTOC -->

<ul>
<li>判别模型、生成模型与朴素贝叶斯方法

<ul>
<li>高斯判别分析(Gaussian dicriminant analysis)</li>
<li>朴素贝叶斯模型</li>
<li>拉普拉斯平滑</li>
</ul></li>
<li>回归算法与分类算法

<ul>
<li>线性回归(Linear Regression)</li>
<li>Logistic 回归（拓展到一般回归）</li>
<li>问题引入</li>
<li>学习过程</li>
<li>线性回归</li>
<li>梯度下降法</li>
<li>最小二乘法</li>
<li>选用误差函数为平方和的概率解释</li>
<li>带权重的线性回归</li>
<li>分类和logistic回归</li>
<li>牛顿法来解最大似然估计</li>
<li>一般线性模型</li>
<li>Softmax回归</li>
</ul></li>
<li>K-Means(K 均值算法)</li>
<li>混合高斯模型(Mixtures of Gaussians)</li>
<li>The EM Algorithm

<ul>
<li>Jenson</li>
<li>EM 算法</li>
<li>重新审视混合高斯模型</li>
<li>总结</li>
</ul></li>
<li>PCA 主成分分析

<ul>
<li>PCA 计算过程</li>
<li>PCA 理论基础</li>
<li>最大方差理论</li>
<li>总结与讨论</li>
</ul></li>
<li>10折交叉验证</li>
<li>极大似然估计</li>
<li>熵</li>
<li>后验概率</li>
<li>集成方法</li>
<li>SVD(singular value decomposition) 奇异值分解</li>
<li>SVM(Support Vector Machines) 支持向量机：</li>
<li>决策树</li>
<li>K-近邻算法（KNN）</li>
<li>树回归</li>
</ul>

<!-- /MarkdownTOC -->

<h2 id="toc_0">判别模型、生成模型与朴素贝叶斯方法</h2>

<p>回归模型是判别模型，也就是根据特征值来求结果的概率。形式化表示为p(y|x;theta)，在参数 theta 确定的情况下，求解条件概率 p(y|x)。通俗的解释为在给定特征后预测结果出现的概率。</p>

<p>比如说要确定一只羊是山羊还是绵羊，用判别模型的方法是先从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。换一种思路，我们可以根据山羊的特征首先学习出一个山羊模型，然后根据绵羊的特征学习出一个绵羊模型。然后从这只羊中提取特征，放到山羊模型中看概率是多少，再放到绵羊模型中看概率是多少，哪个大就是哪个。形式化表示为求p(x|y)（也包括p(y))，y是模型结果，x是特征。</p>

<p>利用贝叶斯公式发现两个模型的统一性：</p>

<p><img src="./_resources/nb1.png" alt="nb1"/></p>

<p>由于我们关注的是y的离散值结果中哪个概率大（比如山羊概率和绵羊概率哪个大），而并不是关心具体的概率，因此上式改写为：</p>

<p><img src="./_resources/nb2.jpg" alt="nb2"/></p>

<p>常见的判别模型有线性回归、对数回归、线性判别分析、支持向量机、boosting、条件随机场、神经网络等。</p>

<p>常见的生产模型有隐马尔科夫模型、朴素贝叶斯模型、高斯混合模型、LDA、Restricted Boltzmann Machine等。</p>

<h3 id="toc_1">高斯判别分析(Gaussian dicriminant analysis)</h3>

<p>1）多值正态分布</p>

<p><img src="./_resources/gda1.jpg" alt="gda1"/></p>

<p><img src="./_resources/gda2.jpg" alt="gda2"/></p>

<p><img src="./_resources/gda3.jpg" alt="gda3"/></p>

<p>2）模型分析与应用</p>

<p>如果输入特征x是连续型随机变量，那么可以使用高斯判别分析模型来确定p(x|y)。</p>

<p>模型如下：</p>

<p><img src="./_resources/gda4.png" alt="gda4"/></p>

<p>输出结果服从伯努利分布，在给定模型下特征符合多值高斯分布。通俗地讲，在山羊模型下，它的胡须长度，角大小，毛长度等连续型变量符合高斯分布，他们组成的特征向量符合多值高斯分布。</p>

<p>这样，可以给出概率密度函数：</p>

<p><img src="./_resources/gda5.png" alt="gda5"/></p>

<p>最大似然估计如下：</p>

<p><img src="./_resources/gda6.png" alt="gda6"/></p>

<p>注意这里的参数有两个<code>u</code>(mu)，表示在不同的结果模型下，特征均值不同，但我们假设协方差相同。反映在图上就是不同模型中心位置不同，但形状相同。这样就可以用直线来进行分隔判别。</p>

<p>求导后，得到参数估计公式：</p>

<p><img src="./_resources/gda7.jpg" alt="gda7"/></p>

<p>如前面所述，在图上表示为：</p>

<p>直线两边的y值不同，但协方差矩阵相同，因此形状相同。<code>u</code>(mu) 不同，因此位置不同。</p>

<p>3）高斯判别分析（GDA）与logistic回归的关系</p>

<p>将GDA用条件概率方式来表述的话，如下：</p>

<p><img src="./_resources/gda8.jpg" alt="gda8"/></p>

<p>这个形式就是logistic回归的形式。</p>

<p>也就是说如果p(x|y)符合多元高斯分布，那么p(y|x)符合logistic回归模型。反之，不成立。为什么反过来不成立呢？因为GDA有着更强的假设条件和约束。</p>

<p>如果认定训练数据满足多元高斯分布，那么GDA能够在训练集上是最好的模型。然而，我们往往事先不知道训练数据满足什么样的分布，不能做很强的假设。Logistic回归的条件假设要弱于GDA，因此更多的时候采用logistic回归的方法。</p>

<p><img src="./_resources/gda9.jpg" alt="gda9"/></p>

<p>这个时候如果采用GDA，那么效果会比较差，因为训练数据特征的分布不是多元高斯分布，而是泊松分布。</p>

<p>这也是logistic回归用的更多的原因。</p>

<h3 id="toc_2">朴素贝叶斯模型</h3>

<p>在GDA中，我们要求特征向量x是连续实数向量。如果x是离散值的话，可以考虑采用朴素贝叶斯的分类方法。</p>

<p>假如要分类垃圾邮件和正常邮件。分类邮件是文本分类的一种应用。</p>

<p>假设采用最简单的特征描述方法，首先找一部英语词典，将里面的单词全部列出来。然后将每封邮件表示成一个向量，向量中每一维都是字典中的一个词的0/1值，1表示该词在邮件中出现，0表示未出现。</p>

<p>比如一封邮件中出现了“a”和“buy”，没有出现“aardvark”、“aardwolf”和“zygmurgy”，那么可以形式化表示为：</p>

<p><img src="./_resources/nb3.png" alt="nb3"/></p>

<p>假设字典中总共有5000个词，那么x是5000维的。这时候如果要建立多项式分布模型（二项分布的扩展）。</p>

<p>多项式分布（multinomial distribution）</p>

<p>某随机实验如果有k个可能结局A1，A2，…，Ak，它们的概率分布分别是p1，p2，…，pk，那么在N次采样的总结果中，A1出现n1次，A2出现n2次，…，Ak出现nk次的这种事件的出现概率P有下面公式：（Xi代表出现ni次）</p>

<p><img src="./_resources/nb4.png" alt="nb4"/></p>

<p>对应到上面的问题上来，把每封邮件当做一次随机试验，那么结果的可能性有 2<sup>5000</sup> 种。意味着pi有2<sup>5000个，参数太多，不可能用来建模。</sup></p>

<p>换种思路，我们要求的是p(y|x)，根据生成模型定义我们可以求p(x|y)和p(y)。假设x中的特征是条件独立的。这个称作朴素贝叶斯假设。如果一封邮件是垃圾邮件（y=1），且这封邮件出现词“buy”与这封邮件是否出现“price”无关，那么“buy”和“price”之间是条件独立的。</p>

<p>形式化表示为，（如果给定Z的情况下，X和Y条件独立）</p>

<p><img src="./_resources/nb5.jpg" alt="nb5"/></p>

<p>这个与NLP中的n元语法模型有点类似，这里相当于unigram。</p>

<p>这里我们发现朴素贝叶斯假设是约束性很强的假设，“buy”从通常上讲与“price”是有关系，我们这里假设的是条件独立。（注意条件独立和独立是不一样的）</p>

<p>建立形式化的模型表示：</p>

<p><img src="./_resources/nb6.jpg" alt="nb6"/></p>

<p>注意这里是联合概率分布积最大，说明朴素贝叶斯是生成模型。</p>

<p>求解得：</p>

<p><img src="./_resources/nb7.png" alt="nb7"/></p>

<p>最后一个式子是表示y=1的样本数占全部样本数的比例，前两个表示在y=1或0的样本中，特征Xj=1的比例。</p>

<p>然而我们要求的是</p>

<p><img src="./_resources/nb8.jpg" alt="nb8"/></p>

<p>实际是求出分子即可，分母对y=1和y=0都一样。</p>

<p>当然，朴素贝叶斯方法可以扩展到x和y都有多个离散值的情况。对于特征是连续值的情况，我们也可以采用分段的方法来将连续值转化为离散值。具体怎么转化能够最优，我们可以采用信息增益的度量方法来确定（参见Mitchell的《机器学习》决策树那一章）。</p>

<p>比如房子大小可以如下划分成离散值：</p>

<p><img src="./_resources/nb9.jpg" alt="nb9"/></p>

<hr/>

<ul>
<li>优点：在数据较少的情况下仍然有效，可以处理多类别问题。</li>
<li>缺点：对于输入数据的准备方式较为敏感。</li>
<li>适用的数据类型：标称型数据。</li>
<li>算法类型：分类算法</li>
</ul>

<p>简述：朴素贝叶斯是贝叶斯理论的一部分，贝叶斯决策理论的核心思想，即选择具有高概率的决策。朴素贝叶斯之所以冠以朴素开头，是因为其在贝叶斯理论的基础上做出了两点假设：</p>

<ol>
<li>每个特征之间相互独立。</li>
<li>每个特征同等重要。</li>
</ol>

<p>贝叶斯准则是构建在条件概率的基础之上的，其公式如下：</p>

<p>P(H|X）=P(X|H)P(H)/P(X)</p>

<p>ps：P(H|X）是根据X参数值判断其属于类别H的概率，称为后验概率。P(H)是直接判断某个样本属于H的概率，称为先验概率。P(X|H)是在类别H中观测到X的概率（后验概率），P(X)是在数据库中观测到X的概率。可见贝叶斯准则是基于条件概率并且和观测到样本的先验概率和后验概率是分不开的。</p>

<p>总结：对于分类而言，使用概率有事要比使用硬规则更为有效。贝叶斯概率及贝叶斯准则提供了一种利用已知值来估计未知概率的有效方法。可以通过特征之间的条件独立性假设，降低对数据量的需求。尽管条件独立性的假设并不正确，但是朴素贝叶斯仍然是一种有效的分类器。</p>

<h3 id="toc_3">拉普拉斯平滑</h3>

<p>朴素贝叶斯方法有个致命的缺点就是对数据稀疏问题过于敏感。</p>

<p>比如前面提到的邮件分类，现在新来了一封邮件，邮件标题是“NIPS call for papers”。我们使用更大的网络词典（词的数目由5000变为35000）来分类，假设NIPS这个词在字典中的位置是35000。然而NIPS这个词没有在训练数据中出现过，这封邮件第一次出现了NIPS。那我们算概率的时候如下：</p>

<p><img src="./_resources/nb10.png" alt="nb10"/></p>

<p>由于NIPS在以前的不管是垃圾邮件还是正常邮件都没出现过，那么结果只能是0了。</p>

<p>显然最终的条件概率也是0。</p>

<p><img src="./_resources/nb11.png" alt="nb11"/></p>

<p>原因就是我们的特征概率条件独立，使用的是相乘的方式来得到结果。</p>

<p>为了解决这个问题，我们打算给未出现特征值，赋予一个“小”的值而不是0。</p>

<p>具体平滑方法如下：</p>

<p><img src="./_resources/nb12.jpg" alt="nb12"/></p>

<p>说白了就是z=j出现的比例。</p>

<p>拉普拉斯平滑法将每个k值出现次数事先都加1，通俗讲就是假设他们都出现过一次。</p>

<p>那么修改后的表达式为：</p>

<p><img src="./_resources/nb13.jpg" alt="nb13"/></p>

<p>这个有点像NLP里面的加一平滑法，当然还有n多平滑法了，这里不再详述。</p>

<p><img src="./_resources/nb14.png" alt="nb14"/></p>

<hr/>

<h2 id="toc_4">回归算法与分类算法</h2>

<p>回归算法和分类算法很像，不过回归算法和分类算法输出标称型类别值不同的是，回归方法会预测出一个连续的值，即回归会预测出具体的数据，而分类只能预测类别。</p>

<h3 id="toc_5">线性回归(Linear Regression)</h3>

<ul>
<li>优点：结果易于理解，计算上不复杂。</li>
<li>缺点：对非线性数据拟合不好。</li>
<li>适用数据类型：数值型和标称型数据。</li>
<li>算法类型：回归算法。</li>
</ul>

<p>ps:回归于分类的不同，就在于其目标变量时连续数值型。</p>

<p>简述：在统计学中，线性回归（Linear Regression）是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合（自变量都是一次方）。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。</p>

<p>线性方程的模型函数的向量表示形式为：</p>

<p><img src="./_resources/mlg19.png" alt="mlg19"/></p>

<p>通过训练数据集寻找向量系数的最优解，即为求解模型参数。其中求解模型系数的优化器方法可以用“最小二乘法”、“梯度下降”算法，来求解损失函数的最优解：</p>

<p><img src="./_resources/mlg20.png" alt="mlg20"/></p>

<p>附加：岭回归（ridge regression）</p>

<p>岭回归是一种专用于共线性数据分析的有偏估计回归方法，实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价，获得回归系数更为符合实际、更可靠的回归方法，对病态数据的耐受性远远强于最小二乘法。</p>

<p>岭回归分析法是从根本上消除复共线性影响的统计方法。岭回归模型通过在相关矩阵中引入一个很小的岭参数K（1&gt;K&gt;0），并将它加到主对角线元素上，从而降低参数的最小二乘估计中复共线特征向量的影响，减小复共线变量系数最小二乘估计的方法，以保证参数估计更接近真实情况。岭回归分析将所有的变量引入模型中，比逐步回归分析提供更多的信息。</p>

<p>总结：与分类一样，回归也是预测目标值的过程。回归与分类的不同点在于，前者预测连续型的变量，而后者预测离散型的变量。回归是统计学中最有力的工具之一。在回归方程里，求得特征对应的最佳回归系统的方法是最小化误差的平方和。</p>

<h3 id="toc_6">Logistic 回归（拓展到一般回归）</h3>

<ul>
<li>优点：计算代价不高，易于理解和实现。</li>
<li>缺点：容易欠拟合，分类精度可能不高。</li>
<li>适用数据类型：数值型和标称型数据。</li>
<li>类别：分类算法。</li>
<li>适用场景：解决二分类问题。</li>
</ul>

<p>简述：Logistic回归算法基于Sigmoid函数，或者说Sigmoid就是逻辑回归函数。Sigmoid函数定义如下：1/（1+exp（-z))。函数值域范围(0,1)。可以用来做分类器。<br/>
Sigmoid函数的函数曲线如下：</p>

<p><img src="./_resources/mlg12.gif" alt="mlg12"/></p>

<p>逻辑回归模型分解如下：</p>

<p>(1)首先将不同维度的属性值和对应的一组权重加和，公式如下： z = w0+w1x1+w2x2+…+wm*xm。（其中x1,x2,…,xm是某样本数据的各个特征，维度为m）</p>

<p>ps：这里就是一个线性回归。W权重值就是需要经过训练学习到的数值，具体W向量的求解，就需要用到极大似然估计和将似然估计函数代入到 优化算法来求解。最常用的最后化算法有 梯度上升算法。</p>

<p>由上面可见：逻辑回归函数虽然是一个非线性的函数，但其实其去除Sigmoid映射函数之后，其他步骤都和线性回归一致。</p>

<p>(2)然后将上述的线性目标函数 z 代入到sigmond逻辑回归函数，可以得到值域为（0,0.5)和（0.5,1）两类值，等于0.5的怎么处理还以自己定。这样其实就得到了2类数据，也就体现了二分类的概念。</p>

<p>总结：Logistic回归的目的是寻找一个非线性函数Sigmoid的最佳拟合参数，参数的求解过程可以由最优化算法来完成。在最优化算法中，最常用的就是梯度上升算法，而梯度上升算法有可以简化为随机梯度上升算法。</p>

<hr/>

<h3 id="toc_7">问题引入</h3>

<p>假设有一个房屋销售的数据如下</p>

<table>
<thead>
<tr>
<th style="text-align: center">面积(m<sup>2)</sup></th>
<th style="text-align: center">价格(万元)</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">123</td>
<td style="text-align: center">250</td>
</tr>
<tr>
<td style="text-align: center">150</td>
<td style="text-align: center">320</td>
</tr>
<tr>
<td style="text-align: center">87</td>
<td style="text-align: center">160</td>
</tr>
<tr>
<td style="text-align: center">102</td>
<td style="text-align: center">220</td>
</tr>
</tbody>
</table>

<p>这个表类似于北京5环左右的房屋价钱，我们可以做出一个图，x轴是房屋的面积。y轴是房屋的售价，如下：</p>

<p><img src="./_resources/lr1.png" alt="l" class="mw_img_right" style="width:1px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>如果来了一个新的面积，假设在销售价钱的记录中没有的，我们怎么办呢？</p>

<p>我们可以用一条曲线去尽量准的拟合这些数据，然后如果有新的输入过来，我们可以在将曲线上这个点对应的值返回。如果用一条直线去拟合，可能是下面的样子：</p>

<p><img src="./_resources/lr2.png" alt="l" class="mw_img_right" style="width:2px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>绿色的点就是我们想要预测的点。</p>

<p>首先给出一些概念和常用的符号。</p>

<ul>
<li>房屋销售记录表：训练集(training set)或者训练数据(training data), 是我们流程中的输入数据，一般称为x</li>
<li>房屋销售价钱：输出数据，一般称为y</li>
<li>拟合的函数（或者称为假设或者模型）：一般写做 y = h(x)</li>
<li>训练数据的条目数(#training set),：一条训练数据是由一对输入数据和输出数据组成的输入数据的维度n (特征的个数，#features)</li>
<li>这个例子的特征是两维的，结果是一维的。然而回归方法能够解决特征多维，结果是一维多离散值或一维连续值的问题。</li>
</ul>

<h3 id="toc_8">学习过程</h3>

<p>下面是一个典型的机器学习的过程，首先给出一个输入数据，我们的算法会通过一系列的过程得到一个估计的函数，这个函数有能力对没有见过的新数据给出一个新的估计，也被称为构建一个模型。就如同上面的线性回归函数。</p>

<p><img src="./_resources/lr3.png" alt="l" class="mw_img_right" style="width:3px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<h3 id="toc_9">线性回归</h3>

<p>线性回归假设特征和结果满足线性关系。其实线性关系的表达能力非常强大，每个特征对结果的影响强弱可以由前面的参数体现，而且每个特征变量可以首先映射到一个函数，然后再参与线性计算。这样就可以表达特征与结果之间的非线性关系。</p>

<p>我们用X1，X2..Xn 去描述feature里面的分量，比如x1=房间的面积，x2=房间的朝向，等等，我们可以做出一个估计函数：</p>

<p><img src="./_resources/lr4.png" alt="l" class="mw_img_right" style="width:4px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>θ在这儿称为参数，在这的意思是调整feature中每个分量的影响力，就是到底是房屋的面积更重要还是房屋的地段更重要。为了如果我们令X0 = 1，就可以用向量的方式来表示了：</p>

<p><img src="./_resources/lr5.png" alt="l" class="mw_img_right" style="width:5px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>我们程序也需要一个机制去评估我们θ是否比较好，所以说需要对我们做出的h函数进行评估，一般这个函数称为损失函数（loss function）或者错误函数(error function)，描述h函数不好的程度，在下面，我们称这个函数为J函数</p>

<p>在这儿我们可以认为错误函数如下：</p>

<p><img src="./_resources/lr6.png" alt="l" class="mw_img_right" style="width:6px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>这个错误估计函数是去对x(i)的估计值与真实值y(i)差的平方和作为错误估计函数，前面乘上的1/2是为了在求导的时候，这个系数就不见了。</p>

<p>至于为何选择平方和作为错误估计函数，讲义后面从概率分布的角度讲解了该公式的来源。</p>

<p>如何调整θ以使得J(θ)取得最小值有很多方法，其中有最小二乘法(min square)，是一种完全是数学描述的方法，和梯度下降法。</p>

<h3 id="toc_10">梯度下降法</h3>

<p>在选定线性回归模型后，只需要确定参数θ，就可以将模型用来预测。然而θ需要在J(θ)最小的情况下才能确定。因此问题归结为求极小值问题，使用梯度下降法。梯度下降法最大的问题是求得有可能是局部极小值，这与初始点的选取有关。</p>

<p>梯度下降法是按下面的流程进行的：</p>

<ol>
<li>首先对θ赋值，这个值可以是随机的，也可以让θ是一个全零的向量。</li>
<li>改变θ的值，使得J(θ)按梯度下降的方向进行减少。</li>
</ol>

<p>梯度方向由J(θ)对θ的偏导数确定，由于求的是极小值，因此梯度方向是偏导数的反方向。结果为</p>

<p><img src="./_resources/lr7.png" alt="l" class="mw_img_right" style="width:7px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>迭代更新的方式有两种，一种是批梯度下降，也就是对全部的训练数据求得误差后再对θ进行更新，另外一种是增量梯度下降，每扫描一步都要对θ进行更新。前一种方法能够不断收敛，后一种方法结果可能不断在收敛处徘徊。</p>

<p>一般来说，梯度下降法收敛速度还是比较慢的。</p>

<p>另一种直接计算结果的方法是最小二乘法。</p>

<h3 id="toc_11">最小二乘法</h3>

<p>将训练特征表示为X矩阵，结果表示成y向量，仍然是线性回归模型，误差函数不变。那么θ可以直接由下面公式得出</p>

<p><img src="./_resources/lr8.png" alt="l" class="mw_img_right" style="width:8px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>但此方法要求X是列满秩的，而且求矩阵的逆比较慢。</p>

<h3 id="toc_12">选用误差函数为平方和的概率解释</h3>

<p><img src="./_resources/lr9.jpg" alt="l" class="mw_img_right" style="width:9px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>这样就估计了一条样本的结果概率，然而我们期待的是模型能够在全部样本上预测最准，也就是概率积最大。注意这里的概率积是概率密度函数积，连续函数的概率密度函数与离散值的概率函数不同。这个概率积成为最大似然估计。我们希望在最大似然估计得到最大值时确定θ。那么需要对最大似然估计公式求导，求导结果既是</p>

<p><img src="./_resources/lr10.png" alt="l" class="mw_img_right" style="width:10px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>这就解释了为何误差函数要使用平方和。</p>

<p>当然推导过程中也做了一些假定，但这个假定符合客观规律。</p>

<h3 id="toc_13">带权重的线性回归</h3>

<p>上面提到的线性回归的误差函数里系统都是1，没有权重。带权重的线性回归加入了权重信息。</p>

<p>基本假设是</p>

<p><img src="./_resources/lr11.jpg" alt="l" class="mw_img_right" style="width:11px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>其中x是要预测的特征，这样假设的道理是离x越近的样本权重越大，越远的影响越小。这个公式与高斯分布类似，但不一样，因为<code>w^(i)</code>不是随机变量。</p>

<p>此方法成为非参数学习算法，因为误差函数随着预测值的不同而不同，这样θ无法事先确定，预测一次需要临时计算，感觉类似KNN。</p>

<h3 id="toc_14">分类和logistic回归</h3>

<p>一般来说，回归不用在分类问题上，因为回归是连续型模型，而且受噪声影响比较大。如果非要应用进入，可以使用logistic回归。</p>

<p>logistic回归本质上是线性回归，只是在特征到结果的映射中加入了一层函数映射，即先把特征线性求和，然后使用函数g(z)将最为假设函数来预测。g(z)可以将连续值映射到0和1上。</p>

<p><img src="./_resources/lr12.jpg" alt="l" class="mw_img_right" style="width:12px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>logistic回归用来分类0/1问题，也就是预测结果属于0或者1的二值分类问题。这里假设了二值满足伯努利分布，也就是</p>

<p><img src="./_resources/lr13.png" alt="l" class="mw_img_right" style="width:13px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>当然假设它满足泊松分布、指数分布等等也可以，只是比较复杂，后面会提到线性回归的一般形式。</p>

<p>与第7节一样，仍然求的是最大似然估计，然后求导，得到迭代公式结果为</p>

<p><img src="./_resources/lr14.jpg" alt="l" class="mw_img_right" style="width:14px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<h3 id="toc_15">牛顿法来解最大似然估计</h3>

<p>前面使用的解最大似然估计的方法都是求导迭代的方法，这里介绍了牛顿下降法，使结果能够快速的收敛。</p>

<p><img src="./_resources/lr15.jpg" alt="l" class="mw_img_right" style="width:15px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>牛顿法收敛速度虽然很快，但求Hessian矩阵的逆的时候比较耗费时间。</p>

<p>当初始点X0靠近极小值X时，牛顿法的收敛速度是最快的。但是当X0远离极小值时，牛顿法可能不收敛，甚至连下降都保证不了。原因是迭代点Xk+1不一定是目标函数f在牛顿方向上的极小点。</p>

<h3 id="toc_16">一般线性模型</h3>

<p>之所以在logistic回归时使用</p>

<p><img src="./_resources/lr16.png" alt="l" class="mw_img_right" style="width:16px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>的公式是由一套理论作支持的。</p>

<p>这个理论便是一般线性模型。</p>

<p>首先，如果一个概率分布可以表示成</p>

<p><img src="./_resources/lr17.png" alt="l" class="mw_img_right" style="width:17px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>时，那么这个概率分布可以称作是指数分布。</p>

<p>伯努利分布，高斯分布，泊松分布，贝塔分布，狄特里特分布都属于指数分布。</p>

<p>在logistic回归时采用的是伯努利分布，伯努利分布的概率可以表示成</p>

<p><img src="./_resources/lr18.png" alt="l" class="mw_img_right" style="width:18px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p><img src="./_resources/lr19.jpg" alt="l" class="mw_img_right" style="width:19px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>这就解释了logistic回归时为了要用这个函数。</p>

<p>一般线性模型的要点是</p>

<p><img src="./_resources/lr20.jpg" alt="l" class="mw_img_right" style="width:20px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<h3 id="toc_17">Softmax回归</h3>

<p>最后举了一个利用一般线性模型的例子。</p>

<p>假设预测值y有k种可能，即y∈{1,2,…,k}</p>

<p>比如k=3时，可以看作是要将一封未知邮件分为垃圾邮件、个人邮件还是工作邮件这三类。</p>

<p><img src="./_resources/lr21.jpg" alt="l" class="mw_img_right" style="width:21px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>即式子左边可以有其他的概率表示，因此可以当作是k-1维的问题。</p>

<p>为了表示多项式分布表述成指数分布，我们引入T(y)，它是一组k-1维的向量，这里的T(y)不是y，T(y)i表示T(y)的第i个分量。</p>

<p><img src="./_resources/lr22.jpg" alt="l" class="mw_img_right" style="width:22px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>应用于一般线性模型，结果y必然是k中的一种。1{y=k}表示当y=k的时候，1{y=k}=1。那么p(y)可以表示为</p>

<p><img src="./_resources/lr23.png" alt="l" class="mw_img_right" style="width:23px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p><img src="./_resources/lr24.jpg" alt="l" class="mw_img_right" style="width:24px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p><img src="./_resources/lr25.jpg" alt="l" class="mw_img_right" style="width:25px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>求得期望值</p>

<p><img src="./_resources/lr26.png" alt="l" class="mw_img_right" style="width:26px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>那么就建立了假设函数，最后就获得了最大似然估计</p>

<p><img src="./_resources/lr27.png" alt="l" class="mw_img_right" style="width:27px;display: block; float: right; margin: 0px 0px 8px 8px;"/></p>

<p>对该公式可以使用梯度下降或者牛顿法迭代求解。</p>

<p>解决了多值模型建立与预测问题。</p>

<hr/>

<h2 id="toc_18">K-Means(K 均值算法)</h2>

<ul>
<li>优点：容易实现。</li>
<li>缺点：可能收敛到局部最小值，在大规模数据集上收敛较慢。</li>
<li>适用数据类型：数值型数据。</li>
<li>算法类型：聚类算法。</li>
</ul>

<p>ps:K-Means和上面的分类和回归算法不同，它属于非监督学习算法。类似分类和回归中的目标变量事先并不存在。与前面“对于数据变量X能预测变量Y”不同的是，非监督学习算法要回答的问题是：“从数据X中能发现什么？“，这里需要回答的X方面可能的问题是：”构成X的最佳6个数据簇都是哪些“或者”X中哪三个特征最频繁共现？“。</p>

<p>K-Means的基本步骤：</p>

<ol>
<li>从数据对象中随机的初始化K个初始点作为质心。然后将数据集中的每个点分配到一个簇中，具体来讲每个点找到距其最近的质心，并将其分配给该质心所对应的簇。</li>
<li>计算每个簇中样本点的均值，然后用均值更新掉该簇的质心。然后划分簇结点。</li>
<li>迭代重复（2）过程，当簇对象不再发生变化时，或者误差在评测函数预估的范围时，停止迭代。</li>
</ol>

<p>算法的时间复杂度上界为O(nkt), 其中t是迭代次数。</p>

<p>ps:初始的K个质心的选取以及距离计算公式的好坏，将影响到算法的整体性能。<br/>
附加：</p>

<p>二分K-均值算法:为克服K-均值算法收敛于局部最小值的问题，有人提出了另一个称为二分K-均值（bisecting K-Means）的算法。该算法首先将所有点作为一个簇，然后将簇一分为二。之后选择其中一个簇继续划分，选择哪个一簇进行划分取决于对其划分是否可以最大程度降低SSE(Sum of Squared Error，两个簇的总误差</p>

<hr/>

<p>K-means也是聚类算法中最简单的一种了，但是里面包含的思想却是不一般。看了Andrew Ng的这个讲义后才有些明白K-means后面包含的EM思想。</p>

<p>聚类属于无监督学习，以往的回归、朴素贝叶斯、SVM等都是有类别标签y的，也就是说样例中已经给出了样例的分类。而聚类的样本中却没有给定y，只有特征x，比如假设宇宙中的星星可以表示成三维空间中的点集(x,y,z)。聚类的目的是找到每个样本x潜在的类别y，并将同类别y的样本x放在一起。</p>

<p>在聚类问题中，给我们的训练样本是 {x(1),...,x(m)}，每个 x(i)∈ R<sup>n，没有了y。</sup></p>

<p>K-means算法是将样本聚类成k个簇（cluster），具体算法描述如下：</p>

<p><img src="./_resources/km1.jpg" alt="k" class="mw_img_center" style="width:1px;display: block; clear:both; margin: 0 auto;"/></p>

<p>K是我们事先给定的聚类数，<code>c(i)</code> 代表样例 i 与 k 个类中距离最近的那个类，<code>c(i)</code> 的值是1到k中的一个。质心<code>u_j</code> 代表我们对属于同一个类的样本中心点的猜测，拿星团模型来解释就是要将所有的星星聚成k个星团，首先随机选取k个宇宙中的点（或者k个星星）作为k个星团的质心，然后第一步对于每一个星星计算其到k个质心中每一个的距离，然后选取距离最近的那个星团作为<code>c(i)</code>，这样经过第一步每一个星星都有了所属的星团；第二步对于每一个星团，重新计算它的质心<code>u_j</code>（对里面所有的星星坐标求平均）。重复迭代第一步和第二步直到质心不变或者变化很小。</p>

<p>下图展示了对n个样本点进行K-means聚类的效果，这里k取2。</p>

<p><img src="./_resources/km2.png" alt="k" class="mw_img_center" style="width:2px;display: block; clear:both; margin: 0 auto;"/></p>

<p>K-means面对的第一个问题是如何保证收敛，前面的算法中强调结束条件就是收敛，可以证明的是K-means完全可以保证收敛性。下面我们定性的描述一下收敛性，我们定义畸变函数（distortion function）如下：</p>

<p><img src="./_resources/km3.png" alt="k" class="mw_img_center" style="width:3px;display: block; clear:both; margin: 0 auto;"/></p>

<p>J函数表示每个样本点到其质心的距离平方和。K-means是要将J调整到最小。假设当前J没有达到最小值，那么首先可以固定每个类的质心<code>u_j</code>，调整每个样例的所属的类别<code>c(i)</code>来让J函数减少，同样，固定<code>c(i)</code>，调整每个类的质心<code>u_j</code>也可以使J减小。这两个过程就是内循环中使J单调递减的过程。当J递减到最小时，<code>u</code>和<code>c</code>也同时收敛。（在理论上，可以有多组不同的<code>u</code>和<code>c</code>值能够使得J取得最小值，但这种现象实际上很少见）。</p>

<p>由于畸变函数J是非凸函数，意味着我们不能保证取得的最小值是全局最小值，也就是说k-means对质心初始位置的选取比较感冒，但一般情况下k-means达到的局部最优已经满足需求。但如果你怕陷入局部最优，那么可以选取不同的初始值跑多遍k-means，然后取其中最小的J对应的<code>u</code>和c输出。</p>

<p>下面累述一下K-means与EM的关系，首先回到初始问题，我们目的是将样本分成k个类，其实说白了就是求每个样例x的隐含类别y，然后利用隐含类别将x归类。由于我们事先不知道类别y，那么我们首先可以对每个样例假定一个y吧，但是怎么知道假定的对不对呢？怎么评价假定的好不好呢？我们使用样本的极大似然估计来度量，这里是就是x和y的联合分布P(x,y)了。如果找到的y能够使P(x,y)最大，那么我们找到的y就是样例x的最佳类别了，x顺手就聚类了。但是我们第一次指定的y不一定会让P(x,y)最大，而且P(x,y)还依赖于其他未知参数，当然在给定y的情况下，我们可以调整其他参数让P(x,y)最大。但是调整完参数后，我们发现有更好的y可以指定，那么我们重新指定y，然后再计算P(x,y)最大时的参数，反复迭代直至没有更好的y可以指定。</p>

<p>这个过程有几个难点，第一怎么假定y？是每个样例硬指派一个y还是不同的y有不同的概率，概率如何度量。第二如何估计P(x,y)，P(x,y)还可能依赖很多其他参数，如何调整里面的参数让P(x,y)最大。这些问题在以后的篇章里回答。</p>

<p>这里只是指出EM的思想，E步就是估计隐含类别y的期望值，M步调整其他参数使得在给定类别y的情况下，极大似然估计P(x,y)能够达到极大值。然后在其他参数确定的情况下，重新估计y，周而复始，直至收敛。</p>

<p>上面的阐述有点费解，对应于K-<code>x(i)</code>对应隐含变量也就是最佳类别<code>c(i)</code>。最开始可以随便指定一个<code>c(i)</code>给它，然后为了让P(x,y)最大（这里是要让J最小），我们求出在给定c情况下，J最小时的<code>u_j</code>（前面提到的其他未知参数），然而此时发现，可以有更好的<code>c(i)</code>（质心与样例<code>x(i)</code>距离最小的类别）指定给样例<code>x(i)</code>，那么<code>c(i)</code>得到重新调整，上述过程就开始重复了，直到没有更好的<code>c(i)</code>指定。这样从K-means里我们可以看出它其实就是EM的体现，E步是确定隐含类别变量<code>c</code>，M步更新其他参数<code>u</code>来使J最小化。这里的隐含类别变量指定方法比较特殊，属于硬指定，从k个类别中硬选出一个给样例，而不是对每个类别赋予不同的概率。总体思想还是一个迭代优化过程，有目标函数，也有参数变量，只是多了个隐含变量，确定其他参数估计隐含变量，再确定隐含变量估计其他参数，直至目标函数最优。</p>

<hr/>

<h2 id="toc_19">混合高斯模型(Mixtures of Gaussians)</h2>

<p>这篇讨论使用期望最大化算法（Expectation-Maximization）来进行密度估计（density estimation）。</p>

<p><img src="./_resources/mg1.jpg" alt="mg1"/></p>

<p>这个式子的最大值是不能通过前面使用的求导数为0的方法解决的，因为求的结果不是close form。但是假设我们知道了每个样例的 <code>z(i)</code>，那么上式可以简化为：</p>

<p><img src="./_resources/mg2.jpg" alt="mg2"/></p>

<p><img src="./_resources/mg3.jpg" alt="mg3"/></p>

<p><img src="./_resources/mg4.jpg" alt="mg4"/></p>

<p><img src="./_resources/mg5.jpg" alt="mg5"/></p>

<p>对比K-means可以发现，这里使用了“软”指定，为每个样例分配的类别 <code>z(i)</code> 是有一定的概率的，同时计算量也变大了，每个样例i都要计算属于每一个类别j的概率。与K-means相同的是，结果仍然是局部最优解。对其他参数取不同的初始值进行多次计算不失为一种好方法。</p>

<p>虽然之前再K-means中定性描述了EM的收敛性，仍然没有定量地给出，还有一般化EM的推导过程仍然没有给出。</p>

<h2 id="toc_20">The EM Algorithm</h2>

<h3 id="toc_21">Jenson</h3>

<p>回顾优化理论中的一些概念。设f是定义域为实数的函数，如果对于所有的实数x，f&#39;&#39;(x) &gt;= 0，那么f是凸函数。当x是向量时，如果其hessian矩阵H是半正定的（H &gt;= 0），那么f是凸函数。如果 f&#39;&#39;(x) &gt; 0或者 H &gt; 0，那么称f是严格凸函数。</p>

<p>Jensen不等式表述如下：</p>

<p>如果f是凸函数，X是随机变量，那么</p>

<p>E[f(X)] &gt;= f(E[X])</p>

<p>特别地，如果f是严格凸函数，那么 E[f(X)] = f(E[X]) 当且仅当 p(x=E[X]) = 1，也就是说X是常量。</p>

<p>这里我们将 f(E[X])  简写为 f(EX)。</p>

<p>如果用图表示会很清晰：</p>

<p><img src="./_resources/em1.png" alt="e" class="mw_img_center" style="width:1px;display: block; clear:both; margin: 0 auto;"/></p>

<p>图中，实线f是凸函数，X是随机变量，有0.5的概率是a，有0.5的概率是b。（就像掷硬币一样）。X的期望值就是a和b的中值了，图中可以看到 E[f(X)] &gt;= f(E[X]) 成立。</p>

<p>当f是（严格）凹函数当且仅当-f是（严格）凸函数。</p>

<p>Jensen不等式应用于凹函数时，不等号方向反向，也就是E[f(X)] &lt;= f(E[X])。</p>

<h3 id="toc_22">EM 算法</h3>

<p>给定的训练样本是{x(1),...,x(m)}，样例间独立，我们想找到每个样例隐含的类别z，能使得p(x,z)最大。p(x,z)的最大似然估计如下：</p>

<p><img src="./_resources/em2.png" alt="e" class="mw_img_center" style="width:2px;display: block; clear:both; margin: 0 auto;"/></p>

<p>第一步是对极大似然取对数，第二步是对每个样例的每个可能类别z求联合分布概率和。但是直接求 theta 一般比较困难，因为有隐藏变量 z 存在，但是一般确定了 z 后，求解就容易了。</p>

<p><img src="./_resources/em3.jpg" alt="e" class="mw_img_center" style="width:3px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em4.png" alt="e" class="mw_img_center" style="width:4px;display: block; clear:both; margin: 0 auto;"/></p>

<p>（1）到（2）比较直接，就是分子分母同乘以一个相等的函数。（2）到（3）利用了Jensen不等式，考虑到 log(x) 是凹函数（二阶导数小于0），而且</p>

<p><img src="./_resources/em5.jpg" alt="e" class="mw_img_center" style="width:5px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em6.jpg" alt="e" class="mw_img_center" style="width:6px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em61.jpg" alt="e" class="mw_img_center" style="width:8px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em7.jpg" alt="e" class="mw_img_center" style="width:7px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em8.jpg" alt="e" class="mw_img_center" style="width:8px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em9.jpg" alt="e" class="mw_img_center" style="width:9px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em10.jpg" alt="e" class="mw_img_center" style="width:10px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em11.jpg" alt="e" class="mw_img_center" style="width:11px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em12.jpg" alt="e" class="mw_img_center" style="width:12px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em13.jpg" alt="e" class="mw_img_center" style="width:13px;display: block; clear:both; margin: 0 auto;"/></p>

<h3 id="toc_23">重新审视混合高斯模型</h3>

<p><img src="./_resources/em14.jpg" alt="e" class="mw_img_center" style="width:14px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em15.jpg" alt="e" class="mw_img_center" style="width:15px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em16.jpg" alt="e" class="mw_img_center" style="width:16px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em17.jpg" alt="e" class="mw_img_center" style="width:17px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em18.jpg" alt="e" class="mw_img_center" style="width:18px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em19.jpg" alt="e" class="mw_img_center" style="width:19px;display: block; clear:both; margin: 0 auto;"/></p>

<p><img src="./_resources/em20.jpg" alt="e" class="mw_img_center" style="width:20px;display: block; clear:both; margin: 0 auto;"/></p>

<h3 id="toc_24">总结</h3>

<p>如果将样本看作观察值，潜在类别看作是隐藏变量，那么聚类问题也就是参数估计问题，只不过聚类问题中参数分为隐含类别变量和其他参数，这犹如在x-y坐标系中找一个曲线的极值，然而曲线函数不能直接求导，因此什么梯度下降方法就不适用了。但固定一个变量后，另外一个可以通过求导得到，因此可以使用坐标上升法，一次固定一个变量，对另外的求极值，最后逐步逼近极值。对应到EM上，E步估计隐含变量，M步估计其他参数，交替将极值推向最大。EM中还有“硬”指定和“软”指定的概念，“软”指定看似更为合理，但计算量要大，“硬”指定在某些场合如K-means中更为实用（要是保持一个样本点到其他所有中心的概率，就会很麻烦）。</p>

<p>另外，EM的收敛性证明方法确实很牛，能够利用log的凹函数性质，还能够想到利用创造下界，拉平函数下界，优化下界的方法来逐步逼近极大值。而且每一步迭代都能保证是单调的。最重要的是证明的数学公式非常精妙，硬是分子分母都乘以z的概率变成期望来套上Jensen不等式，前人都是怎么想到的。</p>

<p>在Mitchell的Machine Learning书中也举了一个EM应用的例子，明白地说就是将班上学生的身高都放在一起，要求聚成两个类。这些身高可以看作是男生身高的高斯分布和女生身高的高斯分布组成。因此变成了如何估计每个样例是男生还是女生，然后在确定男女生情况下，如何估计均值和方差，里面也给出了公式，有兴趣可以参考。</p>

<hr/>

<h2 id="toc_25">PCA 主成分分析</h2>

<ul>
<li>优点：降低数据的复杂性，识别最重要的多个特征。</li>
<li>缺点：不一定需要，且可能损失有用信息。</li>
<li>适用适用类型：数值型数据。</li>
<li>技术类型：降维技术。</li>
</ul>

<p>按照一定的数学变换方法，把给定的一组相关变量（维度）通过线性变换转成另一组不相关的变量，这些新的变量按照方差依次递减的顺序排列。在数学变换中保持变量的<code>总方差</code>不变，使<code>第一变量</code>具有<code>最大的方差</code>，称为<code>第一主成分</code>，<code>第二变量</code>的<code>方差次大</code>，并且和第一变量不相关，称为第二主成分。依次类推，I个变量就有I个主成分。</p>

<p><strong>通过低维表征的向量和特征向量矩阵，可以基本重构出所对应的原始高维向量</strong></p>

<hr/>

<p>真实的训练数据总是存在各种各样的问题：</p>

<ol>
<li>比如拿到一个汽车的样本，里面既有以“千米/每小时”度量的最大速度特征，也有“英里/小时”的最大速度特征，显然这两个特征有一个多余。</li>
<li>拿到一个数学系的本科生期末考试成绩单，里面有三列，一列是对数学的兴趣程度，一列是复习时间，还有一列是考试成绩。我们知道要学好数学，需要有浓厚的兴趣，所以第二项与第一项强相关，第三项和第二项也是强相关。那是不是可以合并第一项和第二项呢？</li>
<li>拿到一个样本，特征非常多，而样例特别少，这样用回归去直接拟合非常困难，容易过度拟合。比如北京的房价：假设房子的特征是（大小、位置、朝向、是否学区房、建造年代、是否二手、层数、所在层数），搞了这么多特征，结果只有不到十个房子的样例。要拟合房子特征-&gt;房价的这么多特征，就会造成过度拟合。</li>
<li>这个与第二个有点类似，假设在IR中我们建立的文档-词项矩阵中，有两个词项为“learn”和“study”，在传统的向量空间模型中，认为两者独立。然而从语义的角度来讲，两者是相似的，而且两者出现频率也类似，是不是可以合成为一个特征呢？</li>
<li>在信号传输过程中，由于信道不是理想的，信道另一端收到的信号会有噪音扰动，那么怎么滤去这些噪音呢？</li>
</ol>

<p>回顾我们之前介绍的《模型选择和规则化》，里面谈到的特征选择的问题。但在那篇中要剔除的特征主要是和类标签无关的特征。比如“学生的名字”就和他的“成绩”无关，使用的是互信息的方法。</p>

<p>而这里的特征很多是和类标签有关的，但里面存在噪声或者冗余。在这种情况下，需要一种特征降维的方法来减少特征数，减少噪音和冗余，减少过度拟合的可能性。</p>

<p>下面探讨一种称作主成分分析（PCA）的方法来解决部分上述问题。PCA的思想是将n维特征映射到k维上（<code>k&lt;n</code>），这k维是全新的正交特征。这k维特征称为主元，是重新构造出来的k维特征，而不是简单地从n维特征中去除其余<code>n-k</code>维特征。</p>

<h3 id="toc_26">PCA 计算过程</h3>

<p>首先介绍PCA的计算过程：</p>

<p>假设我们得到的2维数据如下：</p>

<p><img src="./_resources/pca1.png" alt="pca1"/></p>

<p>行代表了样例，列代表特征，这里有10个样例，每个样例两个特征。可以这样认为，有10篇文档，x是10篇文档中“learn”出现的TF-IDF，y是10篇文档中“study”出现的TF-IDF。也可以认为有10辆汽车，x是千米/小时的速度，y是英里/小时的速度，等等。</p>

<p>第一步分别求x和y的平均值，然后对于所有的样例，都减去对应的均值。这里x的均值是1.81，y的均值是1.91，那么一个样例减去均值后即为（0.69,0.49），得到</p>

<p><img src="./_resources/pca2.png" alt="pca2"/></p>

<p>第二步，求特征协方差矩阵，如果数据是3维，那么协方差矩阵是</p>

<p><img src="./_resources/pca3.png" alt="pca3"/></p>

<p>这里只有x和y，求解得</p>

<p><img src="./_resources/pca4.png" alt="pca4"/></p>

<p>对角线上分别是x和y的方差，非对角线上是协方差。协方差大于0表示x和y若有一个增，另一个也增；小于0表示一个增，一个减；协方差为0时，两者独立。协方差绝对值越大，两者对彼此的影响越大，反之越小。</p>

<p>第三步，求协方差的特征值和特征向量，得到</p>

<p><img src="./_resources/pca5.png" alt="pca5"/></p>

<p>上面是两个特征值，下面是对应的特征向量，特征值 0.0490833989 对应特征向量为 (-0.735178656, 0.677873399)<sup>T，这里的特征向量都归一化为单位向量。</sup></p>

<p>第四步，将特征值按照从大到小的顺序排序，选择其中最大的k个，然后将其对应的k个特征向量分别作为列向量组成特征向量矩阵。</p>

<p>这里特征值只有两个，我们选择其中最大的那个，这里是1.28402771，对应的特征向量是 (-0.677873399, -0.735178656)<sup>T</sup></p>

<p>第五步，将样本点投影到选取的特征向量上。假设样例数为 m，特征数为 n，减去均值后的样本矩阵为 <code>DataAdjust(m*n)</code>，协方差矩阵是 <code>n*n</code>，选取的 k 个特征向量组成的矩阵为 <code>EigenVectors(n*k)</code>。那么投影后的数据 FinalData 为</p>

<pre><code>FinalData(m * k) = DataAdjust(m * n) x EigenVectors(n * k)
</code></pre>

<p>这里是</p>

<pre><code>FinalData(10*1) = DataAdjust(10*2矩阵)× 特征向量(-0.677873399, -0.735178656)^T
</code></pre>

<p>得到结果是</p>

<p><img src="./_resources/pca6.png" alt="pca6"/></p>

<p>这样，就将原始样例的n维特征变成了k维，这k维就是原始特征在k维上的投影。</p>

<p>上面的数据可以认为是learn和study特征融合为一个新的特征叫做LS特征，该特征基本上代表了这两个特征。</p>

<p>上述过程有个图描述：</p>

<p><img src="./_resources/pca7.png" alt="pca7"/></p>

<p>正号表示预处理后的样本点，斜着的两条线就分别是正交的特征向量（由于协方差矩阵是对称的，因此其特征向量正交），最后一步的矩阵乘法就是将原始样本点分别往特征向量对应的轴上做投影。</p>

<p>如果取的k=2，那么结果是</p>

<p><img src="./_resources/pca8.png" alt="pca8"/></p>

<p>这就是经过PCA处理后的样本数据，水平轴（上面举例为LS特征）基本上可以代表全部样本点。整个过程看起来就像将坐标系做了旋转，当然二维可以图形化表示，高维就不行了。上面的如果k=1，那么只会留下这里的水平轴，轴上是所有点在该轴的投影。</p>

<p>这样PCA的过程基本结束。在第一步减均值之后，其实应该还有一步对特征做方差归一化。比如一个特征是汽车速度（0到100），一个是汽车的座位数（2到6），显然第二个的方差比第一个小。因此，如果样本特征中存在这种情况，那么在第一步之后，求每个特征的标准差 sigma，然后对每个样例在该特征下的数据除以 sigma。</p>

<p>归纳一下，使用我们之前熟悉的表示方法，在求协方差之前的步骤是：</p>

<p><img src="./_resources/pca9.png" alt="pca9"/></p>

<p>其中<code>x^(i)</code>是样例，共 m 个，每个样例 n 个特征，也就是说<code>x^(i)</code>是 n 维向量。<code>x_j^(i)</code>是第i个样例的第j个特征。<code>mu</code>是样例均值。<code>sigma_j</code> 是第 j 个特征的标准差。</p>

<p>整个PCA过程貌似极其简单，就是求协方差的特征值和特征向量，然后做数据转换。但是有没有觉得很神奇，为什么求协方差的特征向量就是最理想的k维向量？其背后隐藏的意义是什么？整个PCA的意义是什么？</p>

<h3 id="toc_27">PCA 理论基础</h3>

<p>要解释为什么协方差矩阵的特征向量就是k维理想特征，我看到的有三个理论：分别是最大方差理论、最小错误理论和坐标轴相关度理论。这里简单探讨前两种，最后一种在讨论PCA意义时简单概述。</p>

<h4 id="toc_28">最大方差理论</h4>

<p>在信号处理中认为信号具有较大的方差，噪声有较小的方差，信噪比就是信号与噪声的方差比，越大越好。如前面的图，样本在横轴上的投影方差较大，在纵轴上的投影方差较小，那么认为纵轴上的投影是由噪声引起的。</p>

<p>因此我们认为，最好的k维特征是将n维样本点转换为k维后，每一维上的样本方差都很大。</p>

<p>比如下图有5个样本点：（已经做过预处理，均值为0，特征方差归一）</p>

<p><img src="./_resources/pca10.png" alt="pca10"/></p>

<p>下面将样本投影到某一维上，这里用一条过原点的直线表示（前处理的过程实质是将原点移到样本点的中心点）。</p>

<p><img src="./_resources/pca11.jpg" alt="pca11"/></p>

<p>假设我们选择两条不同的直线做投影，那么左右两条中哪个好呢？根据我们之前的方差最大化理论，左边的好，因为投影后的样本点之间方差最大。</p>

<p>这里先解释一下投影的概念：</p>

<p><img src="./_resources/pca12.png" alt="pca12"/></p>

<p>两个向量的点积（内积），等于一个向量在另一个向量上的投影长度，等于两个向量对应坐标分量之积的代数和。</p>

<p>从内积数值上我们可以看出两个向量的在方向上的接近程度。当内积值为正值时，两个向量大致指向相同的方向（方向夹角小于90度）；当内积值为负值时，两个向量大致指向相反的方向（方向角大于90度）；当内积值为0时，两个向量互相垂直</p>

<p>红色点表示样例 <code>x^(i)</code>，蓝色点表示 <code>x^(i)</code>在 u 上的投影，u 是直线的斜率也是直线的方向向量，而且是单位向量。蓝色点是 <code>x^(i)</code> 在 u 上的投影点，离原点的距离是 <code>&lt; x^(i), u &gt;</code>（即 <code>(x^(i))^T u</code> 或者 <code>u^T x^(i)</code>）由于这些样本点（样例）的每一维特征均值都为 0，因此投影到 u 上的样本点（只有一个到原点的距离值）的均值仍然是0。</p>

<p>回到上面左右图中的左图，我们要求的是最佳的u，使得投影后的样本点方差最大。</p>

<p>由于投影后均值为0，因此方差为：</p>

<p><img src="./_resources/pca13.png" alt="pca13"/></p>

<p>中间那部分很熟悉啊，不就是样本特征的协方差矩阵么（<code>x^(i)</code>的均值为0，一般协方差矩阵都除以m-1，这里用m）。</p>

<p><img src="./_resources/pca14.jpg" alt="pca14"/></p>

<p>因此，我们只需要对协方差矩阵进行特征值分解，得到的前k大特征值对应的特征向量就是最佳的k维新特征，而且这k维新特征是正交的。得到前k个u以后，样例 <code>x^(i)</code> 通过以下变换可以得到新的样本。</p>

<p><img src="./_resources/pca15.png" alt="pca15"/></p>

<p>其中的第j维就是<code>x^(i)</code>在<code>u_j</code>上的投影。</p>

<p>通过选取最大的k个u，使得方差较小的特征（如噪声）被丢弃。</p>

<p>这是其中一种对PCA的解释，第二种是<a href="http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020216.html">错误最小化</a>。</p>

<h3 id="toc_29">总结与讨论</h3>

<p>PCA技术的一大好处是对数据进行降维的处理。我们可以对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息。</p>

<p>PCA技术的一个很大的优点是，它是完全无参数限制的。在PCA的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的。</p>

<p>但是，这一点同时也可以看作是缺点。如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高。</p>

<hr/>

<h2 id="toc_30">10折交叉验证</h2>

<p>英文名是10-fold cross-validation，用来测试算法的准确性。是常用的测试方法。将数据集分成10份。轮流将其中的9份作为训练数据，1分作为测试数据，进行试验。每次试验都会得出相应的正确率（或差错率）。10次的结果的正确率（或差错率）的平均值作为对算法精度的估计，一般还需要进行多次10折交叉验证，在求其平均值，对算法的准确性进行估计。</p>

<h2 id="toc_31">极大似然估计</h2>

<p>极大似然估计，只是一种概率论在统计学中的应用，它是参数评估的方法之一。说的 已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，参数估计通过若干次实验，观察其结果，利用结果推出参数的大概值。极大似然估计是建立在这样的思想上的：已知某个参数能使这个样本出现的概率最大。我们当然不会再去选择其他其他小概率的样本，所以干脆就把这个参数作为估计的真实值。</p>

<h2 id="toc_32">熵</h2>

<p>在信息论中，熵表示的是不确定性的量度。信息论的创始人香农在其著作《通信的数学理论》中提出了建立在概率统计模型上的信息度量。他把信息定义为”用来消除不确定性的东西“。熵的定义为信息的期望值。</p>

<p>ps:熵指的是体系的混乱程度，它在控制论，概率论，数论，天体物理，生命科学等领域都有重要的应用，在不同的学科中也有引申出更为具体的定义，是各个领域十分重要的参量。熵由鲁道夫.克劳修斯提出，并应用在热力学中。后来在，克劳德.埃尔伍德.香农 第一次将熵的概念引入到信息论中来。</p>

<h2 id="toc_33">后验概率</h2>

<p>后验概率是信息论的基本概念之一。在一个通信系统中，在收到某个消息之后，接收端所了解到的该消息发送的概率称为后验证概率。后验概率是指在得到”结果“的信息后重新修正的概率，如贝叶斯公式中的。是执果寻因的问题。后验概率和先验概率有着不可分割的联系，后验的计算要以先验概率为基础，其实说白了后验概率其实就是条件概率。</p>

<h2 id="toc_34">集成方法</h2>

<p>将不同的分类器组合起来，而这种组合结果则被称为集成方法（ensemble method）或者元算法（meta-algorithm）。</p>

<h2 id="toc_35">SVD(singular value decomposition) 奇异值分解</h2>

<ul>
<li>优点：简化数据，去除噪声，提高算法的结果。</li>
<li>缺点：数据转换可能难以理解。</li>
<li>适用数据类型：数值型数据。</li>
<li>SVD是矩阵分解的一种类型。</li>
</ul>

<p>总结：SVD是一种强大的降维工具，我们可以利用SVD来逼近矩阵并从中提取重要特征。通过保留矩阵80%~90%的能量，就可以得到重要的特征并去掉噪声。SVD已经运用到多个应用中，其中一个成功的应用案例就是推荐引擎。推荐引擎将物品推荐给用户，协同过滤则是一种基于用户喜好和行为数据的推荐和实现方法。协同过滤的核心是相似度计算方法，有很多相似度计算方法都可以用于计算物品或用户之间的相似度。通过在低维空间下计算相似度，SVD提高了推荐引擎的效果。</p>

<h2 id="toc_36">SVM(Support Vector Machines) 支持向量机：</h2>

<ul>
<li>优点：泛化错误率低，计算开销不大，结果易解释。</li>
<li>缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二分类问题。</li>
<li>适用数据类型：数值型和标称型数据。</li>
<li>类别：分类算法。</li>
<li>适用场景：解决二分类问题。</li>
</ul>

<p>简述：通俗的讲，SVM是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，即支持向量机的学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。或者简单的可以理解为就是在高维空间中寻找一个合理的超平面将数据点分隔开来，其中涉及到非线性数据到高维的映射以达到数据线性可分的目的。</p>

<p>支持向量概念：</p>

<p><img src="./_resources/mlg13.png" alt="mlg13"/></p>

<p>上面样本图是一个特殊的二维情况，真实情况当然可能是很多维。先从低纬度简单理解一下什么是支持向量。从图中可以看到3条线，中间那条红色的线到其他两条线的距离相等。这条红色的就是SVM在二维情况下要寻找的超平面，用于二分类数据。而支撑另外两条线上的点就是所谓的支持向量。从图中可以看到，中间的超平面和另外两条线中间是没有样本的。找到这个超平面后，利用超平面的数据数学表示来对样本数据进行二分类，就是SVM的机制了。</p>

<p>ps：《机器学习实战》书中有这么几个概念：</p>

<ol>
<li>如果能找到一个直线（或多维的面）将样本点分开，那么这组数据就是线性可分的。将上述数据集分隔开来的直线(或多维的面)称为分隔超平面。分布在超平面一侧的数据属于一个类别，分布在超平面另一侧的数据属于另一个类别</li>
<li>支持向量（Support vector）就是分离超平面最近的那些点。</li>
<li>几乎所有分类问题都可以使用SVM，值得一提的是，SVM本身是一个二分类分类器，对多类问题应用SVM需要对代码做一些修改。</li>
</ol>

<p>公式：SVM有很多实现，但是本章值关注其中最流行的一种实现，及序列最小优化（Sequential Minimal Optimization，SMO）算法。其公式如下：</p>

<p><img src="./_resources/mlg14.png" alt="mlg14"/></p>

<p>SMO算法的目标是求出一些列的alpha，一旦求出了alpha，就很容易计算出权重向量w并得到分隔超平面。</p>

<p>SMO算法的工作原理是：每次循环中选择两个alpha进行优化处理。一旦找到一对合适的alpha，那么就增大其中一个同时减小另一个。这里所谓的“合适”就是指两个alpha必须符合一定的条件，条件之一就是这两个alpha必须要在间隔边界之外，而其第二个条件则是这两个alpha还没有进行过区间化处理或者不在边界上。</p>

<p>核函数将数据从低维度映射到高维：SVM是通过寻找超平面将数据进行分类的，但是当数据不是线性可分的时候就需要利用核函数将数据从低维映射到高维使其线性可分后，在应用SVM理论。</p>

<p><img src="./_resources/mlg15.png" alt="mlg15"/></p>

<p>这个二维数据分布不是线性可分的，其方程为：</p>

<p><img src="./_resources/mlg16.jpg" alt="mlg16"/></p>

<p>但是通过核函数维度映射后，其变为：</p>

<p><img src="./_resources/mlg17.gif" alt="mlg17"/></p>

<p>对应的方程为：</p>

<p><img src="./_resources/mlg18.jpg" alt="mlg18"/></p>

<p>这样映射后的数据就变成了线性可分的，就可以应用SVM理论了。</p>

<p>总结：支持向量机是一种分类器。之所以成为“机”是因为他会产生一个二值决策结果，即它是一种‘决策’机。核方法或者说核技巧会将数据（有时是非线性数据）从一个低维空间映射到一个高维空间，可以将一个在低维空间中的非线性问题转换为高维空间下的线性问题来求解。</p>

<h2 id="toc_37">决策树</h2>

<ul>
<li>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。</li>
<li>缺点：可能会产生匹配过度问题。</li>
<li>适用数据类型：数值型和标称型。</li>
<li>算法类型：分类算法。</li>
<li>数据要求：树的构造只适用于标称型的数据，因此数值型数据必须离散化。</li>
</ul>

<p>简述：在构造决策树时，我们需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时起决定性作用。为了找到决定性特征，划分出最好的结果，我们必须评估每个特征。完成测试后，原始数据就被划分为几个数据子集。这些数据的子集分布在第一个决策点的所有分支上，如果某个分支下的数据属于同一个类型，则无需进一步对数据集进行切割。反之则需要进一步切割。</p>

<p>创建分支的伪代码如下：</p>

<pre><code>检测数据集中的每个子项是否属于同一分类：
   if so return 类标签；
   else
       寻找数据集的最好特征
       划分数据集
       创建分支结点
           for 每个划分的子集
               调用函数createBranch并增加返回结果到分支结点中
           return 分支结点
</code></pre>

<p>在可以评测哪种数据划分方式是最好的数据划分之前，我们必须学习如何计算信息增益。集合的信息度量方式称为香农熵或者简称为熵。熵在信息论中定义为信息的期望值。</p>

<p>信息熵的计算公式为：</p>

<p>H(信息熵) = -∑ P（xi） log2P（xi） ps:其中p（xi）表示选择该分类的概率。</p>

<p>下面简述一下生成决策树的步骤：</p>

<ol>
<li>根据给定的训练数据，根据熵最大原则根据每一个维度来划分数据集，找到最关键的维度。</li>
<li>当某个分支下所有的数据都数据同一分类则终止划分并返回类标签，否则在此分支上重复实施(1)过程。</li>
<li>依次计算就将类标签构建成了一棵抉择树。</li>
<li>依靠训练数据构造了决策树之后，我们就可以将它用于实际数据的分类。</li>
</ol>

<p>ps:当然生成决策树的算法不止这一个，还有其他一些生成决策树的方法，比如：C4.5和CART。</p>

<p>总结：决策树分类器就像带有终止块的流程图，终止块表示分类结果。开始处理数据集时，我们首先需要测量集合中数据的不一致性，也就是熵，然后寻找最优的方案划分数据集，直到数据集中的所有数据属于同一个分类。</p>

<h2 id="toc_38">K-近邻算法（KNN）</h2>

<ul>
<li>优点：精度高、对异常值不敏感、无数据输入假定。</li>
<li>缺点：计算复杂度高，空间复杂度搞。</li>
<li>适用数据范围：数值型和标称型。</li>
<li>算法类型：分类算法。</li>
</ul>

<p>简述：算法原理，存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征和样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后选择k个最相似数据中出现次数最多的分类，作为新数#据的分类。</p>

<h2 id="toc_39">树回归</h2>

<ul>
<li>优点：可以对复杂和非线性的数据建模。</li>
<li>缺点：结果不易理解。</li>
<li>适用数据类型：数值型和标称型数据。</li>
<li>算法类型：回归算法。</li>
</ul>

<p>简述：线性回归方法可以有效的拟合所有样本点(局部加权线性回归除外）。当数据拥有众多特征并且特征之间关系十分复杂时，构建全局模型的回归算法是比较困难的。此外，实际中很多问题为非线性的，例如常见的分段函数，不可能用全局线性模型类进行拟合。树回归将数据集切分成多份易建模的数据，然后利用线性回归进行建模和拟合。较为经典的树回归算法为CART（classification and regreesion trees 分类回归树）。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007634.html">
                
                  <h1>数学：确定性的丧失</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<!-- MarkdownTOC -->

<ul>
<li>第一章-数学真理的起源</li>
<li>第二章-数学真理的繁荣</li>
<li>第三章-科学的数学化</li>
</ul>

<!-- /MarkdownTOC -->

<ul>
<li>战争、饥荒和瘟疫能引起悲剧，然而，人类思想的局限性也能引起智力悲剧。</li>
<li>数学的当前困境是有许多种数学而不是只有一种。而且由于种种原因每一种都无法使对立学派满意。</li>
<li>用歌德的话说：一门科学的历史就是这门科学本身</li>
<li>从数学及科学的角度的历史书</li>
</ul>

<h2 id="toc_0">第一章-数学真理的起源</h2>

<ul>
<li>任何值得一提的文明都探索过真理。</li>
<li>希腊的智者们对自然采取了一种全新的态度。这种态度是理性的、批判的和反宗教的。</li>
<li>希腊人不仅是探索混杂现象的秩序和规则的勇敢的先驱，而且也是以才智发掘出自然现象显而易见所遵循的基本模式的先驱。</li>
<li>毕达哥拉斯学派的自然哲学很难与实际相吻合。美学考虑和对数学关系的穷追不舍相混合，当然会导致超越实际观察的论断。毕达哥拉斯学派也未使物理科学的任一分支向前发展，可以公正地称其理论为肤浅的。但或是凭运气或是凭天生的直觉，毕达哥拉斯学派的确言中了后来两条证明是极为重要的信条：第一是自然界是按数学原理构成的；第二是数学关系决定、统一并显示了自然的秩序。实际上现代科学也坚持毕达哥拉斯学派对数学的强调，虽然，正如我们将看到的，现代理论是毕达哥拉斯学派理论的更为高级的形式。</li>
<li>柏拉图坚持认为只有从理想世界的数学知识来理解现实世界的实在性和可知性，无疑这个世界是数学化的。</li>
<li>柏拉图比毕达哥拉斯学派前进了一步，他不仅希望用数学来理解自然界，而且要用数学来取代自然界本身。他相信，对物质世界仅用少量决定性的几步推理，即能得到基本的真理。按此观点将只有数学存在，数学将取代物理研究。</li>
<li>亚里士多德虽然是柏拉图的学生并从老师那儿继承了许多思想，对于现实世界以及数学和现实之间的关系的探究却有着不同的看法。他批评柏拉图的冥世思想以及把科学归结为数学的认识。亚里士多德是个物理学家，他相信物质的东西是实在的主体的源泉。物理学乃至一般的科学必须研究现实世界并从中获取真理。真正的知识是从感性的经验通过直观和抽象而获得的，这种抽象不能独立于人的思维而存在。</li>
<li>为了推导出数学概念，希腊人从自明的、无人怀疑的公理入手。</li>
<li>从公理出发，可用推理得出结论。有多种推理方法，比如，归纳、类比和演绎，其中只有一种能够证明结论的正确性——三段论式演绎推理。</li>
<li>从探求真理的观点来看，值得提及的是托勒密和欧多克斯一样，充分认识到他的理论只是符合观测结果的方便的数学化描述，而不一定是自然的真正设计。对于某些行星，她有集中可供选择的方案，他选择了数学上较简单的那个。</li>
</ul>

<h2 id="toc_1">第二章-数学真理的繁荣</h2>

<ul>
<li>对外部世界进行研究的主要目的在于发现上帝赋予它的合理次序与和谐，而这些是上帝以数学语言透露给我们的——开普勒</li>
<li>希腊人的宗旨——自然是依数学设计的，与文艺复兴时的信念——上帝是这个设计的作者，融会在一起，统治了欧洲，关于这一点最令人信服的证据就是哥白尼和开普勒的工作。</li>
<li>开普勒的科学推理令人叹为观止，像哥白尼一样，开普勒也是个神秘工作者，他相信上帝在设计世界时，遵循了某个简单、优美得数学方案。他丰富的想象产生了新理论体系的概念，但开普勒明白理论必须与观察结果相一致，到了晚年他更清楚地意识到正式从经验资料提出了科学的基本原则，开普勒因此甘心放弃他最心爱的数学假设。开普勒拥有谦逊、坚忍和毅力等诸多品性，正是这些品性帮助伟人们去去成就他们的非凡事业。</li>
<li>笛卡尔力图解释为什么世界可用数学来解释。他坚持认为物质最基本最可靠的性质就是形状、延展性和在时空中的运动，而这些都是可用数学描述的。由于形状可归结为延展，笛卡尔宣称：“如果给我延展和运动，我就能构造宇宙”。（和翘起地球一样一样的口气）</li>
<li>笛卡尔对数学本身并没有提出什么新定理，但他却提供了一种非常有效的研究方法，即我们现在所称得解析几何，从技术的观点来看，解析几何彻底改变了数学研究方法。</li>
<li>由于伽利略对他的时代的重大创新，他的哲学和科学方法论成为牛顿伟绩的开端，后者出生在伽利略逝世的那年。</li>
</ul>

<h2 id="toc_2">第三章-科学的数学化</h2>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007499.html">
                
                  <h1>机器学习和计算机视觉相关的数学</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<!-- MarkdownTOC -->

<ul>
<li>线性代数 (Linear Algebra)：</li>
<li>概率和统计 (Probability and Statistics)</li>
<li>分析 (Analysis)</li>
<li>拓扑 (Topology)</li>
<li>流形理论 (Manifold theory)</li>
</ul>

<!-- /MarkdownTOC -->

<h2 id="toc_0">线性代数 (Linear Algebra)：</h2>

<p>我想国内的大学生都会学过这门课程，但是，未必每一位老师都能贯彻它的精要。这门学科对于Learning是必备的基础，对它的透彻掌握是必不可少的。我在科大一年级的时候就学习了这门课，后来到了香港后，又重新把线性代数读了一遍，所读的是</p>

<p><strong>Introduction to Linear Algebra (3rd Ed.)  by Gilbert Strang</strong></p>

<p>这本书是MIT的线性代数课使用的教材，也是被很多其它大学选用的经典教材。它的难度适中，讲解清晰，重要的是对许多核心的概念讨论得比较透彻。我个人觉得，学习线性代数，最重要的不是去熟练矩阵运算和解方程的方法——这些在实际工作中MATLAB可以代劳，关键的是要深入理解几个基础而又重要的概念：子空间(Subspace)，正交(Orthogonality)，特征值和特征向量(Eigenvalues and eigenvectors)，和线性变换(Linear transform)。从我的角度看来，一本线代教科书的质量，就在于它能否给这些根本概念以足够的重视，能否把它们的联系讲清楚。Strang的这本书在这方面是做得很好的。</p>

<p>而且，这本书有个得天独厚的优势。书的作者长期在MIT讲授线性代数课(18.06)，<a href="http://ocw.mit.edu/OcwWeb/Mathematics/18-06Spring-2005/CourseHome/index.htm">课程的video</a>在MIT的Open courseware网站上有提供。有时间的朋友可以一边看着名师授课的录像，一边对照课本学习或者复习。</p>

<h2 id="toc_1">概率和统计 (Probability and Statistics)</h2>

<p>概率论和统计的入门教科书很多，我目前也没有特别的推荐。我在这里想介绍的是一本关于多元统计的基础教科书：</p>

<p><strong>Applied Multivariate Statistical Analysis_(5th Ed.)  by Richard A. Johnson and Dean W. Wichern</strong></p>

<p>这本书是我在刚接触向量统计的时候用于学习的，我在香港时做研究的基础就是从此打下了。实验室的一些同学也借用这本书学习向量统计。这本书没有特别追求数学上的深度，而是以通俗易懂的方式讲述主要的基本概念，读起来很舒服，内容也很实用。对于Linear regression, factor analysis, principal component analysis (PCA), and canonical component analysis (CCA)这些Learning中的基本方法也展开了初步的论述。</p>

<p>之后就可以进一步深入学习贝叶斯统计和Graphical models。一本理想的书是</p>

<p><strong>Introduction to Graphical Models (draft version).  by M. Jordan and C.Bishop.</strong></p>

<p>我不知道这本书是不是已经出版了（不要和Learning in Graphical Models混淆，那是个论文集，不适合初学）。这本书从基本的贝叶斯统计模型出发一直深入到复杂的统计网络的估计和推断，深入浅出，statistical learning的许多重要方面都在此书有清楚论述和详细讲解。MIT内部可以access，至于外面，好像也是有电子版的。</p>

<h2 id="toc_2">分析 (Analysis)</h2>

<p>我想大家基本都在大学就学过微积分或者数学分析，深度和广度则随各个学校而异了。这个领域是很多学科的基础，值得推荐的教科书莫过于</p>

<p><strong>Principles of Mathematical Analysis, by Walter Rudin</strong></p>

<p>有点老，但是绝对经典，深入透彻。缺点就是比较艰深——这是Rudin的书的一贯风格，适合于有一定基础后回头去看。</p>

<p>在分析这个方向，接下来就是泛函分析(Functional Analysis)。</p>

<p><strong>Introductory Functional Analysis with Applications, by Erwin Kreyszig.</strong></p>

<p>适合作为泛函的基础教材，容易切入而不失全面。我特别喜欢它对于谱论和算子理论的特别关注，这对于做learning的研究是特别重要的。Rudin也有一本关于functional analysis的书，那本书在数学上可能更为深刻，但是不易于上手，所讲内容和learning的切合度不如此书。</p>

<p>在分析这个方向，还有一个重要的学科是测度理论(Measure theory)，但是我看过的书里面目前还没有感觉有特别值得介绍的。</p>

<h2 id="toc_3">拓扑 (Topology)</h2>

<p>在我读过的基本拓扑书各有特色，但是综合而言，我最推崇：</p>

<p><strong>Topology (2nd Ed.)  by James Munkres</strong></p>

<p>这本书是Munkres教授长期执教MIT拓扑课的心血所凝。对于一般拓扑学(General<br/>
topology)有全面介绍，而对于代数拓扑(Algebraic topology)也有适度的探讨。此书不需要特别的数学知识就可以开始学习，由浅入深，从最基本的集合论概念（很多书不屑讲这个）到 Nagata-Smirnov Theorem和Tychonoff theorem等较深的定理（很多书避开了这个）都覆盖了。讲述方式思想性很强，对于很多定理，除了给出证明过程和引导你思考其背后的原理脉络，很多令人赞叹的亮点——我常读得忘却饥饿，不愿释手。很多习题很有水平。</p>

<h2 id="toc_4">流形理论 (Manifold theory)</h2>

<p>对于拓扑和分析有一定把握时，方可开始学习流形理论，否则所学只能流于浮浅。我所使用的书是</p>

<p><strong>Introduction to Smooth Manifolds.  by John M. Lee</strong></p>

<p>虽然书名有introduction这个单词，但是实际上此书涉入很深，除了讲授了基本的manifold, tangent space, bundle, sub-manifold等，还探讨了诸如纲理论(Category theory)，德拉姆上同调(De Rham cohomology)和积分流形等一些比较高级的专题。对于李群和李代数也有相当多的讨论。行文通俗而又不失严谨，不过对某些记号方式需要熟悉一下。</p>

<p>虽然李群论是建基于平滑流形的概念之上，不过，也可能从矩阵出发直接学习李群和李代数——这种方法对于急需使用李群论解决问题的朋友可能更加实用。而且，对于一个问题从不同角度看待也利于加深理解。下面一本书就是这个方向的典范：</p>

<p><strong>Lie Groups, Lie Algebras, and Representations: An Elementary Introduction.  by Brian C. Hall</strong></p>

<p>此书从开始即从矩阵切入，从代数而非几何角度引入矩阵李群的概念。并通过定义运算的方式建立exponential mapping，并就此引入李代数。这种方式比起传统的通过“左不变向量场(Left-invariant vector field)“的方式定义李代数更容易为人所接受，也更容易揭示李代数的意义。最后，也有专门的论述把这种新的定义方式和传统方式联系起来。</p>

<hr/>

<p>感觉数学似乎总是不够的。这些日子为了解决research中的一些问题，又在图书馆捧起了数学的教科书。从大学到现在，课堂上学的和自学的数学其实不算少了，可是在研究的过程中总是发现需要补充新的数学知识。Learning和Vision都是很多种数学的交汇场。看着不同的理论体系的交汇，对于一个researcher来说，往往是非常exciting的enjoyable的事情。不过，这也代表着要充分了解这个领域并且取得有意义的进展是很艰苦的。记得在两年前的一次blog里面，提到过和learning有关的数学。今天看来，我对于数学在这个领域的作用有了新的思考。对于Learning的研究，</p>

<p>1、Linear Algebra (线性代数) 和 Statistics (统计学) 是最重要和不可缺少的。这代表了Machine Learning中最主流的两大类方法的基础。一种是以研究函数和变换为重点的代数方法，比如Dimension reduction，feature extraction，Kernel等，一种是以研究统计模型和样本分布为重点的统计方法，比如Graphical model, Information theoretical models等。它们侧重虽有不同，但是常常是共同使用的，对于代数方法，往往需要统计上的解释，对于统计模型，其具体计算则需要代数的帮助。以代数和统计为出发点，继续往深处走，我们会发现需要更多的数学。</p>

<p>2、Calculus (微积分)，只是数学分析体系的基础。其基础性作用不言而喻。Learning研究的大部分问题是在连续的度量空间进行的，无论代数还是统计，在研究优化问题的时候，对一个映射的微分或者梯度的分析总是不可避免。而在统计学中，Marginalization和积分更是密不可分——不过，以解析形式把积分导出来的情况则不多见。</p>

<p>3、Partial Differential Equation （偏微分方程，这主要用于描述动态过程，或者仿动态过程。这个学科在Vision中用得比Learning多，主要用于描述连续场的运动或者扩散过程。比如Level set, Optical flow都是这方面的典型例子。</p>

<p>4、Functional Analysis (泛函分析)，通俗地，可以理解为微积分从有限维空间到<br/>
无限维空间的拓展——当然了，它实际上远不止于此。在这个地方，函数以及其所作用的对象之间存在的对偶关系扮演了非常重要的角色。Learning发展至今，也在向无限维延伸——从研究有限维向量的问题到以无限维的函数为研究对象。Kernel Learning 和 Gaussian Process 是其中典型的例子——其中的核心概念都是Kernel。很多做Learning的人把Kernel简单理解为Kernel trick的运用，这就把kernel的意义严重弱化了。在泛函里面，Kernel (Inner Product)是建立整个博大的代数体系的根本，从metric, transform到spectrum都根源于此。</p>

<p>5、Measure Theory(测度理论)，这是和实分析关系非常密切的学科。但是测度理论并不限于此。从某种意义上说，Real Analysis可以从Lebesgue Measure（勒贝格测度）推演，不过其实还有很多别的测度体系——概率本身就是一种测度。测度理论对于Learning的意义是根本的，现代统计学整个就是建立在测度理论的基础之上——虽然初级的概率论教科书一般不这样引入。在看一些统计方面的文章的时候，你可能会发现，它们会把统计的公式改用测度来表达，这样做有两个好处：所有的推导和结论不用分别给连续分布和离散分布各自写一遍了，这两种东西都可以用同一的测度形式表达：连续分布的积分基于Lebesgue测度，离散分布的求和基于计数测度，而且还能推广到那种既不连续又不离散的分布中去（这种东西不是数学家的游戏，而是已经在实用的东西，在Dirchlet Process或者Pitman-Yor Process里面会经常看到)。而且，即使是连续积分，如果不是在欧氏空间进行，而是在更一般的拓扑空间（比如微分流形或者变换群），那么传统的黎曼积分（就是大学一年级在微积分课学的那种）就不work了，你可能需要它们的一些推广，比如Haar Measure或者 Lebesgue-Stieltjes积分。</p>

<p>6、Topology（拓扑学)，这是学术中很基础的学科。它一般不直接提供方法，但是它的很多概念和定理是其它数学分支的基石。看很多别的数学的时候，你会经常接触这样一些概念：Open set / Closed set，set basis，Hausdauf, continuous function，metric space, Cauchy sequence, neighborhood, compactness, connectivity。很多这些也许在大学一年级就学习过一些，当时是基于极限的概念获得的。如果，看过拓扑学之后，对这些概念的认识会有根本性的拓展。比如，连续函数，当时是由epison法定义的，就是无论取多小的正数epsilon，都存在xxx，使得xxx。这是需要一种metric去度量距离的，在general topology里面，对于连续函数的定义连坐标和距离都不需要——如果一个映射使得开集的原像是开集，它就是连续的——至于开集是基于集合论定义的，不是通常的开区间的意思。这只是最简单的例子。当然，我们研究learning也许不需要深究这些数学概念背后的公理体系，但是，打破原来定义的概念的局限在很多问题上是必须的——尤其是当你研究的东西它不是在欧氏空间里面的时候——正交矩阵，变换群，流形，概率分布的空间，都属于此。</p>

<p>7、Differential Manifold (微分流形)，通俗地说它研究的是平滑的曲面。一个直接的印象是它是不是可以用来fitting一个surface什么的——当然这算是一种应用，但是这是非常初步的。本质上说，微分流形研究的是平滑的拓扑结构。一个空间构成微分流形的基本要素是局部平滑：从拓扑学来理解，就是它的任意局部都同胚于欧氏空间，从解析的角度来看，就是相容的局部坐标系统。当然，在全局上，它不要求和欧氏空间同胚。它除了可以用于刻画集合上的平滑曲面外，更重要的意义在于，它可以用于研究很多重要的集合。一个n-维线性空间的全部k-维子空间</p>

<p>8、Lie Group Theory (李群论)，一般意义的群论在Learning中被运用的不是很多，群论在Learning中用得较多的是它的一个重要方向Lie group。定义在平滑流形上的群，并且其群运算是平滑的话，那么这就叫李群。因为Learning和编码不同，更多关注的是连续空间，因为Lie group在各种群中对于Learning特别重要。各种子空间，线性变换，非奇异矩阵都基于通常意义的矩阵乘法构成李群。在李群中的映射，变换<br/>
，度量，划分等等都对于Learning中代数方法的研究有重要指导意义。</p>

<p>9、Graph Theory（图论)，图，由于它在表述各种关系的强大能力以及优雅的理论，高效的算法，越来越受到Learning领域的欢迎。经典图论，在Learning中的一个最重要应用就是graphical models了，它被成功运用于分析统计网络的结构和规划统计推断的流程。Graphical model所取得的成功，图论可谓功不可没。在Vision里面，maxflow(graphcut)算法在图像分割，Stereo还有各种能量优化中也广受应用。另外一个重要的图论分支就是Algebraic graph theory (代数图论)，主要运用于图的谱分析，著名的应用包括Normalized Cut和Spectral Clustering。近年来在semi-supervised learning中受到特别关注。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007389.html">
                
                  <h1>libSVM 使用指南</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>CMU 15 Fall 10601b 机器学习的期末作业是在 CIFAR-10 数据集上的图像分类，我们小组已经实现了 LR, NN, NB 等比较『朴素』的机器学习算法，对于如何实现 SVM 倒是一直没有什么思路。他山之石，可以攻玉，我打算从 libSVM 入手，看看能不能找到点思路。</p>

<h2 id="toc_0">一：下载编译安装</h2>

<p>这三个统称『配置环境』，从<a href="http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/index.html">官网</a>下载，然后自己想办法编译（我是直接找别人编译好的），接着重命名避免和 matlab 自带的 svmtrain 重名。说明一下我用的版本是 3.20</p>

<blockquote>
<p>在当前目录下会出现svmtrain.mexw64、svmpredict.mexw64（64位系统）或者svmtrain.mexw32、svmpredict.mexw32（32位系统）这两个文件，把文件名svmtrain和svmpredict相应改成libsvmtrain和libsvmpredict。</p>

<p>这是因为Matlab中自带有SVM的工具箱，而且其函数名字就是svmtrain和svmpredict，和LIBSVM默认的名字一样，在实际使用的时候有时会产生一定的问题，比如想调用LIBSVM的变成了调用Matlab SVM。</p>

<p>如果有进行重命名的，以后使用LIBSVM时一律使用libsvmtrain和libsvmpredict这两个名字进行调用。</p>
</blockquote>

<h2 id="toc_1">二：原理</h2>

<p>SVM 的原理这里不介绍，关键词：监督学习，二分类，核函数。这里提到是二分类，那么要如何扩展成多分类呢？比方说在我们的这个项目中，图片有十个类别，就要想办法把一个二分类的用到十分类上。比较基本的思路有两种，一对多(one-versus-rest)和一对一(one-versus-one)。</p>

<p>举个例子，一对多实际上是训练十个分类器，对于第一个分类器，类别 1 是一类，类别 2-10 是一类；对于第二个分类器，类别 2 是一类，类别 1 + 类别 3-10 是一类，这样就得到了十个分类器。预测的时候，分别用这十个分类器分类，然后将分类结果中出现最多的那个类别作为结果。</p>

<p>继续举例子，一对一的话实际要训练 \(\frac{10\times9}{2}\) 个分类器，然后预测的时候需要跑所有的分类器，选出现最多的那个类别作为最终分类结果。</p>

<p>libSVM 是使用一对一的方式来实现的</p>

<h2 id="toc_2">三：使用</h2>

<p>基本来说，因为不需要在意具体的实现，所以使用起来还是简单粗暴的</p>

<h3 id="toc_3">训练</h3>

<p>如果数据准备好了的话，一句话就可以搞定。</p>

<pre><code class="language-matlab">model = libsvmtrain(training_label_vector, training_instance_matrix [, &#39;libsvm_options&#39;]);
</code></pre>

<p>这个函数有三个参数，其中</p>

<ul>
<li><code>-training_label_vector</code>:训练样本的类标，如果有m个样本，就是m x 1的矩阵（类型必须为double）。这里可以是二分类和多分类，类标是（-1,1）、（1,2,3）或者其他任意用来表示不同的类别的数字，要转成double类型。</li>
<li><code>-training_instance_matrix</code>:训练样本的特征，如果有m个样本，每个样本特征是n维，则为m x n的矩阵（类型必须为double）。</li>
<li><code>-libsvm_options</code>:训练的参数，会专门开一章来介绍。</li>
</ul>

<h3 id="toc_4">预测</h3>

<p>如果有了训练出来的模型的话，一句话搞定。<code>libpredict</code> 函数用于对测试集的数据进行测试，还能对未知样本进行预测。</p>

<pre><code class="language-matlab">[predicted_label, accuracy, decision_values/prob_estimates] 
　　　　= libsvmpredict(testing_label_vector, testing_instance_matrix, model [, &#39;libsvm_options&#39;]);
</code></pre>

<p>这个函数包括四个参数，其中</p>

<ul>
<li><code>-testing_label_vector</code>:测试样本的类标，如果有m个样本，就是m x 1的矩阵（类型必须为double）。如果类标未知，可以初始化为任意m x 1的double数组。</li>
<li><code>-testing_instance_matrix</code>:测试样本的特征，如果有m个样本，每个样本特征是n维，则为m x n的矩阵（类型必须为double）。</li>
<li><code>-model</code>:使用libsvmtrain返回的模型</li>
<li><code>-libsvm_options</code>:预测的参数，与训练的参数形式一样。</li>
</ul>

<h2 id="toc_5">四：参数</h2>

<p>参数这一部分比较多，而且需要一定的理论基础，很多参数我都不大明白是干嘛的，所以我就先挑一些我懂的参数，然后剩下的就是文档里的大概翻译。所以下面的列表是有先后顺序的</p>

<ul>
<li><code>-s</code> svm类型：SVM设置类型（默认0，我就用默认的)

<ul>
<li>0 — C-SVC； </li>
<li>1 – v-SVC； </li>
<li>2 – one-class SVM； </li>
<li>3 — e-SVR； </li>
<li>4 — v-SVR</li>
</ul></li>
<li><code>-t</code> 核函数类型：核函数设置类型（默认2，据说2的效果也比较好，所以继续用2）

<ul>
<li>0 – 线性核函数：<code>u’v</code></li>
<li>1 – 多项式核函数：<code>（r*u’v + coef0)^degree</code></li>
<li>2 – RBF(径向基)核函数：<code>exp(-r|u-v|^2）</code></li>
<li>3 – sigmoid核函数：<code>tanh(r*u’v + coef0)</code></li>
</ul></li>
<li><code>-h</code> shrinking：是否使用启发式，0或1（默认1）

<ul>
<li>用 0 的话训练会快一些，</li>
</ul></li>
<li><code>-d</code> degree：核函数中的degree设置（针对多项式核函数）（默认3）</li>
<li><code>-g</code> r(gamma）：核函数中的gamma函数设置（针对多项式/rbf/sigmoid核函数）（默认1/k，k为总类别数)</li>
<li><code>-r</code> coef0：核函数中的coef0设置（针对多项式/sigmoid核函数）（（默认0)</li>
<li><code>-c</code> cost：设置C-SVC，e -SVR和v-SVR的参数（损失函数）（默认1）</li>
<li><code>-n</code> nu：设置v-SVC，一类SVM和v- SVR的参数（默认0.5）</li>
<li><code>-p</code> p：设置e -SVR 中损失函数p的值（默认0.1）</li>
<li><code>-m</code> cachesize：设置cache内存大小，以MB为单位（默认40）</li>
<li><code>-e</code> eps：设置允许的终止判据（默认0.001）</li>
<li><code>-wi</code> weight：设置第几类的参数C为weight*C (C-SVC中的C) （默认1）</li>
<li><code>-v</code> n: n-fold交互检验模式，n为fold的个数，必须大于等于2</li>
</ul>

<p>以上这些参数设置可以按照SVM的类型和核函数所支持的参数进行任意组合，如果设置的参数在函数或SVM类型中没有也不会产生影响，程序不会接受该参数；如果应有的参数设置不正确，参数将采用默认值。</p>

<h2 id="toc_6">五：返回数据模型</h2>

<p>训练会返回一个结构体，预测会返回三个结果，这里分别说明一下</p>

<h3 id="toc_7">训练返回的内容</h3>

<p>libsvmtrain函数返回训练好的SVM分类器模型，可以用来对未知的样本进行预测。这个模型是一个结构体，包含以下成员：</p>

<ul>
<li><code>-Parameters</code>: 一个5 x 1的矩阵，从上到下依次表示：

<ul>
<li><code>-s</code> SVM类型（默认0）；</li>
<li><code>-t</code> 核函数类型（默认2）</li>
<li><code>-d</code> 核函数中的degree设置(针对多项式核函数)(默认3)；</li>
<li><code>-g</code> 核函数中的r(gamma）函数设置(针对多项式/rbf/sigmoid核函数) (默认类别数目的倒数)；</li>
<li><code>-r</code> 核函数中的coef0设置(针对多项式/sigmoid核函数)((默认0)</li>
</ul></li>
<li><code>-nr_class</code>: 表示数据集中有多少类别，比如二分类时这个值即为2。</li>
<li><code>-totalSV</code>: 表示支持向量的总数。</li>
<li><code>-rho</code>: 决策函数wx+b中的常数项的相反数（-b）。</li>
<li><code>-Label</code>: 表示数据集中类别的标签，比如二分类常见的1和-1。</li>
<li><code>-ProbA</code>: 使用-b参数时用于概率估计的数值，否则为空。</li>
<li><code>-ProbB</code>: 使用-b参数时用于概率估计的数值，否则为空。</li>
<li><code>-nSV</code>: 表示每类样本的支持向量的数目，和Label的类别标签对应。如Label=[1; -1],nSV=[63; 67]，则标签为1的样本有63个支持向量，标签为-1的有67个。</li>
<li><code>-sv_coef</code>: 表示每个支持向量在决策函数中的系数。</li>
<li><code>-SVs</code>: 表示所有的支持向量，如果特征是n维的，支持向量一共有m个，则为m x n的稀疏矩阵。</li>
</ul>

<p>另外，如果在训练中使用了-v参数进行交叉验证时，返回的不是一个模型，而是交叉验证的分类的正确率或者回归的均方根误差。</p>

<h3 id="toc_8">预测返回的内容</h3>

<p>libsvmtrain函数有三个返回值，不需要的值在Matlab可以用~进行代替。</p>

<ul>
<li><code>-predicted_label</code>：第一个返回值，表示样本的预测类标号。</li>
<li><code>-accuracy</code>：第二个返回值，一个3 x 1的数组，表示分类的正确率、回归的均方根误差、回归的平方相关系数。</li>
<li>-<code>decision_values/prob_estimates</code>：第三个返回值，一个矩阵包含决策的值或者概率估计。对于n个预测样本、k类的问题，如果指定“-b 1”参数，则n x k的矩阵，每一行表示这个样本分别属于每一个类别的概率；如果没有指定“-b 1”参数，则为n x k*(k-1)/2的矩阵，每一行表示k(k-1)/2个二分类SVM的预测结果。</li>
</ul>

<h2 id="toc_9">六：读取或保存</h2>

<p><strong><code>libsvmread</code>函数可以读取以LIBSVM格式存储的数据文件。</strong></p>

<pre><code class="language-matlab">[label_vector, instance_matrix] = libsvmread(‘data.txt’);
</code></pre>

<p>这个函数输入的是文件的名字，输出为样本的类标和对应的特征。</p>

<p><strong><code>libsvmwrite</code>函数可以把Matlab的矩阵存储称为LIBSVM格式的文件。</strong></p>

<pre><code class="language-matlab">libsvmwrite(‘data.txt’, label_vector, instance_matrix]
</code></pre>

<p>这个函数有三个输入，分别为保存的文件名、样本的类标和对应的特征（必须为double类型的稀疏矩阵）。</p>

<h2 id="toc_10">总结</h2>

<p>总体来说训练时间还是很长的（怪电脑），尤其是随着分类的增多所需要的分类器会增长得更快，难以想象要分一百类会怎么样。不过 libSVM 在不同的平台下都有实现，哪怕想要在手机上实现最简单的机器学习，也都可以用这个包，还是非常方便的。</p>

<h2 id="toc_11">参考资料</h2>

<p><a href="http://noalgo.info/363.html">LIBSVM在Matlab下的使用</a></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007285.html">
                
                  <h1>HMM 最佳学习范例</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">一 介绍（Introduction）</h2>

<p>我们通常都习惯寻找一个事物在一段时间里的变化模式（规律）。这些模式发生在很多领域，比如计算机中的指令序列，句子中的词语顺序和口语单词中的音素序列等等，事实上任何领域中的一系列事件都有可能产生有用的模式。</p>

<p>考虑一个简单的例子，有人试图通过一片海藻推断天气——民间传说告诉我们‘湿透的’海藻意味着潮湿阴雨，而‘干燥的’海藻则意味着阳光灿烂。如果它处于一个中间状态（‘有湿气’），我们就无法确定天气如何。然而，天气的状态并没有受限于海藻的状态，所以我们可以在观察的基础上预测天气是雨天或晴天的可能性。另一个有用的线索是前一天的天气状态（或者，至少是它的可能状态）——通过综合昨天的天气及相应观察到的海藻状态，我们有可能更好的预测今天的天气。</p>

<p>这是本教程中我们将考虑的一个典型的系统类型。</p>

<p>首先，我们将介绍产生概率模式的系统，如晴天及雨天间的天气波动。</p>

<p>然后，我们将会看到这样一个系统，我们希望预测的状态并不是观察到的——其底层系统是隐藏的。在上面的例子中，观察到的序列将是海藻而隐藏的系统将是实际的天气。</p>

<p>最后，我们会利用已经建立的模型解决一些实际的问题。对于上述例子，我们想知道：</p>

<ol>
<li>给出一个星期每天的海藻观察状态，之后的天气将会是什么?</li>
<li>给定一个海藻的观察状态序列，预测一下此时是冬季还是夏季？直观地，如果一段时间内海藻都是干燥的，那么这段时间很可能是夏季，反之，如果一段时间内海藻都是潮湿的，那么这段时间可能是冬季。</li>
</ol>

<h2 id="toc_1">二 生成模式（Generating Patterns）</h2>

<h3 id="toc_2">1、确定性模式（Deterministic Patterns）</h3>

<p>考虑一套交通信号灯，灯的颜色变化序列依次是红色-红色/黄色-绿色-黄色-红色。这个序列可以作为一个状态机器，交通信号灯的不同状态都紧跟着上一个状态。</p>

<p><img src="./_resources/hmm1.gif" alt=""/></p>

<p>注意每一个状态都是唯一的依赖于前一个状态，所以，如果交通灯为绿色，那么下一个颜色状态将始终是黄色——也就是说，该系统是确定性的。确定性系统相对比较容易理解和分析，因为状态间的转移是完全已知的。</p>

<h3 id="toc_3">2、非确定性模式（Non-deterministic patterns）</h3>

<p>为了使天气那个例子更符合实际，加入第三个状态——多云。与交通信号灯例子不同，我们并不期望这三个天气状态之间的变化是确定性的，但是我们依然希望对这个系统建模以便生成一个天气变化模式（规律）。</p>

<p>一种做法是假设模型的当前状态仅仅依赖于前面的几个状态，这被称为马尔科夫假设，它极大地简化了问题。显然，这可能是一种粗糙的假设，并且因此可能将一些非常重要的信息丢失。</p>

<p>当考虑天气问题时，马尔科夫假设假定今天的天气只能通过过去几天已知的天气情况进行预测——而对于其他因素，譬如风力、气压等则没有考虑。在这个例子以及其他相似的例子中，这样的假设显然是不现实的。然而，由于这样经过简化的系统可以用来分析，我们常常接受这样的知识假设，虽然它产生的某些信息不完全准确。</p>

<p><img src="./_resources/hmm2a.gif" alt=""/> <img src="./_resources/hmm2b.gif" alt=""/> <img src="./_resources/hmm2c.gif" alt=""/></p>

<p>一个马尔科夫过程是状态间的转移仅依赖于前n个状态的过程。这个过程被称之为n阶马尔科夫模型，其中n是影响下一个状态选择的（前）n个状态。最简单的马尔科夫过程是一阶模型，它的状态选择仅与前一个状态有关。这里要注意它与确定性系统并不相同，因为下一个状态的选择由相应的概率决定，并不是确定性的。</p>

<p>下图是天气例子中状态间所有可能的一阶状态转移情况：</p>

<p><img src="./_resources/hmm3.gif" alt=""/></p>

<p>对于有 M 个状态的一阶马尔科夫模型，共有 \(M^2\) 个状态转移，因为任何一个状态都有可能是所有状态的下一个转移状态。每一个状态转移都有一个概率值，称为状态转移概率——这是从一个状态转移到另一个状态的概率。所有的 \(M^2\) 个概率可以用一个状态转移矩阵表示。注意这些概率并不随时间变化而不同——这是一个非常重要（但常常不符合实际）的假设。</p>

<p>下面的状态转移矩阵显示的是天气例子中可能的状态转移概率：</p>

<p><img src="./_resources/hmm4.gif" alt=""/></p>

<p>也就是说，如果昨天是晴天，那么今天是晴天的概率为0.5，是多云的概率为0.375。注意，每一行的概率之和为1。</p>

<p>要初始化这样一个系统，我们需要确定起始日天气的（或可能的）情况，定义其为一个初始概率向量，称为pi向量。</p>

<p><img src="./_resources/hmm5.gif" alt=""/></p>

<p>也就是说，第一天为晴天的概率为1。</p>

<p>现在我们定义一个一阶马尔科夫过程如下：</p>

<ul>
<li>状态：三个状态——晴天，多云，雨天。</li>
<li>pi向量：定义系统初始化时每一个状态的概率。</li>
<li>状态转移矩阵：给定前一天天气情况下的当前天气概率。</li>
</ul>

<p>任何一个可以用这种方式描述的系统都是一个马尔科夫过程。</p>

<h3 id="toc_4">3、总结</h3>

<p>我们尝试识别时间变化中的模式，并且为了达到这个目我们试图对这个过程建模以便产生这样的模式。我们使用了离散时间点、离散状态以及做了马尔科夫假设。在采用了这些假设之后，系统产生了这个被描述为马尔科夫过程的模式，它包含了一个pi向量（初始概率）和一个状态转移矩阵。关于假设，重要的一点是状态转移矩阵并不随时间的改变而改变——这个矩阵在整个系统的生命周期中是固定不变的。</p>

<h2 id="toc_5">三、隐藏模式（Hidden Patterns）</h2>

<h3 id="toc_6">1、马尔科夫过程的局限性</h3>

<p>在某些情况下，我们希望找到的模式用马尔科夫过程描述还显得不充分。回顾一下天气那个例子，一个隐士也许不能够直接获取到天气的观察情况，但是他有一些水藻。民间传说告诉我们水藻的状态与天气状态有一定的概率关系——天气和水藻的状态是紧密相关的。在这个例子中我们有两组状态，观察的状态（水藻的状态）和隐藏的状态（天气的状态）。我们希望为隐士设计一种算法，在不能够直接观察天气的情况下，通过水藻和马尔科夫假设来预测天气。</p>

<p>一个更实际的问题是语音识别，我们听到的声音是来自于声带、喉咙大小、舌头位置以及其他一些东西的组合结果。所有这些因素相互作用产生一个单词的声音，一套语音识别系统检测的声音就是来自于个人发音时身体内部物理变化所引起的不断改变的声音。</p>

<p>一些语音识别装置工作的原理是将内部的语音产出看作是隐藏的状态，而将声音结果作为一系列观察的状态，这些由语音过程生成并且最好的近似了实际（隐藏）的状态。在这两个例子中，需要着重指出的是，隐藏状态的数目与观察状态的数目可以是不同的。一个包含三个状态的天气系统（晴天、多云、雨天）中，可以观察到4个等级的海藻湿润情况（干、稍干、潮湿、湿润）；纯粹的语音可以由80个音素描述，而身体的发音系统会产生出不同数目的声音，或者比80多，或者比80少。</p>

<p>在这种情况下，观察到的状态序列与隐藏过程有一定的概率关系。我们使用隐马尔科夫模型对这样的过程建模，这个模型包含了一个底层隐藏的随时间改变的马尔科夫过程，以及一个与隐藏状态某种程度相关的可观察到的状态集合。</p>

<h3 id="toc_7">2、隐马尔科夫模型（Hidden Markov Models）</h3>

<p>下图显示的是天气例子中的隐藏状态和观察状态。假设隐藏状态（实际的天气）由一个简单的一阶马尔科夫过程描述，那么它们之间都相互连接。</p>

<p><img src="./_resources/hidden-weather-example.gif" alt=""/><br/>
　　<br/>
隐藏状态和观察状态之间的连接表示：在给定的马尔科夫过程中，一个特定的隐藏状态生成特定的观察状态的概率。这很清晰的表示了‘进入’一个观察状态的所有概率之和为1，在上面这个例子中就是Pr(Obs|Sun), Pr(Obs|Cloud) 及 Pr(Obs|Rain)之和。这里 Obs 指的是观察到的数据</p>

<p>除了定义了马尔科夫过程的概率关系，我们还有另一个矩阵，定义为混淆矩阵（confusion matrix），它包含了给定一个隐藏状态后得到的观察状态的概率。对于天气例子，混淆矩阵是：</p>

<p><img src="./_resources/weather-b-matrix.gif" alt=""/></p>

<p>注意矩阵的每一行之和是1</p>

<h3 id="toc_8">3、总结（Summary）</h3>

<p>我们已经看到在一些过程中一个观察序列与一个底层马尔科夫过程是概率相关的。在这些例子中，观察状态的数目可以和隐藏状态的数码不同。</p>

<p>我们使用一个隐马尔科夫模型（HMM）对这些例子建模。这个模型包含两组状态集合和三组概率集合：</p>

<ul>
<li>隐藏状态：一个系统的（真实）状态，可以由一个马尔科夫过程进行描述（例如，天气）。</li>
<li>观察状态：在这个过程中‘可视’的状态（例如，海藻的湿度）。</li>
<li>pi向量：包含了（隐）模型在时间t=1时一个特殊的隐藏状态的概率（初始概率）。</li>
<li>状态转移矩阵：包含了一个隐藏状态到另一个隐藏状态的概率</li>
<li>混淆矩阵：包含了给定隐马尔科夫模型的某一个特殊的隐藏状态，观察到的某个观察状态的概率。</li>
</ul>

<p>因此一个隐马尔科夫模型是在一个标准的马尔科夫过程中引入一组观察状态，以及其与隐藏状态间的一些概率关系。</p>

<h2 id="toc_9">四、隐马尔科夫模型（Hidden Markov Models）</h2>

<h3 id="toc_10">1、定义（Definition of a hidden Markov model）</h3>

<p>一个隐马尔科夫模型是一个三元组\((\Pi, A, B)\)。</p>

<ul>
<li>\(\Pi=(\pi_i)\)：初始化概率向量；</li>
<li>\(A=(a_{ij})\)：状态转移矩阵；\(Pr(x_{i_t} | x_{j_{t-1}})\)</li>
<li>\(B=(b_{ij})\)：混淆矩阵；\(Pr(y_i | x_j)\)</li>
</ul>

<p>在状态转移矩阵及混淆矩阵中的每一个概率都是时间无关的——也就是说，当系统演化时这些矩阵并不随时间改变。实际上，这是马尔科夫模型关于真实世界最不现实的一个假设。</p>

<h3 id="toc_11">2、应用（Uses associated with HMMs）</h3>

<p>一旦一个系统可以作为HMM被描述，就可以用来解决三个基本问题。其中前两个是模式识别的问题：给定HMM求一个观察序列的概率（评估）；搜索最有可能生成一个观察序列的隐藏状态序列（解码）。第三个问题是给定观察序列生成一个HMM（学习）。</p>

<h4 id="toc_12">a) 评估（Evaluation）</h4>

<p>考虑这样的问题，我们有一些描述不同系统的隐马尔科夫模型（也就是一些\((\Pi, A, B)\)三元组的集合）及一个观察序列。我们想知道哪一个HMM最有可能产生了这个给定的观察序列。例如，对于海藻来说，我们也许会有一个“夏季”模型和一个“冬季”模型，因为不同季节之间的情况是不同的——我们也许想根据海藻湿度的观察序列来确定当前的季节。</p>

<p>我们使用前向算法（forward algorithm）来计算给定隐马尔科夫模型（HMM）后的一个观察序列的概率，并因此选择最合适的隐马尔科夫模型(HMM)。</p>

<p>在语音识别中这种类型的问题发生在当一大堆数目的马尔科夫模型被使用，并且每一个模型都对一个特殊的单词进行建模时。一个观察序列从一个发音单词中形成，并且通过寻找对于此观察序列最有可能的隐马尔科夫模型（HMM）识别这个单词。</p>

<h4 id="toc_13">b) 解码（Decoding）</h4>

<p>给定观察序列搜索最可能的隐藏状态序列。</p>

<p>另一个相关问题，也是最感兴趣的一个，就是搜索生成输出序列的隐藏状态序列。在许多情况下我们对于模型中的隐藏状态更感兴趣，因为它们代表了一些更有价值的东西，而这些东西通常不能直接观察到。</p>

<p>考虑海藻和天气这个例子，一个盲人隐士只能感觉到海藻的状态，但是他更想知道天气的情况，天气状态在这里就是隐藏状态。</p>

<p>我们使用Viterbi 算法（Viterbi algorithm）确定（搜索）已知观察序列及HMM下最可能的隐藏状态序列。</p>

<p>Viterbi算法（Viterbi algorithm）的另一广泛应用是自然语言处理中的词性标注。在词性标注中，句子中的单词是观察状态，词性（语法类别）是隐藏状态（注意对于许多单词，如wind，fish拥有不止一个词性）。对于每句话中的单词，通过搜索其最可能的隐藏状态，我们就可以在给定的上下文中找到每个单词最可能的词性标注。</p>

<h4 id="toc_14">c）学习（Learning）</h4>

<p>根据观察序列生成隐马尔科夫模型。</p>

<p>第三个问题，也是与HMM相关的问题中最难的，根据一个观察序列（来自于已知的集合），以及与其有关的一个隐藏状态集，估计一个最合适的隐马尔科夫模型（HMM），也就是确定对已知序列描述的最合适的\((\Pi, A, B)\)三元组。</p>

<p>当矩阵A和B不能够直接被（估计）测量时，前向-后向算法（forward-backward algorithm）被用来进行学习（参数估计），这也是实际应用中常见的情况。</p>

<h3 id="toc_15">3、总结（Summary）</h3>

<p>由一个向量和两个矩阵\((\Pi, A, B)\)描述的隐马尔科夫模型对于实际系统有着巨大的价值，虽然经常只是一种近似，但它们却是经得起分析的。隐马尔科夫模型通常解决的问题包括：</p>

<ol>
<li>对于一个观察序列匹配最可能的系统——评估，使用前向算法（forward algorithm）解决；</li>
<li>对于已生成的一个观察序列，确定最可能的隐藏状态序列——解码，使用Viterbi 算法（Viterbi algorithm）解决；</li>
<li>对于已生成的观察序列，决定最可能的模型参数——学习，使用前向-后向算法（forward-backward algorithm）解决。</li>
</ol>

<h2 id="toc_16">五、前向算法（Forward Algorithm）</h2>

<p>计算观察序列的概率（Finding the probability of an observed sequence）</p>

<h3 id="toc_17">1、穷举搜索（ Exhaustive search for solution）</h3>

<p>给定隐马尔科夫模型，也就是在模型参数\((\Pi, A, B)\)已知的情况下，我们想找到观察序列的概率。还是考虑天气这个例子，我们有一个用来描述天气及与它密切相关的海藻湿度状态的隐马尔科夫模型(HMM)，另外我们还有一个海藻的湿度状态观察序列。假设连续3天海藻湿度的观察结果是（干燥、湿润、湿透）——而这三天每一天都可能是晴天、多云或下雨，对于观察序列以及隐藏的状态，可以将其视为网格：</p>

<p><img src="./_resources/hmm6.gif" alt=""/></p>

<p>网格中的每一列都显示了可能的的天气状态，并且每一列中的每个状态都与相邻列中的每一个状态相连。而其状态间的转移都由状态转移矩阵提供一个概率。在每一列下面都是某个时间点上的观察状态，给定任一个隐藏状态所得到的观察状态的概率由混淆矩阵提供。</p>

<p>可以看出，一种计算观察序列概率的方法是找到每一个可能的隐藏状态，并且将这些隐藏状态下的观察序列概率相加。对于上面那个（天气）例子，将有3<sup>3</sup> = 27种不同的天气序列可能性，因此，观察序列的概率是：</p>

<p>Pr(dry,damp,soggy | HMM) = Pr(dry,damp,soggy | sunny,sunny,sunny) + Pr(dry,damp,soggy | sunny,sunny ,cloudy) + Pr(dry,damp,soggy | sunny,sunny ,rainy) + . . . . Pr(dry,damp,soggy | rainy,rainy ,rainy)</p>

<p>用这种方式计算观察序列概率极为昂贵，特别对于大的模型或较长的序列，因此我们可以利用这些概率的时间不变性来减少问题的复杂度。</p>

<h3 id="toc_18">2、使用递归降低问题复杂度</h3>

<p>给定一个隐马尔科夫模型（HMM），我们将考虑递归地计算一个观察序列的概率。我们首先定义局部概率（partial probability）,它是到达网格中的某个中间状态时的概率。然后，我们将介绍如何在t=1和t=n(&gt;1)时计算这些局部概率。</p>

<p>假设一个T-长观察序列是：</p>

<p><img src="./_resources/hmm7.gif" alt=""/></p>

<h4 id="toc_19">2a.局部概率(alpha‘s)</h4>

<p>考虑下面这个网格，它显示的是天气状态及对于观察序列干燥，湿润及湿透的一阶状态转移情况：</p>

<p><img src="./_resources/hmm8.gif" alt=""/></p>

<p>我们可以将计算到达网格中某个中间状态的概率作为所有到达这个状态的可能路径的概率求和问题。</p>

<p>例如，t=2时位于“多云”状态的局部概率通过如下路径计算得出：</p>

<p><img src="./_resources/hmm9.gif" alt=""/></p>

<p>我们定义t时刻位于状态j的局部概率为at(j)——这个局部概率计算如下：<br/>
　　<br/>
\[\alpha_t(j)= Pr( 观察状态\;|\;隐藏状态_j ) \times Pr(t时刻所有指向j状态的路径）\]</p>

<p>对于最后的观察状态，其局部概率包括了通过所有可能的路径到达这些状态的概率——例如，对于上述网格，最终的局部概率通过如下路径计算得出：</p>

<p><img src="./_resources/hmm10.gif" alt=""/></p>

<p>由此可见，对于这些最终局部概率求和等价于对于网格中所有可能的路径概率求和，也就求出了给定隐马尔科夫模型(HMM)后的观察序列概率。</p>

<p>第3节给出了一个计算这些概率的动态示例。</p>

<h4 id="toc_20">2b.计算t=1时的局部概率alpha‘s</h4>

<p>我们按如下公式计算局部概率：</p>

<p>\[\alpha_t(j)= Pr( 观察状态\;|\;隐藏状态_j ) \times Pr(t时刻所有指向j状态的路径）\]</p>

<p>特别当t=1时，没有任何指向当前状态的路径。故t=1时位于当前状态的概率是初始概率，即Pr(state|t=1)=P(state)，因此，t=1时的局部概率等于当前状态的初始概率乘以相关的观察概率：</p>

<p>\[\alpha_1(j)=\pi(j)·b_{jk_i}\]</p>

<p>所以初始时刻状态j的局部概率依赖于此状态的初始概率及相应时刻我们所见的观察概率。</p>

<h4 id="toc_21">2c.计算t&gt;1时的局部概率alpha‘s</h4>

<p>我们再次回顾局部概率的计算公式如下：</p>

<p>\[\alpha_t(j)= Pr( 观察状态\;|\;隐藏状态_j ) \times Pr(t时刻所有指向j状态的路径）\]</p>

<p>我们可以假设（递归地），乘号左边项“Pr( 观察状态 | 隐藏状态j )”已经有了，现在考虑其右边项“Pr(t时刻所有指向j状态的路径）”。</p>

<p>为了计算到达某个状态的所有路径的概率，我们可以计算到达此状态的每条路径的概率并对它们求和，例如：</p>

<p><img src="./_resources/hmm11.gif" alt=""/></p>

<p>计算alpha所需要的路径数目随着观察序列的增加而指数级递增，但是t-1时刻alpha‘s给出了所有到达此状态的前一路径概率，因此，我们可以通过t-1时刻的局部概率定义t时刻的alpha‘s，即：</p>

<p><img src="./_resources/hmm12.gif" alt=""/></p>

<p>故我们所计算的这个概率等于相应的观察概率（亦即，t+1时在状态j所观察到的符号的概率）与该时刻到达此状态的概率总和——这来自于上一步每一个局部概率的计算结果与相应的状态转移概率乘积后再相加——的乘积。</p>

<p>注意我们已经有了一个仅利用t时刻局部概率计算t+1时刻局部概率的表达式。</p>

<p>现在我们就可以递归地计算给定隐马尔科夫模型(HMM)后一个观察序列的概率了——即通过t=1时刻的局部概率alpha‘s计算t=2时刻的alpha‘s，通过t=2时刻的alpha‘s计算t=3时刻的alpha‘s等等直到t=T。给定隐马尔科夫模型(HMM)的观察序列的概率就等于t=T时刻的局部概率之和。</p>

<h4 id="toc_22">2d.降低计算复杂度</h4>

<p>我们可以比较通过穷举搜索（评估）和通过递归前向算法计算观察序列概率的时间复杂度。</p>

<p>我们有一个长度为T的观察序列O以及一个含有n个隐藏状态的隐马尔科夫模型l=(pi,A,B)。</p>

<p>穷举搜索将包括计算所有可能的序列：<br/>
　　　<br/>
<img src="./_resources/hmm13.gif" alt=""/></p>

<p>公式</p>

<p><img src="./_resources/hmm14.gif" alt=""/></p>

<p>对我们所观察到的概率求和——注意其复杂度与T成指数级关系。相反的，使用前向算法我们可以利用上一步计算的信息，相应地，其时间复杂度与T成线性关系。</p>

<p>注：穷举搜索的时间复杂度是2TN<sup>T，前向算法的时间复杂度是N<sup>2T，其中T指的是观察序列长度，N指的是隐藏状态数目。</sup></sup></p>

<h3 id="toc_23">3.总结</h3>

<p>我们的目标是计算给定隐马尔科夫模型HMM下的观察序列的概率——Pr(observations |lamda)。</p>

<p>我们首先通过计算局部概率（alpha‘s）降低计算整个概率的复杂度，局部概率表示的是t时刻到达某个状态s的概率。</p>

<p>t=1时，可以利用初始概率(来自于P向量）和观察概率Pr(observation|state)（来自于混淆矩阵）计算局部概率；而t&gt;1时的局部概率可以利用t-时的局部概率计算。</p>

<p>因此，这个问题是递归定义的，观察序列的概率就是通过依次计算t=1,2,…,T时的局部概率，并且对于t=T时所有局部概率alpha‘s相加得到的。</p>

<p>注意，用这种方式计算观察序列概率的时间复杂度远远小于计算所有序列的概率并对其相加（穷举搜索）的时间复杂度。</p>

<p>我们使用前向算法计算T长观察序列的概率:</p>

<p><img src="./_resources/hmm15.gif" alt=""/></p>

<p>其中y的每一个是观察集合之一。局部（中间）概率(alpha‘s)是递归计算的，首先通过计算t=1时刻所有状态的局部概率alpha：</p>

<p><img src="./_resources/hmm16.gif" alt=""/></p>

<p>然后在每个时间点，t=2，… ，T时，对于每个状态的局部概率，由下式计算局部概率alpha:</p>

<p><img src="./_resources/hmm17.gif" alt=""/></p>

<p>也就是当前状态相应的观察概率与所有到达该状态的路径概率之积，其递归地利用了上一个时间点已经计算好的一些值。</p>

<p>最后，给定HMM,lamda,观察序列的概率等于T时刻所有局部概率之和：</p>

<p><img src="./_resources/hmm18.gif" alt=""/></p>

<p>再重复说明一下，每一个局部概率（t &gt; 2 时）都由前一时刻的结果计算得出。</p>

<p>对于“天气”那个例子，下面的图表显示了t = 2为状态为多云时局部概率alpha的计算过程。这是相应的观察概率b与前一时刻的局部概率与状态转移概率a相乘后的总和再求积的结果：</p>

<p><img src="./_resources/hmm19.gif" alt=""/></p>

<p>（注：本图及维特比算法4中的相似图存在问题，具体请见文后评论，非常感谢读者YaseenTA的指正）Rainy状态 α1( r )= πr *brw 就是括号里面(r)还有cw应该是rw。Cloudy 应该是α1( c )= 而不是 α1( r )=</p>

<h3 id="toc_24">总结（Summary）</h3>

<p>我们使用前向算法来计算给定隐马尔科夫模型（HMM）后的一个观察序列的概率。它在计算中利用递归避免对网格所有路径进行穷举计算。</p>

<p>给定这种算法，可以直接用来确定对于已知的一个观察序列，在一些隐马尔科夫模型（HMMs）中哪一个HMM最好的描述了它——先用前向算法评估每一个（HMM），再选取其中概率最高的一个。</p>

<h2 id="toc_25">六、维特比算法（Viterbi Algorithm）</h2>

<p>寻找最可能的隐藏状态序列(Finding most probable sequence of hidden states)</p>

<p>对于一个特殊的隐马尔科夫模型(HMM)及一个相应的观察序列，我们常常希望能找到生成此序列最可能的隐藏状态序列。</p>

<h3 id="toc_26">1.穷举搜索</h3>

<p>我们使用下面这张网格图片来形象化的说明隐藏状态和观察状态之间的关系：</p>

<p><img src="./_resources/hmm6.gif" alt=""/></p>

<p>我们可以通过列出所有可能的隐藏状态序列并且计算对于每个组合相应的观察序列的概率来找到最可能的隐藏状态序列。最可能的隐藏状态序列是使下面这个概率最大的组合：</p>

<p>Pr（观察序列|隐藏状态的组合）</p>

<p>例如，对于网格中所显示的观察序列，最可能的隐藏状态序列是下面这些概率中最大概率所对应的那个隐藏状态序列：<br/>
　　<br/>
Pr(dry,damp,soggy | sunny,sunny,sunny), Pr(dry,damp,soggy | sunny,sunny,cloudy), Pr(dry,damp,soggy | sunny,sunny,rainy), . . . .Pr(dry,damp,soggy | rainy,rainy,rainy)</p>

<p>这种方法是可行的，但是通过穷举计算每一个组合的概率找到最可能的序列是极为昂贵的。与前向算法类似，我们可以利用这些概率的时间不变性来降低计算复杂度。</p>

<h3 id="toc_27">2.使用递归降低复杂度</h3>

<p>给定一个观察序列和一个隐马尔科夫模型（HMM），我们将考虑递归地寻找最有可能的隐藏状态序列。我们首先定义局部概率delta,它是到达网格中的某个特殊的中间状态时的概率。然后，我们将介绍如何在t=1和t=n(&gt;1)时计算这些局部概率。</p>

<p>这些局部概率与前向算法中所计算的局部概率是不同的，因为它们表示的是时刻t时到达某个状态最可能的路径的概率，而不是所有路径概率的总和。<br/>
　　　　</p>

<h4 id="toc_28">2a.局部概率delta‘s和局部最佳途径</h4>

<p>考虑下面这个网格，它显示的是天气状态及对于观察序列干燥，湿润及湿透的一阶状态转移情况：</p>

<p><img src="./_resources/hmm8.gif" alt=""/></p>

<p>对于网格中的每一个中间及终止状态，都有一个到达该状态的最可能路径。举例来说，在t=3时刻的3个状态中的每一个都有一个到达此状态的最可能路径，或许是这样的：</p>

<p><img src="./_resources/hmm20.gif" alt=""/></p>

<p>我们称这些路径局部最佳路径(partial best paths)。其中每个局部最佳路径都有一个相关联的概率，即局部概率或delta。与前向算法中的局部概率不同，delta是到达该状态（最可能）的一条路径的概率。</p>

<p>因而delta(i,t)是t时刻到达状态i的所有序列概率中最大的概率，而局部最佳路径是得到此最大概率的隐藏状态序列。对于每一个可能的i和t值来说，这一类概率（及局部路径）均存在。</p>

<p>特别地，在t=T时每一个状态都有一个局部概率和一个局部最佳路径。这样我们就可以通过选择此时刻包含最大局部概率的状态及其相应的局部最佳路径来确定全局最佳路径（最佳隐藏状态序列）。</p>

<h4 id="toc_29">2b.计算t=1时刻的局部概率delta‘s</h4>

<p>我们计算的局部概率delta是作为最可能到达我们当前位置的路径的概率（已知的特殊知识如观察概率及前一个状态的概率）。当t=1的时候，到达某状态的最可能路径明显是不存在的；但是，我们使用t=1时的所处状态的初始概率及相应的观察状态k1的观察概率计算局部概率delta；即</p>

<p><img src="./_resources/hmm21.gif" alt=""/></p>

<p>——与前向算法类似，这个结果是通过初始概率和相应的观察概率相乘得出的。</p>

<h4 id="toc_30">2c.计算t&gt;1时刻的局部概率delta‘s</h4>

<p>现在我们来展示如何利用t-1时刻的局部概率delta计算t时刻的局部概率delta。</p>

<p>考虑如下的网格：</p>

<p><img src="./_resources/hmm22.gif" alt=""/></p>

<p>我们考虑计算t时刻到达状态X的最可能的路径；这条到达状态X的路径将通过t-1时刻的状态A，B或C中的某一个。</p>

<p>因此，最可能的到达状态X的路径将是下面这些路径的某一个</p>

<pre><code>　　　　　　　（状态序列），…，A，X
　　　　　　　（状态序列），…，B，X
或　　　　　　（状态序列），…，C，X
</code></pre>

<p>我们想找到路径末端是AX,BX或CX并且拥有最大概率的路径。</p>

<p>回顾一下马尔科夫假设：给定一个状态序列，一个状态发生的概率只依赖于前n个状态。特别地，在一阶马尔可夫假设下，状态X在一个状态序列后发生的概率只取决于之前的一个状态，即</p>

<p>Pr (到达状态A最可能的路径) · Pr (X | A) · Pr (观察状态 | X)</p>

<p>与此相同，路径末端是AX的最可能的路径将是到达A的最可能路径再紧跟X。相似地，这条路径的概率将是：</p>

<p>Pr (到达状态A最可能的路径) · Pr (X | A) · Pr (观察状态 | X)</p>

<p>因此，到达状态X的最可能路径概率是：</p>

<p><img src="./_resources/hmm23.gif" alt=""/></p>

<p>其中第一项是t-1时刻的局部概率delta，第二项是状态转移概率以及第三项是观察概率。</p>

<p>泛化上述公式，就是在t时刻，观察状态是kt，到达隐藏状态i的最佳局部路径的概率是：</p>

<p><img src="./_resources/hmm24.gif" alt=""/></p>

<p>这里，我们假设前一个状态的知识（局部概率）是已知的，同时利用了状态转移概率和相应的观察概率之积。然后，我们就可以在其中选择最大的概率了（局部概率delta）。</p>

<h4 id="toc_31">2d.反向指针，phi‘s</h4>

<p>考虑下面这个网格</p>

<p><img src="./_resources/hmm8.gif" alt=""/></p>

<p>在每一个中间及终止状态我们都知道了局部概率，delta(i,t)。然而我们的目标是在给定一个观察序列的情况下寻找网格中最可能的隐藏状态序列——因此，我们需要一些方法来记住网格中的局部最佳路径。</p>

<p>回顾一下我们是如何计算局部概率的，计算t时刻的delta‘s我们仅仅需要知道t-1时刻的delta‘s。在这个局部概率计算之后，就有可能记录前一时刻哪个状态生成了delta(i,t)——也就是说，在t-1时刻系统必须处于某个状态，该状态导致了系统在t时刻到达状态i是最优的。这种记录（记忆）是通过对每一个状态赋予一个反向指针phi完成的，这个指针指向最优的引发当前状态的前一时刻的某个状态。</p>

<p>形式上，我们可以写成如下的公式</p>

<p><img src="./_resources/hmm25.gif" alt=""/></p>

<p>其中argmax运算符是用来计算使括号中表达式的值最大的索引j的。</p>

<p>请注意这个表达式是通过前一个时间步骤的局部概率delta‘s和转移概率计算的，并不包括观察概率（与计算局部概率delta‘s本身不同）。这是因为我们希望这些phi‘s能回答这个问题“如果我在这里，最可能通过哪条路径到达下一个状态？”——这个问题与隐藏状态有关，因此与观察概率有关的混淆（矩阵）因子是可以被忽略的。</p>

<h4 id="toc_32">2e.维特比算法的优点</h4>

<p>使用Viterbi算法对观察序列进行解码有两个重要的优点：</p>

<ol>
<li>通过使用递归减少计算复杂度——这一点和前向算法使用递归减少计算复杂度是完全类似的。</li>
<li>维特比算法有一个非常有用的性质，就是对于观察序列的整个上下文进行了最好的解释（考虑）。事实上，寻找最可能的隐藏状态序列不止这一种方法，其他替代方法也可以，譬如，可以这样确定如下的隐藏状态序列：</li>
</ol>

<p><img src="./_resources/hmm26.gif" alt=""/></p>

<p>其中</p>

<p><img src="./_resources/hmm27.gif" alt=""/></p>

<p>这里，采用了“自左向右”的决策方式进行一种近似的判断，其对于每个隐藏状态的判断是建立在前一个步骤的判断的基础之上（而第一步从隐藏状态的初始向量pi开始）。</p>

<p>这种做法，如果在整个观察序列的中部发生“噪音干扰”时，其最终的结果将与正确的答案严重偏离。</p>

<p>相反，维特比算法在确定最可能的终止状态前将考虑整个观察序列，然后通过phi指针“回溯”以确定某个隐藏状态是否是最可能的隐藏状态序列中的一员。这是非常有用的，因为这样就可以孤立序列中的“噪音”，而这些“噪音”在实时数据中是很常见的。</p>

<h3 id="toc_33">3.小结</h3>

<p>维特比算法提供了一种有效的计算方法来分析隐马尔科夫模型的观察序列，并捕获最可能的隐藏状态序列。它利用递归减少计算量，并使用整个序列的上下文来做判断，从而对包含“噪音”的序列也能进行良好的分析。</p>

<p>在使用时，维特比算法对于网格中的每一个单元(cell)都计算一个局部概率，同时包括一个反向指针用来指示最可能的到达该单元的路径。当完成整个计算过程后，首先在终止时刻找到最可能的状态，然后通过反向指针回溯到t=1时刻，这样回溯路径上的状态序列就是最可能的隐藏状态序列了。</p>

<hr/>

<h3 id="toc_34">1、维特比算法的形式化定义</h3>

<p>维特比算法可以形式化的概括为：</p>

<p>对于每一个i，i = 1，… ，n，令：</p>

<p><img src="./_resources/hmm28.gif" alt=""/></p>

<p>——这一步是通过隐藏状态的初始概率和相应的观察概率之积计算了t=1时刻的局部概率。</p>

<p>对于t=2，…，T和i=1，…，n,令：</p>

<p><img src="./_resources/hmm29.gif" alt=""/></p>

<p>——这样就确定了到达下一个状态的最可能路径，并对如何到达下一个状态做了记录。具体来说首先通过考察所有的转移概率与上一步获得的最大的局部概率之积，然后记录下其中最大的一个，同时也包含了上一步触发此概率的状态。</p>

<p>令：</p>

<p><img src="./_resources/hmm30.gif" alt=""/></p>

<p>——这样就确定了系统完成时(t=T)最可能的隐藏状态。</p>

<p>对于t=T-1，…，1 令：</p>

<p><img src="./_resources/hmm31.gif" alt=""/></p>

<p>——这样就可以按最可能的状态路径在整个网格回溯。回溯完成时，对于观察序列来说，序列i1 … iT就是生成此观察序列的最可能的隐藏状态序列。</p>

<h3 id="toc_35">2.计算单独的delta‘s和phi‘s</h3>

<p>维特比算法中的局部概率delta‘s的计算与前向算法中的局部概率alpha‘s的很相似。下面这幅图表显示了delta‘s和phi‘s的计算细节，可以对比一下前向算法3中的计算局部概率alpha‘s的那幅图表：</p>

<p><img src="./_resources/hmm19.gif" alt=""/></p>

<p>（注：本图及维特比算法4中的相似图存在问题，具体请见文后评论，非常感谢读者YaseenTA的指正）Rainy状态 α1( r )= πr *brw 就是括号里面(r)还有cw应该是rw。Cloudy 应该是α1( c )= 而不是 α1( r )=</p>

<p>唯一不同的是前向算法中计算局部概率alpha‘s时的求和符号（Sigma）在维特比算法中计算局部概率delta‘s时被替换为max——这一个重要的不同也说明了在维特比算法中我们选择的是到达当前状态的最可能路径，而不是总的概率。我们在维特比算法中维护了一个“反向指针”记录了到达当前状态的最佳路径，即在计算phi‘s时通过argmax运算符获得。</p>

<h3 id="toc_36">总结(Summary)</h3>

<p>对于一个特定的隐马尔科夫模型，维特比算法被用来寻找生成一个观察序列的最可能的隐藏状态序列。我们利用概率的时间不变性，通过避免计算网格中每一条路径的概率来降低问题的复杂度。维特比算法对于每一个状态(t&gt;1)都保存了一个反向指针(phi)，并在每一个状态中存储了一个局部概率(delta)。</p>

<p>局部概率delta是由反向指针指示的路径到达某个状态的概率。</p>

<p>当t=T时，维特比算法所到达的这些终止状态的局部概率delta‘s是按照最优（最可能）的路径到达该状态的概率。因此，选择其中最大的一个，并回溯找出所隐藏的状态路径，就是这个问题的最好答案。</p>

<p>关于维特比算法，需要着重强调的一点是它不是简单的对于某个给定的时间点选择最可能的隐藏状态，而是基于全局序列做决策——因此，如果在观察序列中有一个“非寻常”的事件发生，对于维特比算法的结果也影响不大。</p>

<p>这在语音处理中是特别有价值的，譬如当某个单词发音的一个中间音素出现失真或丢失的情况时，该单词也可以被识别出来。</p>

<h2 id="toc_37">七、前向-后向算法(Forward-backward algorithm)</h2>

<p>根据观察序列生成隐马尔科夫模型(Generating a HMM from a sequence of obersvations)</p>

<p>与HMM模型相关的“有用”的问题是评估（前向算法）和解码（维特比算法）——它们一个被用来测量一个模型的相对适用性，另一个被用来推测模型隐藏的部分在做什么（“到底发生了”什么）。可以看出它们都依赖于隐马尔科夫模型（HMM）参数这一先验知识——状态转移矩阵，混淆（观察）矩阵，以及pi向量（初始化概率向量）。</p>

<p>然而，在许多实际问题的情况下这些参数都不能直接计算的，而要需要进行估计——这就是隐马尔科夫模型中的学习问题。前向-后向算法就可以以一个观察序列为基础来进行这样的估计，而这个观察序列来自于一个给定的集合，它所代表的是一个隐马尔科夫模型中的一个已知的隐藏集合。</p>

<p>一个例子可能是一个庞大的语音处理数据库，其底层的语音可能由一个马尔可夫过程基于已知的音素建模的，而其可以观察的部分可能由可识别的状态（可能通过一些矢量数据表示）建模的，但是没有（直接）的方式来获取隐马尔科夫模型（HMM）参数。</p>

<p>前向-后向算法并非特别难以理解，但自然地比前向算法和维特比算法更复杂。由于这个原因，这里就不详细讲解前向-后向算法了（任何有关HMM模型的参考文献都会提供这方面的资料的）。</p>

<p>总之，前向-后向算法首先对于隐马尔科夫模型的参数进行一个初始的估计（这很可能是完全错误的），然后通过对于给定的数据评估这些参数的的价值并减少它们所引起的错误来重新修订这些HMM参数。从这个意义上讲，它是以一种梯度下降的形式寻找一种错误测度的最小值。</p>

<p>之所以称其为前向-后向算法，主要是因为对于网格中的每一个状态，它既计算到达此状态的“前向”概率（给定当前模型的近似估计），又计算生成此模型最终状态的“后向”概率（给定当前模型的近似估计）。 这些都可以通过利用递归进行有利地计算，就像我们已经看到的。可以通过利用近似的HMM模型参数来提高这些中间概率进行调整，而这些调整又形成了前向-后向算法迭代的基础。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007151.html">
                
                  <h1>神经网络简史</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>自图灵提出“机器与智能”，一直就有两派观点，一派认为实现人工智能必须用逻辑和符号系统，这一派看问题是自顶向下的；还有一派认为通过仿造大脑可以达到人工智能，这一派是自底向上的，他们认定如果能造一台机器，模拟大脑中的神经网络，这台机器就有智能了。前一派，我想用“想啥来啥”来形容；后一派就称之为“吃啥补啥”，估计他们的思想来源于中国古代的原始思维，套一句庸俗的哲学词，前者偏唯心，后者偏唯物。这两派一直是人工智能领域里两个阶级、两条路线的斗争，这斗争有时还你死我活。</p>

<p>模拟神经网络的原创文章发表于1943年，两位作者都是传奇人物，麦卡洛可（McCulloch）和皮茨（Pitts)。话分两头。皮茨打小就喜欢数学和哲学，初中时还读过罗素的《数学原理》，还和罗素通信，罗素爱才，邀请他到英国跟随自己学习逻辑。但皮茨家里是苦出身，连高中都读不起，英国留学自然未果。他十五岁时，他爸强行要他退学上班，就像所有爱读书的穷孩子，皮茨一怒就离家出走了。他打听到偶像罗素那时要到芝加哥大学任教，就只身来到芝加哥，还真见到了罗素，老罗遂把他推荐给那时也在芝加哥任教的卡尔纳普。卡尔纳普想看看这孩子到底有多聪明，就把自己的《语言的逻辑句法》一书送给皮茨，没过一个月，皮茨就看完了，把写满笔记的原书还给卡尔纳普。老卡惊为天人，于是给他在芝加哥大学安排了份打扫卫生的工作。别看不起打扫卫生，电影《心灵捕手》（Good Will Hunting）里马特·达蒙饰演的角色也是在知名大学打扫卫生时，不小心解了道数学难题，引起老师的注意。扫马路至少可避免流浪街头。皮茨后来结识了也在芝加哥的麦卡洛可。沃伦-麦卡洛可比皮茨大一辈，他本科在耶鲁学哲学和心理学，后在哥伦比亚得了心理学硕士和医学博士（MD)，其实医学博士和哲学博士不是一回事，MD不是学术学位，属终极职业学位，和MBA、MFA差不多。MD的那个D是指“医生”，PhD的D才是博士。麦卡洛可毕业后做了几年实习医生，先去了耶鲁研究神经生理学，后又去了伊利诺伊大学芝加哥分校，做精神病学系的教授。麦卡洛可的强项是神经科学，但不懂数学，他和十七岁的流浪汉数学票友皮茨是绝配。他们合作的成果就是神经网络的第一篇文章：“A Logical Calculus of Ideas Immanent in Nervous Activity”, 发表在《数学生物物理期刊》上。这篇文章也成了控制论的思想源泉之一。</p>

<p>控制论的始作俑者诺伯特·维纳早年自称神童，他爸是哈佛教授，曾经带着他到英国见过罗素，但罗素特不喜欢这孩子和他爹。自打进入二十世纪后，甭管哪门哪派的学问，最后都能扯到罗素那儿，不想得诺贝尔文学奖的科学家都不是好情人。维纳后来也在哈佛任教，但不被主流数学家喜欢，没拿到终身教职。最后到了隔壁的麻省理工落脚，在二战时搞了点武器研究。那时最好的数学家和物理学家都参与了造原子弹的“曼哈顿”计划，维纳却没沾边。这也许同他的个性有关系，他的同事和家人都觉得他对数学之外的事情反应迟钝。维纳提出“控制论”后出了大名，在麻省理工搞了一大笔钱，麦卡洛可就带着皮茨等一票人马投奔维纳，有钱才能当老大，哪都一样。维纳的老婆玛格丽特是纳粹，在二战时，家里还偷藏了本英文版的希特勒的《我的奋斗》。那时他们的女儿芭芭拉正在读小学，有意无意也看过那书，写作文时居然引用书里的“警句”，差点被学校开除。麦卡洛可的老婆是犹太人，与玛格丽特形同水火。其实维纳祖上是波兰犹太人，玛格丽特早干啥去了？维纳娶玛格丽特是为了自嘲吗？就像很多中国男人讨洋老婆或老外娶中国剩女，图的不是相貌，是稀罕。反正最后维纳被中和为“不可知论者”（agnostic）。玛格丽特有次对维纳说麦卡洛可小组有人（可能暗指皮茨）勾引宝贝女儿芭芭拉，维纳大怒，随即断绝和麦克洛克及其学生的所有往来。现在看玛格丽特是有意造谣。但维纳的举动对皮茨造成巨大创伤，皮茨本来是维纳的特招学生（special student），但估计他年幼时受过挫折，秉性怪异。和维纳闹翻后，他拒绝麻省理工给他的研究生学位，对学问也心灰意冷。皮茨1969年比他的长辈麦卡洛可早几个月离世，只有四十六岁。<br/>
　<br/>
得维纳真传的人不多，不能不说一下迈克尔·阿比卜（Michael Arbib)。他二十三岁就在维纳手下得了PhD，他出名是那本科普书《大脑、机器和数学》。阿比卜后来创办了麻省大学的计算机系，并延揽一帮人工智能人马，其中有后来以“强化学习”出名的巴托（Andy Barto)，使麻省大学的人工智能一直处领先地位。阿比卜后来转往南加州大学，担任一堆系的教授，包括计算机、生物、生物医学工程、电气工程、神经科学、还有心理；他那名片要是印出来，估计很像中国的农民企业家，就差“政协委员”或“人大代表”了。阿比卜到南加州后，没出过什么有影响力的原创成果。在神经网络不景气时，巴托的“可适应学习实验室”曾经短期收容了很多人，其中就有后来的大佬级人物，如乔丹（Michael Jordan），乔丹在伯克利时又培养了Andrew Ng等一干人马，那是后话。<br/>
　　<br/>
1949年，神经心理学家Hebb出版《行为组织学》（Organization of Behavior)，在该书中，Hebb提出了被后人称为“Hebb规则”的学习机制。这个规则认为如果两个细胞总是同时激活的话，它们之间就有某种关联，同时激活的概率越高，关联度也越高。换句话说，就是“吃啥补啥”。2000年诺贝尔医学奖得主肯德尔（Eric Kandel）的动物实验也证实了Hebb规则。后来的各种无监督机器学习算法或多或少都是Hebb规则的变种。</p>

<p>神经网络研究的后一个大突破是1957年。康奈尔大学的实验心理学家弗兰克·罗森布拉特在一台IBM-704计算机上模拟实现了一种他发明的叫作“感知机”（Perceptron）的神经网络模型。这个模型可以完成一些简单的视觉处理任务。这引起了轰动。罗森布拉特在理论上证明了单层神经网络在处理线性可分的模式识别问题时，可以收敛，并以此为基础，做了若干“感知机”有学习能力的实验。罗森布拉特1962年出了本书：《神经动力学原理：感知机和大脑机制的理论》（Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms），这书总结了他的所有研究成果，一时成为“吃啥补啥”派的圣经。罗森布拉特的名声越来越大，得到的研究经费也越来越多。国防部和海军都资助了他的研究工作。媒体对罗森布拉特也表现出了过度的关注。毕竟，能够构建一台可以模拟大脑的机器，当然是一个头版头条的抢眼消息。此时的罗森布拉特也一改往日的害羞，经常在媒体出镜，他开跑车、弹钢琴，到处显摆。这使得另一派的人相当不爽。<br/>
　　<br/>
明斯基是人工智能的奠基人之一，是达特茅斯会议的组织者。明斯基在一次会议上和罗森布拉特大吵，他认为神经网络不能解决人工智能的问题。随后，明斯基和麻省理工学院的另一位教授佩普特合作，企图从理论上证明他们的观点。他们合作的成果就是那本影响巨大、“是也非也”的书：《感知机：计算几何学》（Perceptrons: An Introduction to Computational Geometry)。在书中，明斯基和佩普特证明单层神经网络不能解决XOR（异或）问题。异或是一个基本逻辑问题，如果这个问题都解决不了，那神经网络的计算能力实在有限。其实罗森布拉特也已猜到“感知机”可能存在限制，特别是在“符号处理”方面，并以他神经心理学家的经验指出，某些大脑受到伤害的人也不能处理符号。但“感知机”的缺陷被明斯基以一种敌意的方式呈现，当时对罗森布拉特是致命打击。所有原来的政府资助机构也逐渐停止对神经网络的研究。1971年，罗森布拉特四十三岁生日那天，在划船时淹死。很多人认为他是自杀。王国维沉湖时遗言“经此世变，义无再辱”，在罗森布拉特，我猜“辱”是明斯基的书，“世变”是随后“神经网络”学科的消沉。不同的是，王静安谓之“世变”是历史潮流，但神经网络学科十年后会逆袭。<br/>
　　<br/>
表面是科学，但有证据表明明斯基和罗森布拉特以前就有瓜葛。他们是中学同学。布朗克斯（Bronx）科学高中大概是全世界最好的高中，毕业生里出过八个诺贝尔奖、六个普利策奖、一个图灵奖。远的不说，明斯基是1945年毕业生，而罗森布拉特是1946年毕业生。美国高中学制四年，明斯基和罗森布拉特至少有两年重叠，而且彼此认识，互相嫉妒。1956年的达特茅斯会议定义了“人工智能”这个词，会议的组织者包括明斯基、麦卡锡和香农等，参会者还有司马贺，纽威尔等。这个会议在定义“人工智能”领域时只是提到了神经网络。那时明斯基是神经网络的支持者。他1954年在普林斯顿的博士论文题目是“神经-模拟强化系统的理论，及其在大脑模型问题上的应用”（Theory of Neural-Analog Reinforcement Systems and its Application to the Brain-Model Problem），实际是一篇关于神经网络的论文。他晚年接受采访时开玩笑说，那篇三百多页的博士论文从来没正式发表过，大概只印了三本，他自己也记不清内容了。貌似他想极力开脱自己和神经网络学科的千丝万缕的关系。达特茅斯会议的主题并不是神经网络，而是后来被纽维尔和司马贺称为“物理符号系统”的东西，也就是说达特茅斯会议，“想啥来啥”派是主要基调。<br/>
　　<br/>
罗森布拉特被比他大一岁的明斯基妒忌是自然的。工作上，明斯基所负责的麻省理工学院的人工智能实验室也在向国防部和海军申请经费。大多数的圈内科学家，对罗森布拉特突然被塑造的明星范儿很反感。明斯基早期也是“吃啥补啥”派出身，但此时已经改为“想啥来啥”派了。由于他和佩普特对感知机的批判，俩人后来被“吃啥补啥”派称为“魔鬼搭档”。其实明斯基认识佩普特结识还是通过麦卡洛克的介绍，历史真是纠结。被称“魔鬼”是因为《感知机》第一版有言：“罗森布拉特的论文大多没有科学价值。”这话跳步确实有点大，但罗森布拉特人缘不好，没有得到同行的支持。<br/>
　　<br/>
比罗森布拉特小一岁的维德罗（Widrow）是斯坦福大学教授，在罗森布拉特刚提出“感知机”时，就提出了Adaline可适应性算法。Adaline和感知机很相似，也是机器学习的鼻祖模型之一。罗森布拉特享受盛誉时，维德罗也沾了光，但在罗森布拉特死后，他却并没有被非难。维德罗在几十年后回忆说，那是因为他后来主要在电机系（EE）做集成电路的工作，而不是在计算机系里从事派系繁杂的人工智能研究，圈子不同，老死不相往来。</p>

<p>感知机的失败导致神经网络研究的式微，用加州理工学院的集成电路大佬米德（Carver Mead）的话说是“二十年大饥荒”。明斯基在《感知机》一书再版时，删除了原版中对罗森布拉特的个人攻击的句子，并手写了“纪念罗森布拉特”（In memory of Frank Rosenblatt）。但其他在“大饥荒”时期受到压迫的科学家认为明斯基不可原谅，后来神经网络得势后，这些人纷纷对明斯基口诛笔伐。美国电气电子工程师协会（IEEE）于2004年设立了罗森布拉特奖，以奖励在神经网络领域的杰出研究。</p>

<p>在信息科学和神经科学的结合部的失败，并没有影响到神经生物学内部。哈佛神经生物学家胡贝尔（Hubel）和威瑟尔（Wiesel）对视网膜和视皮层（visual cortex）中神经细胞的信息处理模式做了深入研究，他们为此获得1981年的诺贝尔医学奖。随后，麻省理工学院英年早逝的大卫·马尔（Marr）为视觉信息处理建立数学模型，影响了后来连接主义的运动。威瑟尔后来离开哈佛去了洛克菲勒大学。1991年洛克菲勒大学时任校长大卫·巴尔的摩出了学术丑闻被迫辞职后，威瑟尔出任洛克菲勒校长，为把那所学校建成生物学的重镇做出贡献。<br/>
　　<br/>
1974年，哈佛的一篇博士论文证明了在神经网络多加一层，并且利用“后向传播”（Back-propagation）学习方法，可以解决XOR问题。这篇论文的作者是沃波斯（Werbos），他后来得到了IEEE神经网络学会的先驱奖。沃波斯这篇文章刚发表时并没引起多少重视，那时正是神经网络研究的低谷，文章不合时宜。</p>

<p>神经网络在1980年代的复兴归功于物理学家霍普菲尔德（Hopfield）。1982年，那时在加州理工担任生物物理教授的霍普菲尔德，提出了一种新的神经网络，可以解决一大类模式识别问题，还可以给出一类组合优化问题的近似解。这种神经网络模型后被称为霍普菲尔德网络。1984年，霍普菲尔德用模拟集成电路实现了自己提出的模型。霍老也培养了一批后起之秀，包括现在在生物学重镇Salk研究所担任计算神经生物学实验室主任的Terry Sejnowski。霍老后转往普林斯顿担任分子生物学教授，现已退休。霍普菲尔德模型的提出振奋了神经网络领域。一帮早期神经网络研究的幸存者，在生物学家克里克（Crick，对，就是发明DNA双螺旋的那位诺贝尔奖得主）和认知科学大佬唐·诺曼（Don Norman）的鼓励下，以加州大学圣地亚哥分校为基地，开始了“连接主义”（Connectionism）运动，这个运动的领导者是两位心理学家鲁梅尔哈特（Rumelhart）和麦克利兰德（McLelland），外加一位计算机科学家辛顿（Geoffrey Hinton）。</p>

<p>连接主义运动的成果之一就是那本著名的被称为PDP（Parallel and Distributed Processing)的文集（分两卷 )。此书的出版给认知科学和计算机科学吹了股大风，被后起的神经网络新秀们成为圣经。“神经网络”在八十年代就像九十年代的互联网，后来的Web2.0，和眼下的“大数据”。谁都想套套近乎。一些做理论的大佬也不能免俗，发明RSA算法的R（Rivest）也带了几个学生转做神经网络学习问题的复杂性。一时间红旗不倒，彩旗飘飘，好不热闹。1993年，美国电气电子工程师学会IEEE开始出版《神经网络会刊》，为该领域的高质量文章提供出版渠道。美国国防部和海军、能源部等也加大资助力度。神经网络一下子成了显学。<br/>
　　<br/>
连接主义运动也培养了一堆新人，并使得加州大学圣地亚哥分校的认知科学系成为同类系科的佼佼者。鲁梅尔哈特后转往斯坦福大学任教，前年不幸死于已挣扎多年的神经退化疾病。乔丹就是他的学生，而Andrew Ng( 吴恩达)又是乔丹的学生，鲁梅尔哈特人虽离世，但香火没灭。他的另一名学生Robert Glushko后来远离本行，跟随硅谷互联网早期英雄马蹄塔南鲍姆（Marty Tennenbaum,据说马蹄的儿子都在麻省理工当教授了），创立了一家XML公司，那家公司后来卖给Commerce One，赚了一票钱。Glushko捐钱设立了“鲁梅尔哈特奖”来奖励神经网络的研究者，辛顿成了第一位获奖者。麦克利兰德则先转往卡内基梅隆担任计算机和心理两系教授，后来也到斯坦福，在那里建立了“心、脑、计算研究中心”，一度还担任心理系主任。</p>

<p>辛顿则先转往卡内基梅隆，最终到加拿大多伦多大学计算机系任教。辛顿现在可是神经网络最牛的人了。他还有一段不太为外人所知的革命家史：他是布尔的外曾曾孙子（对，就是“布尔代数”的那个布尔），他曾祖母Ellen是布尔的女儿。中国革命的参与者、美国铁杆左派韩丁和寒春（William and Joan Hinton）也是Ellen的孙子孙女，照这么说韩丁是辛顿的堂叔，寒春是辛顿的堂姑。布尔的小女儿、Ellen的妹妹伏尼契（Ethel Lilian Voynich）是传遍苏联和中国的小说《牛虻》的作者。《牛虻》西方不亮东方亮，在苏联和中国是几代人的革命加爱情励志畅销书。晚年在纽约生活陷入困顿的伏尼契，靠了苏联和周恩来特批的中国的意外稿费得以善终。这一家子把中国、苏联、革命、逻辑和神经网络都联系起来了，通吃“吃啥补啥”派和“想啥来啥”派。智力题：伏尼契和辛顿是啥关系。<br/>
　　<br/>
语言学家、公共知识分子斯蒂夫·平克对连接主义不以为然。鲁梅尔哈特和麦克利兰德在PDP圣经中合作了一章，讲神经网络可以学会动词的过去式，比如一看start，就知道started，一看come就知道came等等。平克认为有规则的过去式（直接加ed的，如started）可以通过简单计算得来；而不规则的（不通过加ed的，如came）则是存在大脑的一个特定区域。平克引用神经心理学的证据指出处理规则的和不规则的操作是在大脑不同部位完成的，他还认为神经网络的行为和一类大脑受伤害患失语症的病人的行为相似。其实这种观察并不深刻，都是罗森布拉特三十年前玩剩下的。符号系统可能比较适合处理规则的情况，而神经网络可能更适合不规则的情况，这个一般人都能想到。对神经网络派的批评也如此：我们可以定义一个规则，可以用符号系统实现也可以用神经网络实现。哪个快用哪个。<br/>
　　<br/>
符号处理和神经网络的方法论之争有时会被更大地夸张。伟大的乔姆斯基就不认可人工智能领域的最新进展。机器翻译历来是人工智能的试金石之一，就像在1996年之前的计算机下棋。机器翻译的早期实践都源于乔姆斯基的理论，但近来的突破却是基于统计的方法。乔姆斯基认为统计的方法不“优雅”（elegant），只是模仿而不是理解。会骑自行车不算理解，对自行车为什么不倒，能说三道四，才算理解。谷歌的研发总监彼特·诺维格为统计方法辩护时说：简单的模型（如乔姆斯基理论，以及后来的各种改进版本）不能解决复杂的问题，人工智能的进一步发展必须两条腿走路。诺维格在加入谷歌之前曾是加州大学伯克利分校的计算机教授，他对两派都了如指掌，在学术界和工业界都被尊重，他写的《人工智能》是最流行的教科书。他的观点似乎被更多的人接受。<br/>
　　<br/>
神经网络在八十年代的光芒被后来的互联网掩盖了。但这几年又恰恰是互联网给了神经网络更大的机会。这几年计算机科学最火的词儿就是“深度学习”。神经网络由一层一层的神经元构成。层数越多，就越深，所谓深度学习就是用很多层神经元构成的神经网络达到机器学习的功能。辛顿就是“深度学习”的始作俑者，他2006年的一篇文章开辟了这个新领域。最新的深度神经网络的最后两层的每个节点都可对应于某些概念。这是神经网络的一大进步，貌似为“吃啥补啥”找到了科学根据，调和了与“符号派”的矛盾。至于符号派买不买账是另一回事。深度学习的实测效果很好。辛顿最早用来做图像识别，而后来微软用深度学习还开发可实用的语音识别和同声翻译系统。<br/>
　　<br/>
年过六十的辛顿不甘寂寞，和他的两个学生开了家专注深度学习的公司。公司成立没多长时间，谷歌和微软就对这家公司动了收购的念头，后来百度也加入竞标，最终花落谷歌，谷歌出了几千万美元于2013年初收购了这家只有三名员工的公司。为了把辛顿纳入花名册，谷歌还真不差钱。<br/>
　　<br/>
2012年，斯坦福大学人工智能实验室主任Andrew Ng（吴恩达）和谷歌合作建造了一个当时最大的神经网络，这是谷歌神秘的X实验室的一个计划。网络上一度疯传的谷歌猫脸识别就是用的这个参数多达十七亿的神经网络。后来Ng自己在斯坦福又搞了个更大的神经网络，参数更高达一百一十二亿。人脑的神经连接有一百万万亿个。从计算能力上说，如果这个人工神经网络要是能接近大脑，每个人工神经元必须能达到一万个大脑神经元的功能。这个神经网络会用到大量的图形处理芯片GPU，GPU是模拟神经网络的完美硬件，因为每个GPU芯片内都有大量的小核心。这和神经网络的大规模并行性天然相似。硬件的进步让以往不可能的成为可能。<br/>
　　<br/>
斯坦福大学人工智能实验室的创办人约翰·麦卡锡，是达特茅斯会议的主要组织者，“人工智能”这个词如果不是他最早提出的，至少是他最早使之流行的。也正是他把明斯基拉到他当时任教的麻省理工。说他是人工智能之父是名副其实，约翰大叔是铁杆的符号派。但现任的人工智能实验室主任却是神经网络的大拿Andrew Ng。这个转变也许是个“吃啥补啥”派得志的风向标。斯坦福的这个神经网络的目标是模拟人的大脑。这让我们不禁想起了罗森布拉特，那不正是他的梦想吗？</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007085.html">
                
                  <h1>Hidden Markov Model</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">Markov Model</h2>

<p>A1 -&gt; A2 -&gt; A3 ···&gt; Ai -&gt; Ai+1 ···&gt; An -&gt;</p>

<p>M 个离散结点形成一条链</p>

<ul>
<li>若每个结点有 K 个状态，则需要 K-1 + (M-1)K(K-1) 个参数，O(M)</li>
<li>如果是全连接，则需要 K<sup>M</sup> -1 个参数，O(K<sup>M</sup> )</li>
</ul>

<p>A1 会有 K 个变化，比方当 A1=1 时，需要给出 A2 = i 这么多个参数, i 为 (0,k)，所以是 K(K-1) 个参数</p>

<p>链状模型可以极大减少我们需要学习的参数的数目</p>

<p>若状态 Ai 确定，则 Ai+1 只与 Ai 有关，与 A1,...,Ai-1 无关，伪随机过程</p>

<p>\[p(\theta^{t+1}\;|\;\theta^{(1)},\theta^{(2)},...,\theta^{(t)})=p(\theta^{t+1}\;|\;\theta^{(t)})\]</p>

<p>例子：C 语言中的伪随机函数使用的是 Markov Model，实际上只要知道第 i 个随机数，就可以计算出第 i+1 个随机数</p>

<p>满足 Markov 模型的样本点 s1,s2...sn 与 |『独立同分布』只弱一点：样本间只有相邻元素有相关关系，并且，有些以『独立同分布』为条件的定理，是可以放松到 Markov Process 的。例如：大数定理。</p>

<h2 id="toc_1">Hidden Markov Model</h2>

<p>HMM 是关于时序的概率模型，描述由一个隐藏的 Markov Chain 随机生成的不可观测的状态最忌序列，再有各个状态生成一个观测二产生观测随机序列的过程。</p>

<p>HMM 随机生成的状态序列，称为状态序列；每个状态生成一个观测，由此产生的光测随机序列，称为观测序列。序列的每个位置可以看做是一个时刻</p>

<p>\[<br/>
z_1 \to z_2 \to \dots \to z_{n-1} \to z_n \to z_{n+1} \to \\<br/>
\;\;\downarrow \; \; \quad \;\downarrow \qquad  \qquad \downarrow \qquad \; \downarrow \qquad \downarrow \qquad \\ <br/>
x_1 \;\quad x_2 \;\quad \;\quad \;\quad x_{n-1} \;\quad x_n \;\quad x_{n+1} \quad<br/>
\]</p>

<p>在 z1, z2 不可观察的前提下</p>

<ul>
<li>x1 和 z2 独立吗？不独立</li>
<li>x1 和 x2 独立吗？不独立</li>
</ul>

<h2 id="toc_2">HMM 的确定</h2>

<p>由出事概率分布 \(\pi\)，状态转移分布 A 以及观测概率分布 B 确定。</p>

<p>\[\lambda=(A,B,\pi)\]</p>

<p>假设我们的 HMM 模型如下</p>

<p>\[<br/>
z_1 \to z_2 \to \dots \to z_{n-1} \to z_n \to z_{n+1} \to \\<br/>
\;\;\downarrow \; \; \quad \;\downarrow \qquad  \qquad \downarrow \qquad \; \downarrow \qquad \downarrow \qquad \\ <br/>
x_1 \;\quad x_2 \;\quad \;\quad \;\quad x_{n-1} \;\quad x_n \;\quad x_{n+1} \quad<br/>
\]</p>

<ul>
<li>Q 是所有可能的状态的集合

<ul>
<li>N 是可能的状态数目</li>
<li>\(Q=\{q_1,q_2,\dots,q_N\}\)</li>
</ul></li>
<li>V 是所有可能的观测的集合

<ul>
<li>M 是可能的观测数</li>
<li>\(V=\{v_1,v_2,\dots,v_M\}\)</li>
</ul></li>
</ul>

<p>I 是长度为 T 的状态序列，O 是对应的观测序列</p>

<p>\[<br/>
I = \{i_1,i_2,\dots,i_T \} \\<br/>
O = \{o_1,o_2,\dots,o_T\}<br/>
\]</p>

<p><strong>A 是状态转移概率矩阵</strong></p>

<p>\[<br/>
A=[a_{ij}]_{N \times N} \\<br/>
a_{ij}=P(i_{t+1}\;|\;i_t = q_i)<br/>
\] </p>

<p>\(a_{ij}\) 是在时刻 t 处于 状态 \(q_i\) 的条件下时刻 t+1 转移到概率 \(q_j\) 的概率</p>

<p><strong>B 是观测概率矩阵</strong></p>

<p>\[<br/>
B=[b_{ik}]_{N\times M} \\<br/>
b_{ik}=P(o_t = v_k \;|\; i_t = q_i)<br/>
\]</p>

<p>\(b_{ik}\) 是在时刻 t 处于状态 \(q_i\) 的条件下生成观测 \(v_k\) 的概率</p>

<p><strong>\(\pi\) 是初始状态概率向量</strong></p>

<p>\[<br/>
\pi=(\pi_i) \\<br/>
\pi_i = P(i_1 = q_i)<br/>
\]</p>

<p>\(\pi_i\) 是时刻 t=1 处于状态 \(q_i\) 的概率</p>

<h2 id="toc_3">两个基本性质</h2>

<p>\[<br/>
z_1 \to z_2 \to \dots \to z_{n-1} \to z_n \to z_{n+1} \to \\<br/>
\;\;\downarrow \; \; \quad \;\downarrow \qquad  \qquad \downarrow \qquad \; \downarrow \qquad \downarrow \qquad \\ <br/>
x_1 \;\quad x_2 \;\quad \;\quad \;\quad x_{n-1} \;\quad x_n \;\quad x_{n+1} \quad<br/>
\]</p>

<p><strong>齐次假设</strong></p>

<p>\[P(i_t\;|\;i_{t-1},o_{t-1},i_{t-2},o_{t-2},\dots,i_1,o_1)=P(i_t\;|\;i_{t-1})\]</p>

<p>这里 \(i_t\) 对应 \(z_n\) 输入的概率，\(o_{t-1}\) 这些对应 \(x_{n-1}\) 的观测，也就是说，\(z_n\) 的状态实际上只由 \(z_{n-1}\) 决定</p>

<p><strong>观测独立性假设</strong></p>

<p>\[P(o_t\;|\;i_t,i_{t-1},o_{t-1},i_{t-2},o_{t-2},\dots,i_1,o_1)=P(o_t\;|\;i_t)\]</p>

<p>也就是说在时刻 t，得到观测 \(o_t\) 的概率只跟 \(i_t\) 有关（通过查 B 矩阵即可）</p>

<h2 id="toc_4">举例</h2>

<p>假设有 3 个盒子，编号为 1 2 3，每个盒子都装有红白两种颜色的小球</p>

<table>
<thead>
<tr>
<th style="text-align: center">盒子号</th>
<th style="text-align: center">1</th>
<th style="text-align: center">2</th>
<th style="text-align: center">3</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">红球</td>
<td style="text-align: center">5</td>
<td style="text-align: center">4</td>
<td style="text-align: center">7</td>
</tr>
<tr>
<td style="text-align: center">白球</td>
<td style="text-align: center">5</td>
<td style="text-align: center">6</td>
<td style="text-align: center">3</td>
</tr>
</tbody>
</table>

<p>按照下面的方法抽取小球，得到球颜色的观测序列：</p>

<ul>
<li>按照 \(\pi=(0.2,0.4,0.4)\) 来选择一个盒子，抽取一个球后放回</li>
<li>按某条件概率选择新的盒子，重复上述过程</li>
<li>最终得到观测序列：红红白白红</li>
</ul>

<h3 id="toc_5">各个参数</h3>

<ul>
<li>状态集合：Q={盒子1，盒子2，盒子3}</li>
<li>观测集合：V={红，白}</li>
<li>状态序列和观测序列的长度 T=5</li>
<li>初始概率分布 \(\pi=(0.2,0.4,0.4)\)</li>
<li>状态转移概率分布 A</li>
<li>观测概率分布 B (一行是一个分布)</li>
</ul>

<p>\(<br/>
\pi=\left( \begin{array}{c}<br/>
0.2 \\<br/>
0.4 \\<br/>
0.4<br/>
\end{array}\right)<br/>
\quad\) \(<br/>
A=\left( \begin{matrix}<br/>
0.5 &amp; 0.2 &amp; 0.3 \\<br/>
0.3 &amp; 0.5 &amp; 0.2 \\<br/>
0.2 &amp; 0.3 &amp; 0.5<br/>
\end{matrix}\right)<br/>
\quad\) \(<br/>
B=\left( \begin{matrix}<br/>
0.5 &amp; 0.5 \\<br/>
0.4 &amp; 0.6 \\<br/>
0.7 &amp; 0.3<br/>
\end{matrix}\right)<br/>
\)</p>

<h2 id="toc_6">三个基本问题</h2>

<p><strong>概率计算问题</strong></p>

<p>给定模型 \(\lambda=(A,B,\pi)\) 和观测序列 \(O=\{o_1,o_2,\dots,o_T\}\)，计算模型 \(\lambda\) 下观测序列 O 出现的概率 \(P(O\;|\;\lambda)\)</p>

<p><strong>学习问题</strong></p>

<p>已知观测序列 \(O=\{o_1,o_2,\dots,o_T\}\)，估计模型 \(\lambda=(A,B,\pi)\) 的参数，使得在该模型下观测序列 \(P(O\;|\;\lambda)\) 最大</p>

<p><strong>预测问题</strong></p>

<p>即解码问题，已知模型 \(\lambda=(A,B,\pi)\) 和观测序列 \(O=\{o_1,o_2,\dots,o_T\}\)，求对给定观测序列条件概率 \(P(I\;|\;O)\) 最大的状态序列 \(I\)。</p>

<h2 id="toc_7">概率计算问题</h2>

<p><strong>直接计算法</strong></p>

<p>按照概率公式，列举所有可能的长度为 T 的状态序列 \(I=\{i_1,i_2,\dots,i_T\}\)，求各个状态序列 \(I\) 与观测序列 \(O=\{o_1,o_2,\dots,o_T\}\) 的联合概率 \(P(O,I\;|\;\lambda)\)，然后对所有可能的状态求和，从而得到 \(P(O\;|\;\lambda)\)</p>

<p>状态序列 \(I=\{i_1,i_2,\dots,i_T\}\) 的概率是：</p>

<p>\[P(I\;|\;\lambda)=\pi_{i_1}a_{i_1i_2}a_{i_2i_3}\dots a_{i_{T-1}i_T}\]</p>

<p>对固定的状态序列 \(I\)，观测序列 \(O\) 的概率是</p>

<p>\[P(O\;|\;I,\lambda)=b_{i_1o_1}b_{i_2o_2}\dots b_{i_To_T}\]</p>

<p>O 和 I 同时出现的联合概率</p>

<p>\[<br/>
P(O,I\;|\;\lambda)=P(O\;|\;I,\lambda)P(I\;|\;\lambda) \\<br/>
=\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}a_{i_2i_3}\dots a_{i_{T-1}i_T}b_{i_To_T} <br/>
\]</p>

<p>对所有可能的状态序列 \(I\) 求和，得到观测序列 O 的概率 \(P(O\;|\;\lambda)\)</p>

<p>\[<br/>
P(O\;|\;\lambda)=\sum_{I}P(O,I\;|\;\lambda)=\sum_{I}P(O\;|\;I,\lambda)P(I\;|\;\lambda) \\<br/>
=\sum_{i_1,i_2,\dots,i_T}\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}a_{i_2i_3}\dots a_{i_{T-1}i_T}b_{i_To_T} <br/>
\]</p>

<p>分析：加和符号中有 2T 个因子，I 的遍历个数为 \(N^T\)，时间复杂度为 O(T N<sup>T</sup> )，复杂度过高</p>

<h3 id="toc_8">前向算法</h3>

<p>定义：给定 \(\lambda\)，定义到时刻 t，部分观测序列为 \(o_1,o_2,\dots,o_t\) 且隐状态为 \(q_i\) 的概率为 <strong>前向概率</strong>，记作</p>

<p>\[\alpha_t(i)=P(o_1,o_2,\dots,o_t,i_t=q_i\;|\;\lambda)\]</p>

<p>可以递推计算前向概率 \(\alpha_t(i)\) 以及观测序列概率 \(P(O\;|\;\lambda)\)</p>

<p>初值：\(\alpha_1(i)=\pi_ib_{io_1}\)</p>

<p>递推，对于 \(t=1,2,\dots,T-1\)，这里的 \(a_{ji}\) 是矩阵 A 中从状态 j 转移到状态 i 的值</p>

<p>\[\alpha_{t+1}(i)=\left(\sum_{j=1}^{N}\alpha_t(j)a_{ji}\right)b_{io_{t+1}} \]</p>

<p>最终</p>

<p>\[P(O\;|\;\lambda)=\sum_{i=1}^{N}\alpha_T(i)\]</p>

<p>前向概率算法的时间复杂度是 O(TN<sup>2</sup> )</p>

<h4 id="toc_9">例子</h4>

<p>还是用刚才的小球的例子，计算观测向量 O=红白红 的出现概率，其中</p>

<p>\(<br/>
\pi=\left( \begin{array}{c}<br/>
0.2 \\<br/>
0.4 \\<br/>
0.4<br/>
\end{array}\right)<br/>
\quad\) \(<br/>
A=\left( \begin{matrix}<br/>
0.5 &amp; 0.2 &amp; 0.3 \\<br/>
0.3 &amp; 0.5 &amp; 0.2 \\<br/>
0.2 &amp; 0.3 &amp; 0.5<br/>
\end{matrix}\right)<br/>
\quad\) \(<br/>
B=\left( \begin{matrix}<br/>
0.5 &amp; 0.5 \\<br/>
0.4 &amp; 0.6 \\<br/>
0.7 &amp; 0.3<br/>
\end{matrix}\right)<br/>
\)</p>

<p>计算初值，\(o_1\)表示红色，\(o_2\)表示白色</p>

<p>\[<br/>
\alpha_1(盒子1)=\pi_1b_{1o_1}=0.2\times0.5=0.1 \\<br/>
\alpha_1(盒子2)=\pi_2b_{2o_1}=0.4\times0.4=0.16 \\<br/>
\alpha_1(盒子3)=\pi_3b_{2o_1}=0.4\times0.7=0.28<br/>
\]</p>

<p>递推</p>

<p>\[<br/>
\begin{align*} <br/>
\alpha_2(i=1)&amp;=\left(\sum_{j=1}^{N}\alpha_1(j)a_{j1}\right)b_{1o_2} \\<br/>
&amp;= (0.1\times0.5+0.16\times0.3+0.28\times0.2)\times0.5 \\ <br/>
&amp;= 0.077<br/>
\end{align*} <br/>
\]</p>

<p>\[<br/>
\alpha_2(2)=0.1104 \\<br/>
\alpha_2(3)=0.606<br/>
\]</p>

<p>\[<br/>
\alpha_3(1)=0.04187 \\<br/>
\alpha_3(2)=0.03551 \\<br/>
\alpha_3(3)=0.05284<br/>
\]</p>

<p>最终</p>

<p>\[<br/>
\begin{align*} <br/>
P(O\;|\;\lambda)&amp;=\sum_{i=1}^{3}\alpha_3(i) \\<br/>
&amp;= 0.04187+0.03551+0.05284 \\ <br/>
&amp;= 0.13022<br/>
\end{align*} <br/>
\]</p>

<p>更通用的就是 </p>

<p>\[<br/>
P(O\;|\;\lambda)=\sum_{i=1}^{N}\alpha_T(i)<br/>
\]</p>

<h2 id="toc_10">后向算法</h2>

<p>定义：给定 \(\lambda\)，定义到时刻 t 隐状态为 \(q_i\) 的前提下，从 t+1 到 T 的部分观测序列概率为 \(o_{t+1},o_{t+2},\dots,o_T\) 的概率为<strong>后向概率</strong>，记作</p>

<p>\[\beta_t(i)=P(o_{t+1},o_{t+2},\dots,o_T\;|\;i_t=q_i,\lambda)\]</p>

<p>可以递推计算前向概率 \(\beta_t(i)\) 以及观测序列概率 \(P(O\;|\;\lambda)\)</p>

<p>初值：\(\beta_T(i)=1\)</p>

<p>递推，对于 \(t=T-1,T-2,\dots,1\)，这里的 \(a_{ij}\) 是矩阵 A 中从状态 i 转移到状态 j 的值</p>

<p>\[\beta_{t}(i)=\left(\sum_{j=1}^{N}a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)\right) \]</p>

<p>最终</p>

<p>\[P(O\;|\;\lambda)=\sum_{i=1}^{N}\pi_ib_{io_1}\beta_1(i)\]</p>

<p>为了计算在时刻 t 隐状态为 \(q_i\) 条件下，时刻 t+1 之后观测序列为 \(o_{t+1},o_{t+2},\dots,o_T\) 的后向概率 \(\beta_t(i)\)，只需要考虑在时刻 t+1 所有可能的 N 个状态 \(q_j\) 的转移概率(\(a_{ij}\)项)，以及在此状态下的观测 \(o_{t+!}\) 的观测概率(\(b_{jo_{t+1}}\)项)，然后考虑状态 \(q_j\) 之后的观测序列的后向概率 \(\beta_{t+1}(j)\)</p>

<h2 id="toc_11">前向后向概率的关系</h2>

<p>根据定义，可得</p>

<p>\[<br/>
P(i_t=q_i,O\;|\;\lambda)=\alpha_t(i)\beta_t(i) \\<br/>
P(O\;|\;\lambda)=\sum_{i=1}^{N}\alpha_t(i)\beta_t(i)<br/>
\]</p>

<h2 id="toc_12">单个状态的概率</h2>

<p>给定模型 \(\lambda\) 和观测 O，求在时刻 t 处于状态 \(q_i\) 的概率</p>

<p>\[<br/>
\gamma_t(i)=P(i_t=q_t\;|\;O,\lambda)<br/>
\]</p>

<p>根据前向后向概率的定义</p>

<p>\[<br/>
P(i_t=q_i,O\;|\;\lambda)=\alpha_t(i)\beta_t(i) \\<br/>
\gamma_t(i)=P(i_t=q_t\;|\;O,\lambda)=\frac{P(i_t=q_i,O\;|\;\lambda)}{P(O\;|\;\lambda)} \\ <br/>
\gamma_t(i)=\frac{\alpha_t(i)\beta_t(i)}{P(O\;|\;\lambda)}=\frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^{N}\alpha_t(i)\beta_t(i)}<br/>
\]</p>

<h2 id="toc_13">两个状态的联合概率</h2>

<p>给定模型 \(\lambda\) 和观测 O，求在时刻 t 处于状态 \(q_i\) 并且时刻 t+1 处于时刻 \(q_j\) 的概率</p>

<p>\[<br/>
\xi_t(i,j)=P(i_t=q_i,i_{t+1}=q_j\;|\;O,\lambda)<br/>
\]</p>

<p>根据前向后向概率的定义</p>

<p>\[<br/>
\begin{align*} <br/>
\xi_t(i,j)&amp;=P(i_t=q_i,i_{t+1}=q_j\;|\;O,\lambda) \\<br/>
&amp;=\frac{P(i_t=q_i,i_{t+1}=q_j,O\;|\;\lambda)}{P(O\;|\;\lambda)} \\<br/>
&amp;=\frac{P(i_t=q_i,i_{t+1}=q_j,O\;|\;\lambda)}{\sum_{i=1}^{N}\sum_{j=1}^{N}P(i_t=q_i,i_{t+1}=q_j,O\;|\;\lambda)}<br/>
\end{align*} <br/>
\]</p>

<p>\[<br/>
P(i_t=q_i,i_{t+1}=q_j,O\;|\;\lambda)=\alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)<br/>
\]</p>

<h2 id="toc_14">学习算法</h2>

<ul>
<li>若训练数据包括观测序列和状态序列，则 HMM 的学习是监督学习 -&gt; MLE</li>
<li>若训练数据只有观测序列，则 HMM 的学习需要使用 EM 算法，是非监督学习</li>
</ul>

<h3 id="toc_15">监督学习方法</h3>

<p>假设已给定训练数据包含 S 个长度相同的观测序列和对应的状态序列 \(\{(O_1,I_1),(O_2,I_2),\dots,(O_s,I_s)\}\)，那么，可以直接给出 HMM 的参数估计，直接用频率去估计概率</p>

<p><strong>转移概率 \(a_{ij}\) 的估计</strong></p>

<p>设样本中时刻 t 处于状态 i，时刻 t+1 转移到状态 j 的频数是 \(A_{ij}\)，则</p>

<p>\[<br/>
\hat{a}_{ij} = \frac{A_{ij}}{\sum_{j=1}^{N}A_{ij}}<br/>
\]</p>

<p><strong>观测概率 \(b_{ik}\) 的估计</strong></p>

<p>设样本中状态 i 并且观测为 k 的频数为 \(B_{ik}\)，则</p>

<p>\[<br/>
\hat{b}_{ij} = \frac{B_{ik}}{\sum_{j=1}^{N}B_{ik}}<br/>
\]</p>

<p><strong>初始状态的估计</strong></p>

<p>\(\pi_i\) 的估计为 S 个样本中初始状态为 \(q_i\) 的概率</p>

<h2 id="toc_16">非监督学习 Baum-Wellch 算法</h2>

<p>所有观测数据写成 \(O=(o_1,o_2,\dots,o_T)\)，所有隐数据写成 \(I=(i_1,i_2,\dots,i_T)\)，完全数据是 \((O,I)=(o_1,o_2,\dots,o_T,i_1,i_2,\dots,i_T)\)，完全数据的对数似然函数是 \(lnP(O,I\;|\;\lambda)\)</p>

<p>假设 \(\bar{\lambda}\) 是 HMM 参数当前的估计值，\(\lambda\) 为待求的参数，\(P(O,I\;|\;\bar{\lambda}\) 可以看作是对数似然函数在当前条件下取值的概率，用来求期望</p>

<p>\[<br/>
Q(\bar{\lambda},\lambda)=\sum_{I}lnP(O,I\;|\;\lambda)P(O,I\;|\;\bar{\lambda})<br/>
\]</p>

<h3 id="toc_17">EM 过程</h3>

<p>根据</p>

<p>\[<br/>
P(O,I\;|\;\lambda)=P(O\;|\;I,\lambda)P(I\;|\;\lambda) \\<br/>
=\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}a_{i_2i_3}\dots a_{i_{T-1}i_T}b_{i_To_T} <br/>
\]</p>

<p>函数可写成（把\(\pi,a,b\)分开）</p>

<p>\[<br/>
Q(\bar{\lambda},\lambda)=\sum_{I}lnP(O,I\;|\;\lambda)P(O,I\;|\;\bar{\lambda}) \\<br/>
= \sum_{I}ln\pi_{i_1}P(O,I\;|\;\bar{\lambda})+\sum_{I}\left(\sum_{t=1}^{T-1}lna_{i_ti_{t+1}}\right)P(O,I\;|\;\bar{\lambda})+\sum_{I}\left(\sum_{t=1}^{T}lnb_{i_to_{t}}\right)P(O,I\;|\;\bar{\lambda})<br/>
\]</p>

<p>极大化 Q，求得参数 \(A,B,\pi\)</p>

<p>由于这三个参数分别位于三个项中，可分别极大化</p>

<h3 id="toc_18">初始概率</h3>

<p>\[<br/>
\sum_{I}ln\pi_{i_1}P(O,I\;|\;\bar{\lambda})=\sum_{i=1}^{N}ln\pi_{i_1}P(O,i_1=i\;|\;\bar{\lambda})<br/>
\]</p>

<p>注意到 \(\pi_i\) 满足加和为 1，利用拉格朗日乘子法，得到</p>

<p>\[<br/>
 \sum_{i=1}^{N}ln\pi_{i_1}P(O,i_1=i\;|\;\bar{\lambda})+\gamma\left(\sum_{i=1}^{N}\pi_i-1\right)<br/>
 \]</p>

<p>对上式相对于 \(\pi_i\) 求偏导，得到</p>

<p>\[<br/>
P(O,i_1=i\;|\;\bar{\lambda})+\gamma\pi_i=0;<br/>
\]</p>

<p>对 i 求和，得到</p>

<p>\[<br/>
\gamma=-P(O\;|\;\bar{\lambda})<br/>
\]</p>

<p>从而得到初始状态概率</p>

<p>\[<br/>
\pi_i=\frac{P(O,i_1=i\;|\;\bar{\lambda})}{P(O\;|\;\bar{\lambda})}<br/>
\]</p>

<h3 id="toc_19">转移概率和观测概率</h3>

<p>第二项可写成</p>

<p>\[<br/>
\sum_{I}\left(\sum_{t=1}^{T-1}lna_{i_ti_{t+1}}\right)P(O,I\;|\;\bar{\lambda})=\sum_{i=1}^{N}\sum_{j=1}^{N}\sum_{t=1}^{T-1}lna_{ij}P(O,i_t=i,i_{t+1}=j\;|\;\bar{\lambda})<br/>
\]</p>

<p>仍然使用拉格朗日乘子法，得到</p>

<p>\[<br/>
a_{ij}=\frac{\sum_{t=1}^{T-1}P(O,i_t=i,i_{t+1}=j\;|\;\bar{\lambda})}{\sum_{t=1}^{T-1}P(O,i_t=i\;|\;\bar{\lambda})}=\frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}<br/>
\]</p>

<p>同理，对于观测概率，得到</p>

<p>\[<br/>
b_{ik}=\frac{\sum_{t=1}^{T}P(O,i_t=i\;|\;\bar{\lambda})I(o_t=v_k)}{\sum_{t=1}^{T}P(O,i_t=i\;|\;\bar{\lambda})}=\frac{\sum_{t=1,o_t=v_k}^{T}\gamma_t(i)}{\sum_{t=1}^{T}\gamma_t(i)}<br/>
\]</p>

<h2 id="toc_20">预测算法</h2>

<h3 id="toc_21">预测的近似算法</h3>

<p>在每个时刻 t 选择在该时刻最有可能出现的状态 \(i_t^*\)，从而得到一个隐状态序列 \(I^*=\{i_1^*,i_2^*,\dots,i_T^*\}\)，将它作为预测的结果</p>

<p>给定模型和观测序列，时刻 t 处于状态 \(q_i\) 的概率为</p>

<p>\[<br/>
\gamma_t(i)=\frac{\alpha_t(i)\beta_t(i)}{P(O\;|\;\lambda)}=\frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^{N}\alpha_t(i)\beta_t(i)}<br/>
\]</p>

<p>选择概率最大的 i 作为最有可能的状态（会出现此状态在实际中可能不会发生的情况）</p>

<h3 id="toc_22">Viterbi 算法</h3>

<p>用动态规划解 HMM 预测问题，用 DP 求概率最大的路径，一条路径对应一个状态序列。</p>

<p>定义变量 \(\delta_t(i)\)：在时刻 t 状态为 i 的所有路径中，概率的最大值</p>

<p>定义</p>

<p>\[<br/>
\delta_t(i)=max_{i_1,i_2,\dots,i_{t-1}} P(i_t=i,i_{t-1},\dots,i_1,o_t,\dots,o_1\;|\;\lambda)<br/>
\]</p>

<p>递推</p>

<p>\[<br/>
\delta_1(i)=\pi_ib_{io_1} \\<br/>
\delta_{t+1}(i)=max_{i_1,i_2,\dots,i_{t}} P(i_{t+1}=i,i_{t},\dots,i_1,o_{t+1},\dots,o_1\;|\;\lambda) \\<br/>
= max_{1\le i\le N}\left(\delta_t(j)a_{ji}\right)b_{io_{t+1}}<br/>
\]</p>

<p>终止</p>

<p>\[<br/>
P^*=max_{1\le i\le N} \delta_T(i)<br/>
\]</p>

<h4 id="toc_23">例子</h4>

<p>还是用刚才的小球的例子，观测向量 O=红白红，试求最优状态序列</p>

<p>\(<br/>
\pi=\left( \begin{array}{c}<br/>
0.2 \\<br/>
0.4 \\<br/>
0.4<br/>
\end{array}\right)<br/>
\quad\) \(<br/>
A=\left( \begin{matrix}<br/>
0.5 &amp; 0.2 &amp; 0.3 \\<br/>
0.3 &amp; 0.5 &amp; 0.2 \\<br/>
0.2 &amp; 0.3 &amp; 0.5<br/>
\end{matrix}\right)<br/>
\quad\) \(<br/>
B=\left( \begin{matrix}<br/>
0.5 &amp; 0.5 \\<br/>
0.4 &amp; 0.6 \\<br/>
0.7 &amp; 0.3<br/>
\end{matrix}\right)<br/>
\)</p>

<p>初始化，在 t=1 时，对于每一个状态 i，求状态为 i 观测到 \(o_1=red\) (矩阵 B 的第一列) 的概率，记为 \(\delta_1(i)\)</p>

<p>\[<br/>
\delta_1(i)=\pi_ib_{io_1}=\pi_ib_{i,red}<br/>
\]</p>

<p>求得</p>

<p>\[<br/>
\delta_1(1)=0.2\times0.5=0.1 \\<br/>
\delta_1(2)=0.4\times0.4=0.16 \\<br/>
\delta_1(3)=0.4\times0.8=0.28<br/>
\]</p>

<p>在 t=2 时，对每个状态 i，求在 t=1 时状态为 j 观测为红并且在 t=2 时状态为 i 观测为白的路径的最大概率，记为 \(\delta_2(i)\)，这里 \(o_2=white\) 则：</p>

<p>\[<br/>
\delta_{t+1}(i)=max_{1\le j\le 3} \left(\delta_1(j)a_{ji}\right)b_{io_{2}}=max_{1\le j\le 3} \left(\delta_1(j)a_{j1}\right)b_{i,white}<br/>
\]</p>

<p>求得</p>

<p>\[<br/>
\delta_{2}(1)=max_{1\le j\le 3} \left(\delta_1(j)a_{j1}\right)b_{i,white} \\<br/>
= max\{0.10\times0.5,0.16\times0.3,0.28\times0.2\}\times0.5=0.028<br/>
\]</p>

<p>同理可得</p>

<p>\[<br/>
\delta_{2}(2)=0.0504 \\<br/>
\delta_{2}(3)=0.042<br/>
\]</p>

<p>继续可以求得</p>

<p>\[<br/>
\delta_{3}(1)=0.00756 \\<br/>
\delta_{3}(2)=0.01008 \\<br/>
\delta_{3}(3)=0.0147<br/>
\]</p>

<p>所以最大是 \(\delta_{3}(3)=0.0147\)，根据每一步最大，得到的序列是(3,3,3)</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204007006.html">
                
                  <h1>深入浅出数据分析</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<!-- MarkdownTOC -->

<ul>
<li>分解数据

<ul>
<li>统计模型取决于心智模型</li>
</ul></li>
<li>检验你的理论</li>
<li>最优化：寻找最大值</li>
<li>数据图形化：图形让你更精明</li>
<li>假设检验：假设并非如此</li>
<li>贝叶斯统计</li>
<li>主观概率：信念数字化</li>
<li>启发法：凭人类的天性作分析</li>
<li>直方图：数字的形状</li>
<li>回归：预测</li>
<li>误差：合理误差</li>
<li>关系数据库</li>
<li>整理数据：井然有序</li>
<li>正文未及的十大要诀</li>
</ul>

<!-- /MarkdownTOC -->

<h2 id="toc_0">分解数据</h2>

<p>数据无所不在，数据分析就是仔细推敲证据。固定基本流程：</p>

<ul>
<li>确定：了解问题，确定问题</li>
<li>分解：分解问题和数据，使其成为更小的组成部分</li>
<li>评估：对前两步了解到的情况作出各种结论</li>
<li>决策：把这些结论重新组合在一起，作出一个决策</li>
</ul>

<p><strong>未明确</strong>确定自己的问题或目标就进行数据分析就如同未定下目的地就上路旅行一样。</p>

<p>客户将根据你的分析作决策，你需要尽可能从他那里多了解一些信息，才能<strong>确定问题</strong>。</p>

<p>你对外界的假设和你确信的观点就是你的<strong>心智模型</strong>。心智模型有时助益良多，有时带来麻烦。重中之重是明确心智模型，并且像对待数据一样严肃认真地对待心智模型。</p>

<p><strong>务必尽量明确你的心智模型</strong></p>

<h3 id="toc_1">统计模型取决于心智模型</h3>

<p>心智模型决定你的观察结果，是你观察现实的棱镜。你无法看到一切，因此你的大脑必须做出选择，以便集中注意力，这就是所谓的心智模型<strong>决定观察结果</strong>。你的统计模型<strong>取决于</strong>你的心智模型，如果用了错误的心智模型，分析就会胎死腹中。</p>

<p><strong>最好使用正确的心智模型</strong></p>

<p>心智模型应当包括你不了解的因素，一定要指出<strong>不确定</strong>因素，只要能明确不确定因素，你就会小心防范并想办法填补知识空白，继而提出更好的建议。</p>

<p>所获得的新数据若未经过任何处理，即称为<strong>原始数据</strong>，为了让他人提供的数据在你要进行的数据运算中发挥作用，几乎总是要调节数据。千万要<strong>保存原始数据</strong>，避免进行任何数据处理。即使是最好的数据分析师也会失误，必须能够将自己的工作结果与原始数据进行比较。</p>

<h2 id="toc_2">检验你的理论</h2>

<p>一个好实验往往能让你摆脱对<strong>观察数据</strong>的无限依赖，能帮助你理清因果联系；可靠的<strong>实证数据</strong>将让你的分析判断更具有说服力。</p>

<p><strong>比较越多，分析结果越正确</strong>，对于观察研究尤其如此。</p>

<p>为了<strong>控制</strong>观察研究混杂因素，有时候，将数据拆分为更小的数据块是一个好想法。这些小数据块更具有<strong>同质性</strong>。换句话说，这些小数据块不包含那些有可能扭曲你的分析结果及让你产生错误想法的内部偏差。</p>

<p><strong>控制组(Control Group)</strong> 一组体现现状的处理对象，未经过任何新的处理(也称对照组)</p>

<p>没有控制组就意味着没有比较，没有比较就意味着无法对所发生的情况进行判断。</p>

<h2 id="toc_3">最优化：寻找最大值</h2>

<p><strong>你能控制的变量受到约束条件的限制</strong>，决策变量是你能控制的因素。约束条件不会告诉你的如何实现最大利润，它们只告诉你在实现利润最大化的过程中无法做到的事。</p>

<p>为了解决一个最优化问题，你需要将决策变量、约束条件及希望最大化的目标合并成一个目标函数。你希望最大化或最小化的对象就是目标，目标函数则可以帮助你找出最优化结果。</p>

<p><strong>任何最优化问题都有一些约束条件和一个目标函数</strong></p>

<p><strong>合理的选择都出现在可行区域里</strong></p>

<p><strong>新约束条件改变了可行区域</strong></p>

<p><strong>做好修改模型的准备</strong></p>

<h2 id="toc_4">数据图形化：图形让你更精明</h2>

<p><strong>体现数据</strong>。创建优秀数据图形的第一要务就是促使客户谨慎思考并制定决策，优秀的数据分析由始至终都离不开<strong>用数据思考</strong>。</p>

<p>散点图是<strong>探索性数据分析</strong>的奇妙工具，统计学家用这个术语描述在一组数据中寻找一些假设条件进行测试的活动。</p>

<p>分析师喜欢用散点图发现<strong>因果关系</strong>，即一个变量影响另一个变量的关系。通常用散点图的 X 轴代表自变量(我们假想为原因的变量)，用 Y 轴代表应变量(我们假定为结果的变量)。</p>

<p><strong>优秀的图形设计有助于思考的原因</strong>，当你描述你的数据图形时，需要论述课相互换用的两种因果模型或图解</p>

<h2 id="toc_5">假设检验：假设并非如此</h2>

<p>变量之间可以正相关，也可以负相关。</p>

<p>假设检验的核心是证伪，请勿试图选出最合理的假设，只需<strong>剔除无法证实的假设</strong>。</p>

<p><strong>诊断性</strong>是证据所具有的一种功能，能够帮助你评估所考虑的假设的相对似然。如果证据具有诊断性，就能帮助你对假设排序。</p>

<h2 id="toc_6">贝叶斯统计</h2>

<p><strong>贝叶斯规则</strong>能帮助你利用<strong>基础概率</strong>和波动数据做到明察秋毫。</p>

<p><strong>条件概率</strong>即以一件事的发生为前提的另一件事的发生概率。</p>

<p>我们的大脑生来不擅长处理概率数字，因此，将概率转变为整数，然后进行思考，是避免犯错误的一个有效办法。</p>

<p>新信息会改变的基础概率。</p>

<h2 id="toc_7">主观概率：信念数字化</h2>

<p>如果用一个数字形式的概率来表示自己对某事的确认程度，所用的就是<strong>主观概率</strong>。</p>

<p>贝叶斯规则是修正主观概率的好办法</p>

<p><img src="./_resources/da1.jpg" alt="da1"/></p>

<p>使用贝叶斯规则求主观概率的根本在于找出<strong>在假设成立的条件下，证据出现的概率</strong></p>

<h2 id="toc_8">启发法：凭人类的天性作分析</h2>

<p>启发法是从直觉走向最优化的桥梁。</p>

<p><strong>启发法</strong>1.(心理学定义)用一种更便于理解的属性代替一种难解的，令人困惑的属性。2.(计算机科学定义)一种解决问题的方法，可能会得出正确答案，但不保证得出最优化答案。</p>

<p>固定模式必定具有启发性：处理固定模式不需要大费力气，而且速度超快。</p>

<p>启发法并非百试不爽。快而省的经验可能有助于找出某些问题的答案，而在其他情况下，却先入为主地让你做出不恰当的判断。</p>

<h2 id="toc_9">直方图：数字的形状</h2>

<p><strong>直方图</strong>是一种功能强大的图形，无论数据集多庞大，直方图都能显示出数据点在数值范围内的<strong>分布</strong>情况</p>

<p>直方图不同区间之间的缺口即数据点之间的缺口</p>

<h2 id="toc_10">回归：预测</h2>

<p>回归分析法力无边，只要使用得法，就能帮助你预测某些结果值。若与控制实验同时使用，回归分析还能预测未来。</p>

<p>回归线就是最准确地贯穿平均值图中的各个点的直线</p>

<h2 id="toc_11">误差：合理误差</h2>

<p>指出误差可以让预测和信念更全面。</p>

<p>用回归方程预测数据范围以外的数值称为<strong>外插法</strong>。外插法与<strong>内插法</strong>有所不同，内插法对数据范围内的点进行预测，这这是回归法本来的目的。内插法很准确，但使用外插法就得小心了。</p>

<p><strong>低劣的预测比不作预测更糟糕</strong></p>

<p>千万要对模型假设保持戒心。观察他人的模型时，一定要想一想他们的假设有何道理，以及他们是否忘记了某种假设。不合适的假设会使模型完全失效——这还算是最好的结果；最坏的结果是具有危险的欺骗性。</p>

<p>机会误差 = 实际结果与模型预测结果之间的误差</p>

<h2 id="toc_12">关系数据库</h2>

<p>数据库就是一系列相互有特定关系的数据。一个数据库就是一张表格或一组表格，表格以某种方式对数据进行管理，使数据之间的相互关系显而易见。</p>

<h2 id="toc_13">整理数据：井然有序</h2>

<p>乱糟糟的数据毫无用处。作为数据分析师，你花在数据整理上的时间多过数据分析上的时间。</p>

<p>清理混乱数据的根本在于准备。一旦组织好数据，就能修复数据。</p>

<h2 id="toc_14">正文未及的十大要诀</h2>

<ol>
<li>统计知识越渊博，分析工作越有可能取得辉煌成就</li>
<li>娴熟的数据分析师应该是一个电子表格忍者</li>
<li>体现出比较、对比、差异。体现出因果关系、机制、理由、系统结构。体现出多元数据。将文字、数字、图片、图形全面结合起来。充分描述证据。数据分析报告的成败在于报告内容的质量、相关性和整体性</li>
<li>数据透视表是电子表格和数据分析软件中极其有效的数据分析工具，是探索性数据分析和相关数据库数据汇总的梦幻之作</li>
<li>R 社区</li>
<li>非线性与多元回归</li>
<li>原假设-备择假设检验</li>
<li>随机性</li>
<li>Google Docs</li>
<li>你的专业技能</li>
</ol>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204006958.html">
                
                  <h1>Graphic Model 学习笔记</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>A compact wawy to represent joint distributions</li>
<li>Useful to query various conditional probabilites</li>
<li>A powerful language to model real-world systems</li>
<li>Easy to plug in prior knowledge</li>
<li>Extremely widely used</li>
</ul>

<h2 id="toc_0">Graphcial model notation</h2>

<ul>
<li>Nodes: variables (with domains)

<ul>
<li>Can be assigned (observed) or unassigned (unobserved)</li>
</ul></li>
<li>Arcs: iteractions

<ul>
<li>Indicate <q>direct influence</q> between variables</li>
<li>Formally: encode conditional independence</li>
</ul></li>
</ul>

<h2 id="toc_1">Probabilities in BNs</h2>

<p>Bayes nets implicitly encode joint distributions.</p>

<ul>
<li>As a product of local conditional distributions</li>
<li>To see what probability a BN gives to a full assignment, multiply all the relevant conditionals together</li>
</ul>

<p>\[P(x_1,x_2,...,x_n)=\prod_{i=1}^n P(x_i\;|\;parents(X_i))\]</p>

<h2 id="toc_2">Causal Chains</h2>

<p>\[X \to Y \to Z\]</p>

<p>\[P(x,y,z)=P(x)P(y|x)P(z|y)\]</p>

<p>Is X independent of Z given Y?</p>

<p>\[\because P(z|x,y)=\frac{P(x,y,z)}{P(x,y)}=\frac{P(x)P(y|x)P(z|y)}{P(x)P(y|x)}=P(z|y)\]</p>

<p>Answer is Yes. Evidence along the chain <q>blocks</q> the influence.</p>

<hr/>

<p>Another configuration</p>

<p>\[X \gets Y \to Z\]</p>

<ul>
<li>Are X and Z independent? No</li>
<li>Are X and Z independent given Y? Yes</li>
</ul>

<p>\[\because P(z|x,y)=\frac{P(x,y,z)}{P(x,y)}=\frac{P(y)P(x|y)P(z|y)}{P(y)P(x|y)}=P(z|y)\]</p>

<p>Observing the cause blocks influence between effects</p>

<hr/>

<p>Last configuration: two causes of one effect(v-structures)</p>

<p>\[X \to Y \gets Z\]</p>

<ul>
<li>Are X and Z independent? Yes</li>
<li>Are X and Z independent given Y? No</li>
</ul>

<p>This is backwards from the other cases. Observing an effect activates influence between possible causes.  </p>

<hr/>

<p>The general case</p>

<ul>
<li>Any complex example can be analyzed using these three canonical cases</li>
<li>General question: in a given BN, are two variables independent (given evidence)?</li>
</ul>

<h2 id="toc_3">Probabilistic Inference</h2>

<p>Posterior probabilities: Probabilityof any even given any evidence</p>

<h3 id="toc_4">Bayesian inference</h3>

<ul>
<li>Bayesian probability treats parameters as random variables</li>
<li>Learning / parameter estimation is replaced by probabilistic inference \(P(\theta|D)\)</li>
</ul>

<p>Pros</p>

<ul>
<li>Elegant - no distinction between parameters and other hidden variables</li>
<li>Can us priors to learn from small data sets</li>
</ul>

<p>Cons</p>

<ul>
<li>Math can get hairy</li>
<li>Often computatoinally intractable</li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204006902.html">
                
                  <h1>EM, GMM 指南</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">Jensen 不等式</h2>

<p>若 f 是凸函数，基本 Jensen 不等式</p>

<p>\[<br/>
f(\theta x+(1-\theta)y \le \theta f(x)+(1-\theta)f(y)<br/>
\]</p>

<p>若 \(\theta_1,\dots,\theta_k \ge 0\;,\;\theta_1+\dots+\theta_k=1\)，则</p>

<p>\[<br/>
f(\theta_1 x_1+\dots+\theta_k x_k) \le \theta_1 f(x_1)+\dots+\theta_k f(x_k)<br/>
\]</p>

<p>且</p>

<p>\[<br/>
f(\mathbf{E}x) \le \mathbf{E}f(x)<br/>
\]</p>

<h2 id="toc_1">考察高斯分布</h2>

<p>若给定一组样本 \(x_1,x_2,\dots,x_n\)，已知它们来自于高斯分布 \(N(\mu,\sigma)\)，试估计参数 \(\mu,\sigma\)</p>

<p>高斯分布的概率密度函数</p>

<p>\[<br/>
f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}<br/>
\]</p>

<p>将 \(x_1,x_2,\dots,x_n\) 带入，得到样本的似然函数</p>

<p>\[<br/>
L(x)=\prod_i \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}}<br/>
\]</p>

<p>化简对数似然函数</p>

<p>\[<br/>
\begin{align*} <br/>
l(x)&amp;=log\prod_i \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}} \\<br/>
&amp;=\sum_ilog \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}} \\<br/>
&amp;=\left(\sum_i log\frac{1}{\sqrt{2\pi}\sigma}\right)+\left( \sum_i-\frac{(x_i-\mu)^2}{2\sigma^2}\right) \\<br/>
&amp;=-\frac{n}{2}log(2\pi\sigma^2)-\frac{1}{2\sigma^2}\sum_i(x_i-\mu)^2<br/>
\end{align*} <br/>
\]</p>

<p>可得目标函数</p>

<p>\[<br/>
l(x)= -\frac{n}{2}log(2\pi\sigma^2)-\frac{1}{2\sigma^2}\sum_i(x_i-\mu)^2<br/>
\]</p>

<p>将目标函数对参数 \(\mu,\sigma\)分别求偏导，可得</p>

<p>\[<br/>
\mu=\frac{1}{n}\sum_ix_i \\<br/>
\sigma^2=\frac{1}{n}\sum_i(x_i-\mu)^2<br/>
\]</p>

<h2 id="toc_2">直观理解 GMM 参数估计</h2>

<p>假设我们需要调查我们学校的男生和女生的身高分布。假设你在校园里随便地活捉了100个男生和100个女生。他们共200个人（也就是200个身高的样本数据，为了方便表示，下面，我说“人”的意思就是对应的身高）。样本中存在男性和女性，它们服从 \(N(\mu_1,\sigma_1)\) 和 \(N(\mu_2,\sigma_2)\) 的分布，试估计 \(\mu_1,\sigma_1,\mu_2,\sigma_2\)，这里我们不知道性别，对于存在一个隐变量的分布(这里就是不知道性别)，用 EM 算法就非常合适</p>

<p>假如我们知道性别的话，用数学的语言来说就是：在学校那么多男生（身高）中，我们独立地按照概率密度\(p(x\;|\;\theta)\)抽取100了个（身高），组成样本集 X，我们想通过样本集 X 来估计出未知参数 \(\theta\)。这里概率密度\(p(x\;|\;\theta)\)我们知道了是高斯分布\(N(\mu,\sigma)\)的形式，其中的未知参数是\(\theta=[\mu,\sigma]^T\)。抽到的样本集是\(X=\{x_1,x_2,\dots,x_N\}\)，其中\(x_i\)表示抽到的第 i 个人的身高，这里 N 就是100，表示抽到的样本个数。</p>

<p>由于每个样本都是独立地从\(p(x\;|\;\theta)\)中抽取的，换句话说这100个男生中的任何一个，都是我随便捉的，从我的角度来看这些男生之间是没有关系的。那么，我从学校那么多男生中为什么就恰好抽到了这100个人呢？抽到这100个人的概率是多少呢？因为这些男生（的身高）是服从同一个高斯分布\(p(x\;|\;\theta)\)的。那么我抽到男生A（的身高）的概率是\(p(x_A\;|\;\theta)\)，抽到男生B的概率是\(p(x_B\;|\;\theta)\)，那因为他们是独立的，所以很明显，我同时抽到男生A和男生B的概率是\(p(x_A\;|\;\theta)\times p(x_B\;|\;\theta)\)，同理，我同时抽到这100个男生的概率就是他们各自概率的乘积了。用数学家的口吻说就是从分布是\(p(x\;|\;\theta)\)的总体样本中抽取到这100个样本的概率，也就是样本集X中各个样本的联合概率，用下式表示：</p>

<p>\[<br/>
L(x)=L(x_1,\dots,x_n;\theta)=\prod_i \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}}<br/>
\]</p>

<p>这个概率反映了，在概率密度函数的参数是\(\theta\)时，得到 X 这组样本的概率。因为这里 X 是已知的，也就是说我抽取到的这100个人的身高可以测出来，也就是已知的了。而\(\theta\)是未知了，则上面这个公式只有\(\theta\)是未知数，所以它是\(\theta\)的函数。这个函数放映的是在不同的参数\(\theta\)取值下，取得当前这个样本集的可能性，因此称为参数\(\theta\)相对于样本集 X 的似然函数（likehood function）。记为\(L(\theta)\)。</p>

<p>在学校那么男生中，我一抽就抽到这100个男生（表示身高），而不是其他人，那是不是表示在整个学校中，这100个人（的身高）出现的概率最大啊。那么这个概率怎么表示？哦，就是上面那个似然函数\(L(\theta)\)。所以，我们就只需要找到一个参数\(\theta\)，其对应的似然函数\(L(\theta)\)最大，也就是说抽到这100个男生（的身高）概率最大。这个叫做\(\theta\)的最大似然估计量，记为：</p>

<p>\[<br/>
\hat{\theta}=arg\;max\;l(\theta)<br/>
\]</p>

<p>有时，可以看到\(L(\theta)\)是连乘的，所以为了便于分析，还可以定义对数似然函数，将其变成连加的：</p>

<p>\[<br/>
H(\theta)=ln\;L(\theta)=ln\prod_{i=1}^np(x_i;\theta)=\sum_{i=1}^nln\;p(x_i;\theta)<br/>
\]</p>

<p>好了，现在我们知道了，要求\(\theta\)，只需要使\(\theta\)的似然函数\(L(\theta)\)极大化，然后极大值对应的\(\theta\)就是我们的估计。这里就回到了求最值的问题了。怎么求一个函数的最值？当然是求导，然后让导数为0，那么解这个方程得到的\(\theta\)就是了（当然，前提是函数\(L(\theta)\)连续可微）。那如果\(\theta\)是包含多个参数的向量那怎么处理啊？当然是求\(L(\theta)\)对所有参数的偏导数，也就是梯度了，那么 n 个未知的参数，就有 n 个方程，方程组的解就是似然函数的极值点了，当然就得到这 n 个参数了。</p>

<p>最大似然估计你可以把它看作是一个反推。多数情况下我们是根据已知条件来推算结果，而最大似然估计是已经知道了结果，然后寻求使该结果出现的可能性最大的条件，以此作为估计值。</p>

<p>极大似然估计，只是一种概率论在统计学的应用，它是参数估计的方法之一。说的是已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，参数估计就是通过若干次试验，观察其结果，利用结果推出参数的大概值。最大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。</p>

<p>求最大似然函数估计值的一般步骤：</p>

<ol>
<li>写出似然函数；</li>
<li>对似然函数取对数，并整理；</li>
<li>求导数，令导数为0，得到似然方程；</li>
<li>解似然方程，得到的参数即为所求；</li>
</ol>

<p>再回到例子本身，如果没有“男的左边，女的右边，其他的站中间！”这个步骤，或者说我抽到这200个人中，某些男生和某些女生一见钟情，已经好上了，纠缠起来了。咱们也不想那么残忍，硬把他们拉扯开。那现在这200个人已经混到一起了，这时候，你从这200个人（的身高）里面随便给我指一个人（的身高），我都无法确定这个人（的身高）是男生（的身高）还是女生（的身高）。也就是说你不知道抽取的那200个人里面的每一个人到底是从男生的那个身高分布里面抽取的，还是女生的那个身高分布抽取的。用数学的语言就是，抽取得到的每个样本都不知道是从哪个分布抽取的。</p>

<p>这个时候，对于每一个样本或者你抽取到的人，就有两个东西需要猜测或者估计的了，一是这个人是男的还是女的？二是男生和女生对应的身高的高斯分布的参数是多少？</p>

<p>只有当我们知道了哪些人属于同一个高斯分布的时候，我们才能够对这个分布的参数作出靠谱的预测，例如刚开始的最大似然所说的，但现在两种高斯分布的人混在一块了，我们又不知道哪些人属于第一个高斯分布，哪些属于第二个，所以就没法估计这两个分布的参数。反过来，只有当我们对这两个分布的参数作出了准确的估计的时候，才能知道到底哪些人属于第一个分布，那些人属于第二个分布。</p>

<p>这就成了一个先有鸡还是先有蛋的问题了。鸡说，没有我，谁把你生出来的啊。蛋不服，说，没有我，你从哪蹦出来啊。（呵呵，这是一个哲学问题。当然了，后来科学家说先有蛋，因为鸡蛋是鸟蛋进化的）。为了解决这个你依赖我，我依赖你的循环依赖问题，总得有一方要先打破僵局，说，不管了，我先随便整一个值出来，看你怎么变，然后我再根据你的变化调整我的变化，然后如此迭代着不断互相推导，最终就会收敛到一个解。这就是EM算法的基本思想了。</p>

<p>例如，小时候，老妈给一大袋糖果给你，叫你和你姐姐等分，然后你懒得去点糖果的个数，所以你也就不知道每个人到底该分多少个。咱们一般怎么做呢？先把一袋糖果目测的分为两袋，然后把两袋糖果拿在左右手，看哪个重，如果右手重，那很明显右手这代糖果多了，然后你再在右手这袋糖果中抓一把放到左手这袋，然后再感受下哪个重，然后再从重的那袋抓一小把放进轻的那一袋，继续下去，直到你感觉两袋糖果差不多相等了为止。呵呵，然后为了体现公平，你还让你姐姐先选了。</p>

<p>EM算法就是这样，假设我们想估计知道A和B两个参数，在开始状态下二者都是未知的，但如果知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A。可以考虑首先赋予A某种初值，以此得到B的估计值，然后从B的当前值出发，重新估计A的取值，这个过程一直持续到收敛为止。</p>

<p>EM的意思是“Expectation Maximization”，在我们上面这个问题里面，我们是先随便猜一下男生（身高）的正态分布的参数：如均值和方差是多少。例如男生的均值是1米7，方差是0.1米（当然了，刚开始肯定没那么准），然后计算出每个人更可能属于第一个还是第二个正态分布中的（例如，这个人的身高是1米8，那很明显，他最大可能属于男生的那个分布），这个是属于Expectation一步。有了每个人的归属，或者说我们已经大概地按上面的方法将这200个人分为男生和女生两部分，我们就可以根据之前说的最大似然那样，通过这些被大概分为男生的n个人来重新估计第一个分布的参数，女生的那个分布同样方法重新估计。这个是Maximization。然后，当我们更新了这两个分布的时候，每一个属于这两个分布的概率又变了，那么我们就再需要调整E步……如此往复，直到参数基本不再发生变化为止。</p>

<p>这里把每个人（样本）的完整描述看做是三元组\(y_i=\{x_i,z_{i1},z_{i2}\}\)，其中，\(x_i\)是第 i 个样本的观测值，也就是对应的这个人的身高，是可以观测到的值。\(z_{i1}\)和\(z_{i2}\)表示男生和女生这两个高斯分布中哪个被用来产生值\(x_i\)，就是说这两个值标记这个人到底是男生还是女生（的身高分布产生的）。这两个值我们是不知道的，是隐含变量。确切的说，\(z_{ij}\)在\(x_i\)由第 j 个高斯分布产生时值为1，否则为0。例如一个样本的观测值为1.8，然后他来自男生的那个高斯分布，那么我们可以将这个样本表示为{1.8, 1, 0}。如果\(z_{i1}\)和\(z_{i2}\)的值已知，也就是说每个人我已经标记为男生或者女生了，那么我们就可以利用上面说的最大似然算法来估计他们各自高斯分布的参数。但是它们未知，因此我们只能用EM算法。</p>

<p>咱们现在不是因为那个恶心的隐含变量（抽取得到的每个样本都不知道是从哪个分布抽取的）使得本来简单的可以求解的问题变复杂了，求解不了吗。那怎么办呢？人类解决问题的思路都是想能否把复杂的问题简单化。好，那么现在把这个复杂的问题逆回来，我假设已经知道这个隐含变量了，哎，那么求解那个分布的参数是不是很容易了，直接按上面说的最大似然估计就好了。那你就问我了，这个隐含变量是未知的，你怎么就来一个假设说已知呢？你这种假设是没有根据的。呵呵，我知道，所以我们可以先给这个给分布弄一个初始值，然后求这个隐含变量的期望，当成是这个隐含变量的已知值，那么现在就可以用最大似然求解那个分布的参数了吧，那假设这个参数比之前的那个随机的参数要好，它更能表达真实的分布，那么我们再通过这个参数确定的分布去求这个隐含变量的期望，然后再最大化，得到另一个更优的参数，……迭代，就能得到一个皆大欢喜的结果了。</p>

<p>用数学的方式来描述就是：</p>

<p>随机变量 X 是有 K 个高斯分布混合而成，取各个高斯分布的概率为 \(\pi_1,\pi_2,\dots,\pi_K\)，第 i 个高斯分布的均值为 \(\mu_1\)，方差为 \(\sum_i\)。若观测到随机变量 X 的一系列样本 \(x_1,x_2,\dots,x_n\)，试估计参数 \(\pi,\mu,\Sigma\)</p>

<p>建立目标函数，产生这个样本的对数似然函数为</p>

<p>\[<br/>
l(x)=\sum_{i=1}^{N}log\left(\sum_{k=1}^{K}\pi_kN(x_i\;|\;\mu_k,\Sigma_k)\right)<br/>
\]</p>

<p>由于在对数函数里面又有求和，没办法用直接求导解方程的办法直接求得极大值。为此，我们分成两步解决这个问题。</p>

<h3 id="toc_3">第一步 估算数据来自哪个组份</h3>

<p>对于每个数据 \(x_i\) 来说，它由第 k 个组份生成的概率为</p>

<p>\[<br/>
\gamma(i,k)=\frac{\pi_kN(x_i\;|\;\mu_k,\Sigma_k)}{\sum_{j=1}^K\pi_jN(x_i\;|\;\mu_j,\Sigma_j)}<br/>
\]</p>

<p>由于式子里 \(\mu,\Sigma\) 也是需要我们估计的值，我们采用迭代发，在计算 \(\gamma(i,k)\) 的时候假定 \(\mu,\Sigma\) 均已知。第一次计算时，需要先验知识给定 \(\mu,\Sigma\)。</p>

<h3 id="toc_4">第二步 估算每个组份的参数</h3>

<p>假设上一步中得到的 \(\gamma(i,k)\) 就是正确的『数据 \(x_i\) 由组份 k 生成的概率』，或者，我们可以看做 \(x_i\) 其中有 \(\gamma(i,k)\times x_i\) 部分是由组份 k 所生成的。</p>

<p>对于所有的数据点，现在实际上可以看作组份 k 生成了 \(\{\gamma(i,k)\times x_i \;|\;i=1,2,\dots,N\}\) 这些点。组份 k 是一个标准的高斯分布，所以</p>

<p>\[<br/>
\mu_k=\frac{1}{N_k}\sum_{i=1}^{N}\gamma(i,k)x_i \\<br/>
\Sigma_k=\frac{1}{N_k}\sum_{i=1}^{N}\gamma(i,k)(x_i-\mu_k)(x_i-\mu_k)^T<br/>
\]</p>

<h2 id="toc_5">EM 算法的提出</h2>

<p>假定有训练集</p>

<p>\[<br/>
\{x^{(1)},\dots,x^{(m)}\}<br/>
\]</p>

<p>包含 m 个独立样本，希望从众找到该组数据的模型 p(x,z) 的参数，这里 x 就是可以观测到的数据，z 是隐变量。</p>

<p>取对数似然函数</p>

<p>\[<br/>
\ell(\theta)=\sum_{i=1}^{m}log\;p(x;\theta)=\sum_{i=1}^{m}log\sum_zp(x,z;\theta)<br/>
\]</p>

<p>这里，z 是隐随机变量，直接找到参数的估计是很困难的，我们的策略是建立 \(\ell(\theta)\) 的下界，并且求该下界的最大值；重复这个过程，直到收敛到局部最大值</p>

<h3 id="toc_6">Jensen 不等式</h3>

<p>令 \(Q_i\) 是 z 的某一个分布，\(Q_i \ge 0\)，有</p>

<p>\[<br/>
\begin{align*}<br/>
\sum_ilog\;p(x^{(i)};\theta) &amp;= \sum_ilog\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta) \\<br/>
&amp;= \sum_ilog\sum_{z^{(i)}}Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} \\<br/>
&amp;\ge \sum_i\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}<br/>
\end{align*}<br/>
\]</p>

<p>把 \(Q_i(z^{(i)})\) 看成是一个概率，相当于就是求一个期望，于是上面的推导实际上可以看做下面的形式</p>

<p>\[<br/>
f(\mathbf{E}x) \le \mathbf{E}f(x)<br/>
\]</p>

<p>经过变化之后的式子会稍微好求解一些，上面这个不等式，在满足以下条件时取等号，c 是一个常数</p>

<p>\[<br/>
\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}=c<br/>
\]</p>

<p>就可以通过这个条件寻找尽量紧的下界，要求是一个常数，也就是说分子分母成比例，有</p>

<p>\[<br/>
Q_i(z^{(i)}) \propto p(x^{(i)},z^{(i)};\theta) \;\; and \;\; \sum_z Q_i(z^{(i)})=1<br/>
\]</p>

<p>因此可得</p>

<p>\[<br/>
\begin{align*}<br/>
Q_i(z^{(i)}) &amp;= \frac{p(x^{(i)},z^{(i)};\theta)}{\sum_zp(x^{(i)},z;\theta)} \\<br/>
&amp;=\frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)};\theta)} \\<br/>
&amp;=p(z^{(i)}\;|\;x^{(i)};\theta)<br/>
\end{align*} <br/>
\]</p>

<h3 id="toc_7">EM 算法整体框架</h3>

<p>实际上这里的 \(Q_i(z^{(i)})\) 就是上面例子的 \(\pi_k\)</p>

<p>Repeat until convergence {</p>

<p>(E-step) For each \(i\), set</p>

<p>\[<br/>
Q_i(z^{(i)}) := p(z^{(i)}\;|\;x^{(i)};\theta)<br/>
\]</p>

<p>(M-step) Set</p>

<p>\[<br/>
\theta := arg max_\theta \sum_i\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}<br/>
\]</p>

<p>}</p>

<h2 id="toc_8">理论框架推导 GMM</h2>

<p>随机变量 \(X\) 是有 K 个高斯分布混合而成，取各个高斯分布的概率为 \(\phi_1,\phi_2,\dots,\phi_K\)，第 i 个高斯分布的均值为 \(\mu_1\)，方差为 \(\sum_i\)。若观测到随机变量 \(X\) 的一系列样本 \(x_1,x_2,\dots,x_n\)，试估计参数 \(\phi,\mu,\Sigma\)</p>

<h3 id="toc_9">E-step</h3>

<p>\[<br/>
\omega_j^{(i)}=Q_i(z^{(i)}=j)=P(z^{(i)}=j\;|\;x^{(i)};\phi,\mu,\Sigma)<br/>
\]</p>

<p>这里的 \(\omega_j^{(i)}\) 表示第 i 个样本来自第 j 个分布的概率</p>

<h3 id="toc_10">M-step</h3>

<p>将多项分布和高斯分布的参数代入，可得</p>

<p>\[<br/>
\begin{align*}<br/>
&amp;\sum_{i=1}^m\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\phi,\mu,\Sigma)}{Q_i(z^{(i)})} \\<br/>
=&amp;\sum_{i=1}^m\sum_{j=1}^kQ_i(z^{(i)}=j)log \frac{p(x^{(i)}\;|\;z^{(i)}=j;\mu,\Sigma)p(z^{(i)}=j}{Q_i(z^{(i)}=j)} \\<br/>
=&amp;\sum_{i=1}^m\sum_{j=1}^k\omega_j^{(i)}log\frac{\frac{1}{(2\pi)^{m/2}|\Sigma_j^{1/2}|}exp\left(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j)\right)·\phi_j}{\omega_j^{(i)}}<br/>
\end{align*}<br/>
\]</p>

<p>第一次转换是把联合概率转换为条件概率，其中 \(z^{(i)}\) 只跟 \(\phi\) 有关，\(x^{(i)}\) 只跟 \(\mu,\Sigma\) 有关，所以可以分开写。于是前面的一个 p 就是一个高斯模型（后面直接代入得到最终公式），后面的一个 p 就是 \(\phi_j\) 本身，因此得到这个公式</p>

<p>对均值求偏导</p>

<p>\[<br/>
\begin{align*}<br/>
&amp;\nabla_{u_l} \sum_{i=1}^m\sum_{j=1}^k\omega_j^{(i)}log\frac{\frac{1}{(2\pi)^{m/2}|\Sigma_j^{1/2}|}exp\left(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j)\right)·\phi_j}{\omega_j^{(i)}} \\<br/>
=&amp;-\nabla_{u_l} \sum_{i=1}^m\sum_{j=1}^k\omega_j^{(i)}\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j) \\<br/>
=&amp;\frac{1}{2}\sum_{i=1}^{m}\omega_j^{(i)}\nabla_{u_l}2u_l^T\Sigma_j^{-1}x^{(i)}-u_l^T\Sigma_j^{-1}u_l \\<br/>
=&amp;\sum_{i=1}^m\omega_j^{(i)}\left(\Sigma_j^{-1}x^{(i)}-\Sigma_j^{-1}u_l\right)<br/>
\end{align*}<br/>
\]</p>

<p>令上式等于 0，解得均值</p>

<p>\[<br/>
u_l := \frac{\sum_{i=1}^{m}\omega_l^{(i)}x^{(i)}}{\sum_{i=1}^{m}\omega_l^{(i)}}<br/>
\]</p>

<p>同样的方法对 \(\Sigma\) 求偏导，并令其等于 0，解得</p>

<p>\[<br/>
\Sigma_j=\frac{\sum_{i=1}^{m}\omega_l^{(i)}(x^{(i)}-\mu_j)(x^{(i)}-\mu_j)^T}{\sum_{i=1}^{m}\omega_l^{(i)}}<br/>
\]</p>

<p>关于 \(\phi\) ，在目标函数与它相关的是</p>

<p>\[<br/>
\sum_{i=1}^m\sum_{j=1}^k\omega_j^{(i)}log\phi_j<br/>
\]</p>

<p>由于多项分布的概率和为 1，建立拉格朗日方程</p>

<p>\[<br/>
L(\phi)=\sum_{i=1}^m\sum_{j=1}^k\omega_j^{(i)}log\phi_j+\beta\left(\sum_{j=1}^k\phi_j-1\right)<br/>
\]</p>

<p>这样求解的 \(\phi_i\) 一定非负，所以不用考虑这个条件，然后对 \(\phi,\beta\) 分别求偏导，令其为 0，可得</p>

<p>\[<br/>
\frac{\partial}{\partial\phi_j}L(\phi)=\sum_{i=1}^{m}\frac{\omega_j^{(i)}}{\phi_j}+\beta \\<br/>
-\beta = \sum_{i=1}^m\sum_{j=1}^k\omega_j^{(i)}=\sum_{i=1}^m1=m \\<br/>
\phi_j:=\frac{1}{m}\sum_{i=1}^{m}\omega_j^{(i)}<br/>
\]</p>

<p>估算出来这三个参数，再带入到 E-step，就可以循环进行计算了</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204006842.html">
                
                  <h1>深度学习相关收集</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">入门</h2>

<p>其他回答者资料给的很充足了，这里补充点类似于学习路径的东西。</p>

<p>除了一些基础的机器学习知识，在学习和理解Deep Learning之前，需要先对于Neural Network和AutoEncoder这两个模型有所了解，特别是后者，AutoEncoder的隐藏层与输入层的关系、使用AutoEncoder来pre-training一个多层网络。</p>

<p>下一步就是要理解『简单的增加神经网络深度』会遇到什么问题。比如diffusion of gradients，比如严重的over-fitting，比如计算时间开销。<br/>
继续下去，要知道这些问题的原因与解决办法，这一步就映射到神经网络向深度学习的发展过程，比如pre-training、dropout、ReLU等技术的出现以及我们现在有能力（计算能力、相对于以前的大数据量）处理深层网络。<br/>
到这里，初步理解通常意义的Deep Learning模型就是深度神经网络。</p>

<p>但是接下来的才是关键。</p>

<p>对于不同的应用方向，有不同的具体的DNN的模型，比如CNN之于图像，RNN之于NLP。</p>

<p>这里以CNN为例子。CNN的特殊的一些地方在于：卷积、池化、子采样、白化、权值共享等等非常多的技术。每一个都是一个概念/方法。这是CNN所特有的。如何理解这些技术呢？<br/>
动手实现一个LeNet然后跑一下Minst数据集的手写识别（或者自己搞点图像数据），学以致用，会帮助建立好的直觉，甚至可能不懂的地方也慢慢理解了。<br/>
不过一个比较有趣的概念是 卷积。<br/>
------这个地方说得不是很好，但是我也不知道怎么表达更清楚点------<br/>
卷积这个东西有很多种理解方式：比如信号处理的理解、数学/物理上的理解、或者我的理解 :-D<br/>
『个人现在持有的看法是，这些技术都围绕一个重要的观点：减少网络参数（包括卷积也是有这个功能的）。其实每一个技术，都有自己更具体的意义，但是有共性的地方』。<br/>
对于使用CNN，要知道现在最常用的方法：AlexNet等的pre-training+具体问题的fine-tuning这种手段：一定要读一下一些相关paper。</p>

<p>最后推荐几个易用性强的库（也是好搭的）：sklearn-theano, deeppy, keras。<br/>
最后，搭环境太痛苦了，特别是mac下caffe简直是折磨QAQ</p>

<hr/>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204006778.html">
                
                  <h1>凸优化教程</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">思考凸集和凸函数</h2>

<p><img src="./_resources/co1.jpg" alt="co1"/></p>

<h2 id="toc_1">凸集</h2>

<p>集合 C 内任意两点间的线段均在集合 C 内，则称集合 C 为凸集</p>

<p><img src="./_resources/co2.jpg" alt="co2"/></p>

<p><strong>一些例子</strong></p>

<p><img src="./_resources/co3.jpg" alt="co3"/></p>

<h2 id="toc_2">超平面和半空间</h2>

<p><img src="./_resources/co4.jpg" alt="co4"/></p>

<h2 id="toc_3">多面体</h2>

<p><img src="./_resources/co5.jpg" alt="co5"/></p>

<p>一个例子</p>

<p><img src="./_resources/co6.jpg" alt="co6"/></p>

<h2 id="toc_4">保持凸性的运算</h2>

<p><img src="./_resources/co7.jpg" alt="co7"/></p>

<p><strong>集合交运算：半空间的交</strong></p>

<p><img src="./_resources/co8.jpg" alt="co8"/></p>

<p><strong>仿射变换</strong></p>

<p><img src="./_resources/co9.jpg" alt="co9"/></p>

<p><strong>透视变换</strong></p>

<p><img src="./_resources/co10.jpg" alt="co10"/></p>

<p>凸集的透视变换仍然是凸集</p>

<p><strong>投射函数(线性分式函数)</strong></p>

<p><img src="./_resources/co11.jpg" alt="co11"/></p>

<p>Ax+b - 仿射函数</p>

<h2 id="toc_5">分割超平面</h2>

<p><img src="./_resources/co12.jpg" alt="co12"/></p>

<p>一个例子</p>

<p><img src="./_resources/co13.jpg" alt="co13"/></p>

<p><strong>分割超平面的构造</strong></p>

<p><img src="./_resources/co14.jpg" alt="co14"/></p>

<h2 id="toc_6">支撑超平面</h2>

<p><img src="./_resources/co15.jpg" alt="co15"/></p>

<p><strong>思考</strong></p>

<p><img src="./_resources/co16.jpg" alt="co16"/></p>

<h2 id="toc_7">凸函数</h2>

<p><img src="./_resources/co17.jpg" alt="co17"/></p>

<h3 id="toc_8">一阶可微</h3>

<p><img src="./_resources/co18.jpg" alt="co18"/></p>

<p>即函数的增长(下降)速度要快于(慢于)以当前点的梯度为方向的直线。</p>

<p><strong>进一步思考</strong></p>

<p><img src="./_resources/co19.jpg" alt="co19"/></p>

<h3 id="toc_9">二阶可微</h3>

<p><img src="./_resources/co20.jpg" alt="co20"/></p>

<p><strong>凸函数举例</strong></p>

<p><img src="./_resources/co21.jpg" alt="co21"/></p>

<h2 id="toc_10">上境图 epigraph</h2>

<p><img src="./_resources/co22.jpg" alt="co22"/></p>

<p>一个函数是凸函数，当且仅当其上境图是凸集(可以根据定义证明)</p>

<p>进一步，一个函数是凹函数，当且仅当其亚图(hypograph)是凸集</p>

<p><img src="./_resources/co23.jpg" alt="co23"/></p>

<h2 id="toc_11">Jensen 不等式</h2>

<p><strong>若 f 是凸函数</strong></p>

<p><img src="./_resources/co24.jpg" alt="co24"/></p>

<p><strong>Jensen 不等式几乎是所有不等式的基础</strong></p>

<p><img src="./_resources/co25.jpg" alt="co25"/></p>

<h2 id="toc_12">保持函数凸性的算子</h2>

<p><img src="./_resources/co26.jpg" alt="co26"/></p>

<h3 id="toc_13">凸函数的逐点最大值</h3>

<p><img src="./_resources/co27.jpg" alt="co27"/></p>

<p>凸函数的逐点最大值仍然是凸函数</p>

<p><img src="./_resources/co28.jpg" alt="co28"/></p>

<h2 id="toc_14">凸优化</h2>

<p>优化问题的基本形式</p>

<p><img src="./_resources/co29.jpg" alt="co29"/></p>

<p><img src="./_resources/co30.jpg" alt="co30"/></p>

<p>inf-下确界 sup-上确界</p>

<h2 id="toc_15">凸优化问题的基本形式</h2>

<p><img src="./_resources/co31.jpg" alt="co31"/></p>

<p>要求还是比较严格的</p>

<h2 id="toc_16">对偶问题</h2>

<p><img src="./_resources/co32.jpg" alt="co32"/></p>

<h2 id="toc_17">Lagrange 对偶函数(dual function)</h2>

<p><img src="./_resources/co33.jpg" alt="co33"/></p>

<p>通过 Lagrange 方法我们可以把一个一般的优化问题转换成凸优化问题</p>

<p>左侧为原函数，右侧为对偶函数</p>

<p><img src="./_resources/co34.jpg" alt="co34"/></p>

<p>左侧的虚线函数是约束条件</p>

<h2 id="toc_18">鞍点解释</h2>

<p><img src="./_resources/co35.jpg" alt="co35"/></p>

<p>不可行即不满足约束条件 fi(x) &lt;= 0</p>

<h2 id="toc_19">鞍点：最优点</h2>

<p><img src="./_resources/co36.jpg" alt="co36"/></p>

<p><img src="./_resources/co37.jpg" alt="co37"/></p>

<h2 id="toc_20">例子：线性方程的最小二乘问题</h2>

<p><img src="./_resources/co38.jpg" alt="co38"/></p>

<p><img src="./_resources/co39.jpg" alt="co39"/></p>

<p>先对 x 求偏导，令其为 0，得到 x 和 v 的关系，然后把用 v 来表示的 <code>x*</code> 带入 L 中，即得到 g，也就是对偶函数。</p>

<p><img src="./_resources/co40.jpg" alt="co40"/></p>

<p>然后再求对偶函数的极大值，g 关于 v 求导数，令其为零，求得 v，然后把 v 的表达式代入 <code>x*</code>，就得到了最优解</p>

<p><img src="./_resources/co41.jpg" alt="co41"/></p>

<h2 id="toc_21">强对偶条件</h2>

<p><img src="./_resources/co42.jpg" alt="co42"/></p>

<p>这里 hi(x) = 0, fi(x) &lt;= 0</p>

<p>为了取等号，fi(x) 和 hi(x) 都需要等于 0</p>

<p><img src="./_resources/co43.jpg" alt="co43"/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204006721.html">
                
                  <h1>卷积神经网络 CNN 指南</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Deep Learning是全部深度学习算法的总称，CNN是深度学习算法在图像处理领域的一个应用。</p>

<p>第一点，在学习Deep learning和CNN之前，总以为它们是很了不得的知识，总以为它们能解决很多问题，学习了之后，才知道它们不过与其他机器学习算法如svm等相似，仍然可以把它当做一个分类器，仍然可以像使用一个黑盒子那样使用它。</p>

<p>第二点，Deep Learning强大的地方就是可以利用网络中间某一层的输出当做是数据的另一种表达，从而可以将其认为是经过网络学习到的特征。基于该特征，可以进行进一步的相似度比较等。</p>

<p>第三点，Deep Learning算法能够有效的关键其实是大规模的数据，这一点原因在于每个DL都有众多的参数，少量数据无法将参数训练充分。</p>

<p>卷积神经网络简介（Convolutional Neural Networks，简称CNN）</p>

<p>卷积神经网络是近年发展起来，并引起广泛重视的一种高效识别方法。20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（Convolutional Neural Networks-简称CNN）。现在，CNN已经成为众多科学领域的研究热点之一，特别是在模式分类领域，由于该网络避免了对图像的复杂前期预处理，可以直接输入原始图像，因而得到了更为广泛的应用。 K.Fukushima在1980年提出的新识别机是卷积神经网络的第一个实现网络。随后，更多的科研工作者对该网络进行了改进。其中，具有代表性的研究成果是Alexander和Taylor提出的“改进认知机”，该方法综合了各种改进方法的优点并避免了耗时的误差反向传播。</p>

<p>一般地，CNN的基本结构包括两层，其一为特征提取层，每个神经元的输入与前一层的局部接受域相连，并提取该局部的特征。一旦该局部特征被提取后，它与其它特征间的位置关系也随之确定下来；其二是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射是一个平面，平面上所有神经元的权值相等。特征映射结构采用影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有位移不变性。此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数。卷积神经网络中的每一个卷积层都紧跟着一个用来求局部平均与二次提取的计算层，这种特有的两次特征提取结构减小了特征分辨率。</p>

<p>CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。由于CNN的特征检测层通过训练数据进行学习，所以在使用CNN时，避免了显示的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。</p>

<h2 id="toc_0">神经网络</h2>

<p>首先介绍神经网络，这一步的详细可以参考资源1。简要介绍下。神经网络的每个单元如下：</p>

<p><img src="./_resources/cnn1.jpeg" alt="cnn1"/></p>

<p>其对应的公式如下：</p>

<p><img src="./_resources/cnn2.jpeg" alt="cnn2"/></p>

<p>其中，该单元也可以被称作是Logistic回归模型。当将多个单元组合起来并具有分层结构时，就形成了神经网络模型。下图展示了一个具有一个隐含层的神经网络。</p>

<p><img src="./_resources/cnn3.jpeg" alt="cnn3"/></p>

<p>其对应的公式如下：</p>

<p><img src="./_resources/cnn4.jpeg" alt="cnn4"/></p>

<p>比较类似的，可以拓展到有2,3,4,5，…个隐含层。</p>

<p>神经网络的训练方法也同Logistic类似，不过由于其多层性，还需要利用链式求导法则对隐含层的节点进行求导，即梯度下降+链式求导法则，专业名称为反向传播。关于训练算法，本文暂不涉及。</p>

<h2 id="toc_1">卷积神经网络</h2>

<p>在图像处理中，往往把图像表示为像素的向量，比如一个1000×1000的图像，可以表示为一个1000000的向量。在上一节中提到的神经网络中，如果隐含层数目与输入层一样，即也是1000000时，那么输入层到隐含层的参数数据为1000000×1000000=10<sup>12，这样就太多了，基本没法训练。所以图像处理要想练成神经网络大法，必先减少参数加快速度。就跟辟邪剑谱似的，普通人练得很挫，一旦自宫后内力变强剑法变快，就变的很牛了。</sup></p>

<h3 id="toc_2">局部感知</h3>

<p>卷积神经网络有两种神器可以降低参数数目，第一种神器叫做局部感知野。一般认为人对外界的认知是从局部到全局的，而图像的空间联系也是局部的像素联系较为紧密，而距离较远的像素相关性则较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。网络部分连通的思想，也是受启发于生物学里面的视觉系统结构。视觉皮层的神经元就是局部接受信息的（即这些神经元只响应某些特定区域的刺激）。如下图所示：左图为全连接，右图为局部连接。</p>

<p><img src="./_resources/cnn5.jpeg" alt="cnn5"/></p>

<p>在上右图中，假如每个神经元只和10×10个像素值相连，那么权值数据为1000000×100个参数，减少为原来的千分之一。而那10×10个像素值对应的10×10个参数，其实就相当于卷积操作。</p>

<h3 id="toc_3">参数共享</h3>

<p>但其实这样的话参数仍然过多，那么就启动第二级神器，即权值共享。在上面的局部连接中，每个神经元都对应100个参数，一共1000000个神经元，如果这1000000个神经元的100个参数都是相等的，那么参数数目就变为100了。</p>

<p>怎么理解权值共享呢？我们可以这100个参数（也就是卷积操作）看成是提取特征的方式，该方式与位置无关。这其中隐含的原理则是：图像的一部分的统计特性与其他部分是一样的。这也意味着我们在这一部分学习的特征也能用在另一部分上，所以对于这个图像上的所有位置，我们都能使用同样的学习特征。</p>

<p>更直观一些，当从一个大尺寸图像中随机选取一小块，比如说 8×8 作为样本，并且从这个小块样本中学习到了一些特征，这时我们可以把从这个 8×8 样本中学习到的特征作为探测器，应用到这个图像的任意地方中去。特别是，我们可以用从 8×8 样本中所学习到的特征跟原本的大尺寸图像作卷积，从而对这个大尺寸图像上的任一位置获得一个不同特征的激活值。</p>

<p>如下图所示，展示了一个3x3的卷积核在5x5的图像上做卷积的过程。每个卷积都是一种特征提取方式，就像一个筛子，将图像中符合条件（激活值越大越符合条件）的部分筛选出来。</p>

<p><img src="./_resources/cnn6.gif" alt="cnn6"/></p>

<h3 id="toc_4">多卷积核</h3>

<p>上面所述只有100个参数时，表明只有1个100*100的卷积核，显然，特征提取是不充分的，我们可以添加多个卷积核，比如32个卷积核，可以学习32种特征。在有多个卷积核时，如下图所示：</p>

<p><img src="./_resources/cnn7.jpeg" alt="cnn7"/></p>

<p>上图右，不同颜色表明不同的卷积核。每个卷积核都会将图像生成为另一幅图像。比如两个卷积核就可以将生成两幅图像，这两幅图像可以看做是一张图像的不同的通道。如下图所示，下图有个小错误，即将w1改为w0，w2改为w1即可。下文中仍以w1和w2称呼它们。</p>

<p>下图展示了在四个通道上的卷积操作，有两个卷积核，生成两个通道。其中需要注意的是，四个通道上每个通道对应一个卷积核，先将w2忽略，只看w1，那么在w1的某位置（i,j）处的值，是由四个通道上（i,j）处的卷积结果相加然后再取激活函数值得到的。</p>

<p><img src="./_resources/cnn8.jpeg" alt="cnn8"/></p>

<p><img src="./_resources/cnn9.jpeg" alt="cnn9"/></p>

<p>所以，在上图由4个通道卷积得到2个通道的过程中，参数的数目为4×2×2×2个，其中4表示4个通道，第一个2表示生成2个通道，最后的2×2表示卷积核大小。</p>

<h3 id="toc_5">Down-pooling</h3>

<p>在通过卷积获得了特征 (features) 之后，下一步我们希望利用这些特征去做分类。理论上讲，人们可以用所有提取得到的特征去训练分类器，例如 softmax 分类器，但这样做面临计算量的挑战。例如：对于一个 96X96 像素的图像，假设我们已经学习得到了400个定义在8X8输入上的特征，每一个特征和图像卷积都会得到一个 (96 − 8 + 1) × (96 − 8 + 1) = 7921 维的卷积特征，由于有 400 个特征，所以每个样例 (example) 都会得到一个 892 × 400 = 3,168,400 维的卷积特征向量。学习一个拥有超过 3 百万特征输入的分类器十分不便，并且容易出现过拟合 (over-fitting)。</p>

<p>为了解决这个问题，首先回忆一下，我们之所以决定使用卷积后的特征是因为图像具有一种“静态性”的属性，这也就意味着在一个图像区域有用的特征极有可能在另一个区域同样适用。因此，为了描述大的图像，一个很自然的想法就是对不同位置的特征进行聚合统计，例如，人们可以计算图像一个区域上的某个特定特征的平均值 (或最大值)。这些概要统计特征不仅具有低得多的维度 (相比使用所有提取得到的特征)，同时还会改善结果(不容易过拟合)。这种聚合的操作就叫做池化 (pooling)，有时也称为平均池化或者最大池化 (取决于计算池化的方法)。</p>

<p><img src="./_resources/cnn10.jpeg" alt="cnn10"/></p>

<p>至此，卷积神经网络的基本结构和原理已经阐述完毕。</p>

<h3 id="toc_6">多层卷积</h3>

<p>在实际应用中，往往使用多层卷积，然后再使用全连接层进行训练，多层卷积的目的是一层卷积学到的特征往往是局部的，层数越高，学到的特征就越全局化。</p>

<h2 id="toc_7">ImageNet-2010网络结构</h2>

<p>ImageNet LSVRC是一个图片分类的比赛，其训练集包括127W+张图片，验证集有5W张图片，测试集有15W张图片。本文截取2010年Alex Krizhevsky的CNN结构进行说明，该结构在2010年取得冠军，top-5错误率为15.3%。值得一提的是，在今年的ImageNet LSVRC比赛中，取得冠军的GoogNet已经达到了top-5错误率6.67%。可见，深度学习的提升空间还很巨大。</p>

<p>下图即为Alex的CNN结构图。需要注意的是，该模型采用了2-GPU并行结构，即第1、2、4、5卷积层都是将模型参数分为2部分进行训练的。在这里，更进一步，并行结构分为数据并行与模型并行。数据并行是指在不同的GPU上，模型结构相同，但将训练数据进行切分，分别训练得到不同的模型，然后再将模型进行融合。而模型并行则是，将若干层的模型参数进行切分，不同的GPU上使用相同的数据进行训练，得到的结果直接连接作为下一层的输入。</p>

<p><img src="./_resources/cnn11.jpeg" alt="cnn11"/></p>

<p>上图模型的基本参数为：</p>

<p>输入：224×224大小的图片，3通道</p>

<p>第一层卷积：5×5大小的卷积核96个，每个GPU上48个。</p>

<p>第一层max-pooling：2×2的核。</p>

<p>第二层卷积：3×3卷积核256个，每个GPU上128个。</p>

<p>第二层max-pooling：2×2的核。</p>

<p>第三层卷积：与上一层是全连接，3*3的卷积核384个。分到两个GPU上个192个。</p>

<p>第四层卷积：3×3的卷积核384个，两个GPU各192个。该层与上一层连接没有经过pooling层。</p>

<p>第五层卷积：3×3的卷积核256个，两个GPU上个128个。</p>

<p>第五层max-pooling：2×2的核。</p>

<p>第一层全连接：4096维，将第五层max-pooling的输出连接成为一个一维向量，作为该层的输入。</p>

<p>第二层全连接：4096维</p>

<p>Softmax层：输出为1000，输出的每一维都是图片属于该类别的概率。</p>

<h2 id="toc_8">DeepID网络结构</h2>

<p>DeepID网络结构是香港中文大学的Sun Yi开发出来用来学习人脸特征的卷积神经网络。每张输入的人脸被表示为160维的向量，学习到的向量经过其他模型进行分类，在人脸验证试验上得到了97.45%的正确率，更进一步的，原作者改进了CNN，又得到了99.15%的正确率。</p>

<p>如下图所示，该结构与ImageNet的具体参数类似，所以只解释一下不同的部分吧。</p>

<p><img src="./_resources/cnn12.jpeg" alt="cnn12"/></p>

<p>上图中的结构，在最后只有一层全连接层，然后就是softmax层了。论文中就是以该全连接层作为图像的表示。在全连接层，以第四层卷积和第三层max-pooling的输出作为全连接层的输入，这样可以学习到局部的和全局的特征。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204006681.html">
                
                  <h1>贝叶斯网络</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">一个简单的贝叶斯网络</h2>

<p>abc 的联合概率：p(a,b,c)=p(c|a,b)p(b|a)p(a)</p>

<p><img src="./_resources/by1.jpg" alt="by1"/></p>

<p>一个有向无环图，在某些更复杂的情况下，图是可以简化的</p>

<h2 id="toc_1">全连接贝叶斯网络</h2>

<p>每一对结点之间都有边连接</p>

<p><img src="./_resources/by2.jpg" alt="by2"/></p>

<h2 id="toc_2">一个『正常』的贝叶斯网络</h2>

<p><img src="./_resources/by3.jpg" alt="by3"/></p>

<ul>
<li>有些边缺失</li>
<li>直观上：(只是一个感觉，后面会证明不对)

<ul>
<li>x1 和 x2 独立</li>
<li>x6 和 x7 在 x4 给定的条件下独立</li>
</ul></li>
<li>x1,x2,...,x7 的联合分布</li>
</ul>

<p><img src="./_resources/by4.jpg" alt="by4"/></p>

<p>联合分布中，父亲会作为条件，写在后面，依次递推来写即可。</p>

<h2 id="toc_3">对一个实际贝叶斯网络的分析</h2>

<p><img src="./_resources/by5.jpg" alt="by5"/></p>

<p>这里 0 表示 没有，1 表示有，对于 P(D|C,B) 来说，我们实际上只需要四个参数，因为对于每个确定的 C,B 组合来说，D 为两点分布，一个参数即可。</p>

<p>如果没有贝叶斯网络，参数就会很多很多。</p>

<h2 id="toc_4">通过贝叶斯网络判定条件独立</h2>

<p><img src="./_resources/by6.jpg" alt="by6"/></p>

<ul>
<li>P(a,b,c)=P(c)P(a|c)P(b|c)</li>
<li>则: P(a,b|c)=P(a,b,c) / P(c)</li>
<li>把 P(c) 移到等式左边，得到: P(a,b|c) = P(a|c)P(b|c)</li>
<li>这也就满足条件独立的定义，即在 c 给定的条件下，a 和 b 被阻断，是独立的</li>
<li>这种 tail-to-tail 的模式中，两个 tail 是条件独立的</li>
</ul>

<p><img src="./_resources/by7.jpg" alt="by7"/></p>

<p>对于上图的这种情况</p>

<ul>
<li>P(a,b,c)=P(a)P(c|a)P(b|c)</li>
<li>则:</li>
<li>P(a,b|c)=P(a,b,c) / P(c)   # 带入上式</li>
<li>= P(a)P(c|a)P(b|c) / P(c)  # P(a)P(c|a) = P(a,c)</li>
<li>= P(a,c)P(b|c) / P(c)</li>
<li>= P(a|c)P(b|c)</li>
<li>在 c 给定的条件下，a 和 b 被阻断，是独立的</li>
<li>这种 head-to-tail 的模式中，中间被隔断 head 和 tail 是条件独立的</li>
</ul>

<p><img src="./_resources/by8.jpg" alt="by8"/></p>

<p>上图的情况比较不一样</p>

<p><img src="./_resources/by9.jpg" alt="by9"/></p>

<p>其中求和的意思就是对 c 做积分，那么积分完成后 c 就为总概率 1，就可以从式子中消去，也由此得到最终的结果。</p>

<p>也就是说，即使 c 是未知的，a 和 b 也是被阻断的，是独立的(head-to-head)，而且是严格独立的(无条件独立)</p>

<h2 id="toc_5">贝叶斯网络的构建</h2>

<p><img src="./_resources/by10.jpg" alt="by10"/></p>

<p>等式最后一步可以看做是一个简化参数的过程</p>

<p><strong>举个例子</strong></p>

<p><img src="./_resources/by11.jpg" alt="by11"/></p>

<p>第一步，如果我们算出 P(J|M) = P(J)，那么说明 J 和 M 互相独立，也就是说在网络中没有连线。如果不相等，就要加上一个箭头</p>

<p><img src="./_resources/by12.jpg" alt="by12"/></p>

<p>一个一个依次计算，如果相等则没有连线，如果不相等则有连线，以这幅图为例，最后所需要的参数为 <code>1+2+4+2+4=13</code></p>

<p>这里选取节点的顺序与最终形成的网络结构也有关系。</p>

<h2 id="toc_6">贝叶斯网络的推导</h2>

<p><img src="./_resources/by13.jpg" alt="by13"/></p>

<p>假如我们发现一个人呼吸困难，那么他有多大的可能会抽烟呢？</p>

<p><img src="./_resources/by14.jpg" alt="by14"/></p>

<p>条件概率可以改写成联合分布除以边缘分布，这里分母一般是固定的所以重点考察联合分布。</p>

<p>下一条式子是 d,b,x,c,s 所有变量的联合分布(求和的右边式子)。我们对 b,x,c 积分，并固定 d=1，就可以得到上面我们要求的联合分布 P(s,d=1)</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14520204006634.html">
                
                  <h1>Bag of Words 模型</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>BOW (bag of words) 模型简介 Bag of words模型最初被用在文本分类中，将文档表示成特征矢量。它的基本思想是假定对于一个文本，忽略其词序和语法、句法，仅仅将其看做是一些词汇的集合，而文本中的每个词汇都是独立的。简单说就是讲每篇文档都看成一个袋子（因为里面装的都是词汇，所以称为词袋，Bag of words即因此而来），然后看这个袋子里装的都是些什么词汇，将其分类。如果文档中猪、马、牛、羊、山谷、土地、拖拉机这样的词汇多些，而银行、大厦、汽车、公园这样的词汇少些，我们就倾向于判断它是一篇描绘乡村的文档，而不是描述城镇的。举个例子，有如下两个文档：</p>

<blockquote>
<p>文档一：Bob likes to play basketball, Jim likes too.<br/>
文档二：Bob also likes to play football games.</p>
</blockquote>

<p>基于这两个文本文档，构造一个词典：</p>

<blockquote>
<p>Dictionary = {1:”Bob”, 2. “like”, 3. “to”, 4. “play”, 5. “basketball”, 6. “also”, 7. “football”，8. “games”, 9. “Jim”, 10. “too”}。</p>
</blockquote>

<p>这个词典一共包含10个不同的单词，利用词典的索引号，上面两个文档每一个都可以用一个10维向量表示（用整数数字0~n（n为正整数）表示某个单词在文档中出现的次数）：</p>

<blockquote>
<p>1：[1, 2, 1, 1, 1, 0, 0, 0, 1, 1]<br/>
2：[1, 1, 1, 1 ,0, 1, 1, 1, 0, 0]</p>
</blockquote>

<p>向量中每个元素表示词典中相关元素在文档中出现的次数(下文中，将用单词的直方图表示)。不过，在构造文档向量的过程中可以看到，我们并没有表达单词在原来句子中出现的次序（这是本Bag-of-words模型的缺点之一，不过瑕不掩瑜甚至在此处无关紧要）。</p>

<p>为什么要用BOW模型描述图像？</p>

<p>SIFT特征虽然也能描述一幅图像，但是每个SIFT矢量都是128维的，而且一幅图像通常都包含成百上千个SIFT矢量，在进行相似度计算时，这个计算量是非常大的，通行的做法是用聚类算法对这些矢量数据进行聚类，然后用聚类中的一个簇代表BOW中的一个视觉词，将同一幅图像的SIFT矢量映射到视觉词序列生成码本，这样每一幅图像只用一个码本矢量来描述，这样计算相似度时效率就大大提高了。</p>

<p>构建BOW码本步骤：</p>

<ol>
<li>假设训练集有M幅图像，对训练图象集进行预处理。包括图像增强，分割，图像统一格式，统一规格等等。</li>
<li>提取SIFT特征。对每一幅图像提取SIFT特征（每一幅图像提取多少个SIFT特征不定）。每一个SIFT特征用一个128维的描述子矢量表示，假设M幅图像共提取出N个SIFT特征。</li>
<li>用K-means对2中提取的N个SIFT特征进行聚类，K-Means算法是一种基于样本间相似性度量的间接聚类方法，此算法以K为参数，把N个对象分为K个簇，以使簇内具有较高的相似度，而簇间相似度较低。聚类中心有k个（在BOW模型中聚类中心我们称它们为视觉词），码本的长度也就为k，计算每一幅图像的每一个SIFT特征到这k个视觉词的距离，并将其映射到距离最近的视觉词中（即将该视觉词的对应词频+1）。完成这一步后，每一幅图像就变成了一个与视觉词序列相对应的词频矢量。</li>
<li>构造码本。码本矢量归一化因为每一幅图像的SIFT特征个数不定，所以需要归一化。如上述例子，归一化后为[1 0 0],1/12*[5 3 4].测试图像也需经过预处理，提取SIFT特征，将这些特征映射到为码本矢量，码本矢量归一化，最后计算其与训练码本的距离，对应最近距离的训练图像认为与测试图像匹配。 &gt; 设视觉词序列为{眼睛 鼻子 嘴}（k=3），则训练集中的图像变为： &gt; &gt; 第一幅图像：[1 0 0] &gt; &gt; 第二幅图像：[5 3 4]......</li>
</ol>

<p>当然，在提取sift特征的时候，可以将图像打成很多小的patch，然后对每个patch提取SIFT特征。</p>

<p>总结一下，整个过程其实就做了三件事，首先提取对 n 幅图像分别提取SIFT特征，然后对提取的整个SIFT特征进行k-means聚类得到 k 个聚类中心作为视觉单词表，最后对每幅图像以单词表为规范对该幅图像的每一个SIFT特征点计算它与单词表中每个单词的距离，最近的+1，便可得到该幅图像的码本。实际上第三步是一个统计的过程，所以BOW中向量元素都是非负的。Yunchao Gong 2012年NIPS上有一篇用二进制编码用于图像快速检索的文章就是针对这类元素是非负的特征而设计的编码方案。</p>

<p>其实BOW没有什么特别的理论推导，我觉得仅仅只是将类似SIFT、HOG这些局部特征的统计方法从微观扩展到宏观的过程，利用直方图的统计的特性，构造多个词典，利用简单的距离映射，得到每一副图片的BOW的特征，但是这样一个简单的扩展确实最重要的创新点，同时也构造了一个广泛应用的框架。</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2016/1/5</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='math.html'>数学</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>小土刀的笔记</h1>
                <div class="site-des"></div>
                <div class="social">











  <a class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>
              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="math.html"><strong>数学</strong></a>
        
            <a href="personal.html"><strong>个人</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="14520323012993.html">周国平人生哲思录</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14520323012929.html">爱是光着脚的哲学：古代智慧与现代爱情</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14520323012886.html">生活十讲</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14520323012841.html">人与永恒</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14520323012786.html">不疯魔，不哲学</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  </body>
</html>
